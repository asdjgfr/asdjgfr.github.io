{"pages":[],"posts":[{"title":"10元成本抢到周杰伦演唱会门票","text":"周杰伦从我小的时候火到我中年实在是太难了，前有粉丝黄牛抢、后有大麦不放票。年龄大了手速根本跟不上，所以只能靠脑子解决了。 抢票无非就三点 网速、手速和运气 现在就来解决这些问题。 网速 首先网速问题很好解决。大麦的集群使用的是阿里云的服务器，官方默认内网速度为千兆，那么我们挑一个非演唱会举办地区以及其周边的服务器那么就可以大概率避过抢票的大军。所以可以选择青岛或者北京的服务器。 由于只是抢票用，所以选择按量付费，也就是按小时计费 因为按量付费非常适合当前的场景，所以在这配置直接拉满当然内存 64G 就不需要了，能省 3 块就省 3 块 这样一台 16 核，40G 内存，带宽 3Gbps(大概 3000M/S)的服务器就到手了。 网速问题解决了，成本 8.79 元。 手速首先买票的流程很简单，以下以大麦为例： 选择票价 确认购买 选择购票人 确认订单 付款（人工操作） 流程确认明白后首先准备前期工作： 注册一个大麦的账号，配置好收货地址，购票人的身份证。先买一下别的演出票，确认账号可以正常使用。 首先运行环境当然选择headless-chrome。当然如果你觉得windows比较好用的话直接Chrome + Tampermonkey也勉强可以。 运行的环境为 Node.js® ，所以安装谷歌提供的Puppeteer 首先启动 Puppeteer： 12const puppeteer = require(&quot;puppeteer&quot;);const browser = await puppeteer.launch(); 然后打开大麦的登录地址： 1234await page.goto(&quot; https://passport.damai.cn/login&quot;, { //等待页面加载结束后再执行 waitUntil: &quot;domcontentloaded&quot;}); 在开发者工具中找到大麦的账号密码输入框，分别是： fm-login-id fm-login-password 直接输入并点击登录就可以了： 123document.querySelector(&quot;#fm-login-id&quot;).value = &quot;你的账号&quot;;document.querySelector(&quot;#fm-login-password&quot;).value = &quot;你的密码&quot;;document.querySelector(&quot;.fm-button.fm-submit.password-login&quot;).click(); 之后跳转你需要购买的页面，以下以周杰伦杭州场的举例： 首先看到页面的结构为日期+票价 那么流程就是选场次然后选票价： 首先找到全部的场次： 123let performs = document.querySelectorAll( &quot;.perform__order__select__performs .select_right_list_item&quot;); 判断一下非无票的并点击 1[...performs].find(el =&gt; el.querySelector(&quot;.presell&quot;).innerText !== &quot;无票&quot;); 如果是undefined那就证明都没有票了，果断刷新页面再次重复执行。 接下来票档同样操作。 在这提取字符串里的数字，用来筛选想要买的档位 1skuname.innerText.replace(/[^\\d.]/g, &quot;&quot;); 之后就是等待购买了，在这使用MutationObserver来监听DOM的变化，如果disabled没有了那么直接点击就可以了 123456789101112const targetNode = document.getElementById('[data-spm=&quot;dbuy&quot;]');const config = { attributes: true };// Callback function to execute when mutations are observedconst callback = function(mutationsList, observer) { for (let mutation of mutationsList) { if (mutation.type === &quot;attributes&quot;) { targetNode.click(); } }};const observer = new MutationObserver(callback); 之后跳转到确认订单页就没什么了，找到之前配置好的演出参加人的checkbox直接click提交订单就可以了。 在这记得加个延时，20s 左右，在 20s 期间每 3s + Math.random()左右提交一次点击，如果页面没跳转那么大概率是失败了，跳转回选择场次的页面重复之前的流程。 如果跳转了，那么直接关闭程序，执行browser.close();就可以了，抓紧拿起手机去订单里面付款。 消耗电费 1 元。 运气如果 20 分钟之后还是没成功，那么就是没抢到票。问题没有解决，接下来解决出问题的人就可以了 成本 0 元。","link":"/2019/08/25/10%E5%85%83%E6%88%90%E6%9C%AC%E6%8A%A2%E5%88%B0%E5%91%A8%E6%9D%B0%E4%BC%A6%E6%BC%94%E5%94%B1%E4%BC%9A%E9%97%A8%E7%A5%A8/"},{"title":"JavaScript实现Twitter雪花算法","text":"使用SnowFlake的理由按照时间自增，可排序。 并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)。 经测试 MacBook Pro (15-inch, 2018) 每秒可产生136万左右的ID。 Twitter_Snowflaketwitter开源的地址：twitter-archive/snowflake SnowFlake的结构如下(共64bits，每部分用-分开): 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 | ———————-|———————- –|– –|– —–|—— 1bit不用 41bit 时间戳 数据标识id 机器id 序列号id 1位标识，二进制中最高位为1的都是负数，但是我们生成的id一般都使用整数，所以这个最高位固定是0 41位时间戳，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69 10位的数据机器位，可以部署在1024个节点，包括5位dataCenterId和5位workerId 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号 加起来刚好64位，为一个Long型。 实现 思路还是很简单的，直接写结果+注释吧。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110class SnowFlake { /** * @param {bigInt} workerId 工作ID (0~31) * @param {bigInt} dataCenterId 数据中心ID (0~31) */ constructor(workerId, dataCenterId) { // 开始时间 this.startTime = BigInt(new Date().getTime()); // 位数划分 [数据标识id(5bit 31)、机器id(5bit 31)](合计共支持1024个节点)、序列id(12bit 4095) this.workerIdBits = 5n; this.dataCenterIdBits = 5n; this.sequenceBits = 12n; // 支持的最大十进制id // -1 左移5位后与 -1 异或 this.maxWorkerId = -1n ^ (-1n &lt;&lt; this.workerIdBits); this.maxDataCenterId = -1n ^ (-1n &lt;&lt; this.dataCenterIdBits); // 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) this.sequenceMask = -1n ^ (-1n &lt;&lt; this.sequenceBits); // 机器ID向左移12位 数据标识id向左移17位(12+5) 时间截向左移22位(5+5+12) this.workerIdShift = this.sequenceBits; this.dataCenterIdShift = this.sequenceBits + this.workerIdBits; this.timestampLeftShift = this.dataCenterIdShift + this.dataCenterIdBits; // 工作机器ID(0~31) 数据中心ID(0~31) 毫秒内序列(0~4095) this.sequence = 0n; // 上次生成ID的时间戳，保存在内存中。 this.lastTimestamp = -1n; const { maxWorkerId, maxDataCenterId } = this; if (workerId &gt; maxWorkerId || workerId &lt; 0n) { throw new Error( `workerId 不能大于 ${maxWorkerId} 或小于 0` ); } if (dataCenterId &gt; maxDataCenterId || dataCenterId &lt; 0n) { throw new Error( `dataCenterId 不能大于 ${maxDataCenterId} 或小于 0` ); } this.workerId = workerId; this.dataCenterId = dataCenterId; return this; } /** * 获得下一个ID (该方法是线程安全的) * * @returns {bigint} SnowflakeId 返回 id */ nextId() { let timestamp = this.timeGen(); // 如果当前时间小于上一次ID生成的时间戳，说明系统时钟回拨过这个时候应当抛出异常 const diff = timestamp - this.lastTimestamp; if (diff &lt; 0n) { throw new Error( `出现时钟回拨。拒绝生成 ${-diff} 毫秒的ID` ); } // 如果是同一时间生成的，则进行毫秒内序列 if (diff === 0n) { this.sequence = (this.sequence + 1n) &amp; this.sequenceMask; // 毫秒内序列溢出 if (this.sequence === 0n) { // 阻塞到下一个毫秒，获得新的时间戳 timestamp = this.tilNextMillis(this.lastTimestamp); } } else { // 时间戳改变，毫秒内序列重置 this.sequence = 0n; } // 保存上次生成ID的时间截 this.lastTimestamp = timestamp; // 移位并通过或运算拼到一起组成64位的ID // 将各 bits 位数据移位后或运算合成一个大的64位二进制数据 return ( ((timestamp - this.startTime) &lt;&lt; this.timestampLeftShift) | // 时间数据左移22 (this.dataCenterId &lt;&lt; this.dataCenterIdShift) | // 数据标识id左移 17 (this.workerId &lt;&lt; this.workerIdShift) | // 机器id左移 12 this.sequence ); } /** * 阻塞到下一个毫秒，直到获得新的时间戳 * @param {bigInt} lastTimestamp 上次生成ID的时间截 * @return {bigInt} 当前时间戳 */ tilNextMS(lastTimestamp) { let timestamp = this.timeGen(); while (timestamp &lt;= lastTimestamp) { timestamp = this.timeGen(); } return timestamp; } /** * 返回以毫秒为单位的当前时间 * @return {bigInt} 当前时间(毫秒) */ timeGen() { return BigInt(+new Date()); }} 测试一下123456789(function () { console.time('id'); const idWorker = new SnowFlake(1n, 1n); const tempArr = []; for (let i = 0; i &lt; 100000; i++) { tempArr.tempArr(idWorker.nextId()); } console.timeEnd('id');})()","link":"/2019/11/26/JavaScript%E5%AE%9E%E7%8E%B0Twitter%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95/"},{"title":"MAC上的Chrome 恢复白色主题","text":"在新版的Chrome上会跟随Mac上的暗色主题也变成黑色的。但是网页设计全部都是白色的主题，所以在使用的时候看起来非常丑。 打开终端输入如下命令就可以恢复白色模式。不需要修改Mac的主题。 1defaults write com.google.Chrome NSRequiresAquaSystemAppearance -bool YES","link":"/2019/08/08/MAC%E4%B8%8A%E7%9A%84Chrome%20%E6%81%A2%E5%A4%8D%E7%99%BD%E8%89%B2%E4%B8%BB%E9%A2%98/"},{"title":"React 使用TypeScript时customize-cra配置别名无效的解决办法","text":"想用TypeScript做一个个人的项目，结果在启动的时候就遇到了问题，customize-cra配置路径别名的时候总是报错，网上搜的都是旧版的，官网也只有JS的配置。后来在这个issues下找到了答案，再这记录一下。 首先在根目录下新建config-overrides.js： 12345//引入需要的组件const { override, addWebpackAlias,} = require('customize-cra'); 然后写入配置： 12345678const path = require('path');module.exports = override( addWebpackAlias({ // eslint-disable-next-line no-useless-computed-key [&quot;@&quot;]: path.resolve(__dirname, &quot;src&quot;), }),); 网上的教程都到此为止。时机后面应该还有一步。 在根目录下新建paths.json（叫什么名无所谓，和接下来的配置保持一致就行）： 12345678{ &quot;compilerOptions&quot;: { &quot;baseUrl&quot;: &quot;src&quot;, &quot;paths&quot;: { &quot;@/*&quot;: [&quot;*&quot;] } }} 然后在tsconfig.json里加入： 1&quot;extends&quot;: &quot;./paths.json&quot; 重启项目 1import Hello from &quot;@/components/Hello&quot;; 不再报错，配置成功。","link":"/2019/11/13/React%20%E4%BD%BF%E7%94%A8TypeScript%E6%97%B6%E9%85%8D%E7%BD%AE%E5%88%AB%E5%90%8D%E6%97%A0%E6%95%88%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"},{"title":"SpaceX上的Javascript 这下面试造火箭没准真就去造火箭了","text":"在上个月SpaceX 成功发射了载人火箭Dragon 2，其中的飞行界面就是由Chromium 和JavaScript进行构建的，当然只有图形界面是，系统的其他部分还是由c++来完成的。 Also, only the actual graphical display application uses Chromium/JS. The rest of the system is all C++. The display code has 100% test coverage, down to validation of graphical output (for example if you have a progress bar and you set it to X% the tests verify that it is actually drawn correctly). 不知道会不会出现氧气剩余 NaN%**，着陆地点undefined** 火箭的操作界面估计是不会开源了，但是SpaceX-API 倒是在GitHub上开源了。 继阿波罗登月的代码之后又参与了SpaceX-API 的review，以后面试问我参与过什么项目就可以说参与过阿波罗登月计划和SpaceX 载人航天计划的code review。感觉准备个PPT可以去融资了。 什么是SpaceX-API SpaceX-API 是一个用于火箭、核心舱、太空舱、发射台和发射数据的开源 REST API。 接口文档展示了所提供的 API 接口，还包括多种语言的接口调用。 比如dragons的信息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159[ { &quot;id&quot;: &quot;dragon1&quot;, &quot;name&quot;: &quot;Dragon 1&quot;, &quot;type&quot;: &quot;capsule&quot;, &quot;active&quot;: true, &quot;crew_capacity&quot;: 0, &quot;sidewall_angle_deg&quot;: 15, &quot;orbit_duration_yr&quot;: 2, &quot;dry_mass_kg&quot;: 4200, &quot;dry_mass_lb&quot;: 9300, &quot;first_flight&quot;: &quot;2010-12-8&quot;, &quot;heat_shield&quot;: { &quot;material&quot;: &quot;PICA-X&quot;, &quot;size_meters&quot;: 3.6, &quot;temp_degrees&quot;: 3000, &quot;dev_partner&quot;: &quot;NASA&quot; }, &quot;thrusters&quot;: [ { &quot;type&quot;: &quot;Draco&quot;, &quot;amount&quot;: 18, &quot;pods&quot;: 4, &quot;fuel_1&quot;: &quot;nitrogen tetroxide&quot;, &quot;fuel_2&quot;: &quot;monomethylhydrazine&quot;, &quot;thrust&quot;: { &quot;kN&quot;: 0.4, &quot;lbf&quot;: 90 } } ], &quot;launch_payload_mass&quot;: { &quot;kg&quot;: 6000, &quot;lb&quot;: 13228 }, &quot;launch_payload_vol&quot;: { &quot;cubic_meters&quot;: 25, &quot;cubic_feet&quot;: 883 }, &quot;return_payload_mass&quot;: { &quot;kg&quot;: 3000, &quot;lb&quot;: 6614 }, &quot;return_payload_vol&quot;: { &quot;cubic_meters&quot;: 11, &quot;cubic_feet&quot;: 388 }, &quot;pressurized_capsule&quot;: { &quot;payload_volume&quot;: { &quot;cubic_meters&quot;: 11, &quot;cubic_feet&quot;: 388 } }, &quot;trunk&quot;: { &quot;trunk_volume&quot;: { &quot;cubic_meters&quot;: 14, &quot;cubic_feet&quot;: 494 }, &quot;cargo&quot;: { &quot;solar_array&quot;: 2, &quot;unpressurized_cargo&quot;: true } }, &quot;height_w_trunk&quot;: { &quot;meters&quot;: 7.2, &quot;feet&quot;: 23.6 }, &quot;diameter&quot;: { &quot;meters&quot;: 3.7, &quot;feet&quot;: 12 }, &quot;wikipedia&quot;: &quot;https://en.wikipedia.org/wiki/SpaceX_Dragon&quot;, &quot;description&quot;: &quot;Dragon is a reusable spacecraft developed by SpaceX, an American private space transportation company based in Hawthorne, California. Dragon is launched into space by the SpaceX Falcon 9 two-stage-to-orbit launch vehicle. The Dragon spacecraft was originally designed for human travel, but so far has only been used to deliver cargo to the International Space Station (ISS).&quot; }, { &quot;id&quot;: &quot;dragon2&quot;, &quot;name&quot;: &quot;Dragon 2&quot;, &quot;type&quot;: &quot;capsule&quot;, &quot;active&quot;: false, &quot;crew_capacity&quot;: 7, &quot;sidewall_angle_deg&quot;: 15, &quot;orbit_duration_yr&quot;: 2, &quot;dry_mass_kg&quot;: 6350, &quot;dry_mass_lb&quot;: 14000, &quot;first_flight&quot;: null, &quot;heat_shield&quot;: { &quot;material&quot;: &quot;PICA-X&quot;, &quot;size_meters&quot;: 3.6, &quot;temp_degrees&quot;: 3000, &quot;dev_partner&quot;: &quot;NASA&quot; }, &quot;thrusters&quot;: [ { &quot;type&quot;: &quot;Draco&quot;, &quot;amount&quot;: 18, &quot;pods&quot;: 4, &quot;fuel_1&quot;: &quot;nitrogen tetroxide&quot;, &quot;fuel_2&quot;: &quot;monomethylhydrazine&quot;, &quot;thrust&quot;: { &quot;kN&quot;: 0.4, &quot;lbf&quot;: 90 } }, { &quot;type&quot;: &quot;SuperDraco&quot;, &quot;amount&quot;: 8, &quot;pods&quot;: 4, &quot;fuel_1&quot;: &quot;dinitrogen tetroxide&quot;, &quot;fuel_2&quot;: &quot;monomethylhydrazine&quot;, &quot;thrust&quot;: { &quot;kN&quot;: 71, &quot;lbf&quot;: 16000 } } ], &quot;launch_payload_mass&quot;: { &quot;kg&quot;: 6000, &quot;lb&quot;: 13228 }, &quot;launch_payload_vol&quot;: { &quot;cubic_meters&quot;: 25, &quot;cubic_feet&quot;: 883 }, &quot;return_payload_mass&quot;: { &quot;kg&quot;: 3000, &quot;lb&quot;: 6614 }, &quot;return_payload_vol&quot;: { &quot;cubic_meters&quot;: 11, &quot;cubic_feet&quot;: 388 }, &quot;pressurized_capsule&quot;: { &quot;payload_volume&quot;: { &quot;cubic_meters&quot;: 11, &quot;cubic_feet&quot;: 388 } }, &quot;trunk&quot;: { &quot;trunk_volume&quot;: { &quot;cubic_meters&quot;: 14, &quot;cubic_feet&quot;: 494 }, &quot;cargo&quot;: { &quot;solar_array&quot;: 2, &quot;unpressurized_cargo&quot;: true } }, &quot;height_w_trunk&quot;: { &quot;meters&quot;: 7.2, &quot;feet&quot;: 23.6 }, &quot;diameter&quot;: { &quot;meters&quot;: 3.7, &quot;feet&quot;: 12 }, &quot;wikipedia&quot;: &quot;https://en.wikipedia.org/wiki/Dragon_2&quot;, &quot;description&quot;: &quot;Dragon 2 (also Crew Dragon, Dragon V2, or formerly DragonRider) is the second version of the SpaceX Dragon spacecraft, which will be a human-rated vehicle. It includes a set of four side-mounted thruster pods with two SuperDraco engines each, which can serve as a launch escape system or launch abort system (LAS). In addition, it has much larger windows, new flight computers and avionics, and redesigned solar arrays, and a modified outer mold line from the initial cargo Dragon that has been flying for several years.&quot; }] 其中使用的技术栈： 后台框架使用的是 Koa。 内容缓存使用的是 Redis、Nginx 和 Cloudflare 。 测试使用的是 Jest 和 Supertest 。 使用 Circle CI 进行持续集成/部署。 数据库使用的是 **MongoDB **。 本地部署 首先clone项目 1git clone https://github.com/r-spacex/SpaceX-API.git &amp;&amp; cd SpaceX-API 安装并启动MongoDB数据库 安装依赖 1npm i or 1yarn 运行测试 1npm test 启动 1npm start or 1yarn start 使用Docker部署 当然也可以使用Docker来进行部署： 123git clone https://github.com/r-spacex/SpaceX-API.git &amp;&amp; cd SpaceX-APIdocker-compose builddocker-compose up 总结 虽然这个项目不是真的造火箭，但好歹也能吹吹牛逼。而且代码质量和工程结构都可以学习学习。","link":"/2020/06/05/SpaceX%E4%B8%8A%E7%9A%84Javascript%20%E8%BF%99%E4%B8%8B%E9%9D%A2%E8%AF%95%E9%80%A0%E7%81%AB%E7%AE%AD%E6%B2%A1%E5%87%86%E7%9C%9F%E5%B0%B1%E5%8E%BB%E9%80%A0%E7%81%AB%E7%AE%AD%E4%BA%86/"},{"title":"macOS Sierra及以上版本 打开任何来源","text":"macOS Sierra及以上版本所有第三方应用都无法打开了，提示无法打开或者扔进废纸篓。这对于我这种用学习版的人来讲简直就是要了老命，本着学习的精神找到了开启方法，记录一下。 macOS Sierra之前的系统也是需要手动去打开应用程序-系统偏好设置-安全性和隐私-通用里勾选任何来源，这样操作之后才能打开第三方应用。而到了macOS Sierra同样如此，但是默认是不显示的。 我的系统版本： 开启方式 打开应用程序-实用工具-终端； 复制以下代码sudo spctl --master-disable ，注意是**两个-**。 输入你的root密码。 没有任何提示就是对的，尽情安装xx 软件吧。 当然，如果你不喜欢用终端输入命令的方式打开任何来源选项，你也可以通过另一种方法来打开第三方应用程序： 按住 Control 键并点按或右键点按该 app 的图标，点击打开即可出现“打开”选项（没有测试过）。\u0010\u0010","link":"/2019/10/18/macOS%20Sierra%E5%8F%8A%E4%BB%A5%E4%B8%8A%E7%89%88%E6%9C%AC%20%E6%89%93%E5%BC%80%E4%BB%BB%E4%BD%95%E6%9D%A5%E6%BA%90/"},{"title":"利用AI把老照片修复成彩色4K并实现微信小程序查看管理","text":"​ 马上要过年了，为了让我妈可以在亲戚朋友面前愉快的聊（装）天（逼），我决定把家里的老照片修复一下，一些爸妈年轻时的黑白照片也弄成彩色的。不然他们老以为我坐电脑前面就是玩游戏 😂。 先上结果对比，左面是老照片，右面是修复后的。 我妈年轻的时候咋这么好看 😆 确认过眼神，就是我要的亚子，那么开始操作吧。 1. 扫描相片​ 首先第一步需要把照片扫描到电脑上，有高清的扫描仪是最好的，但是像我这种穷 b 就只能用手机完成了，在这用的是 Google 良心应用照片扫描仪（官网，Google Play，App Store）。 官方宣传说： 毫无眩光的高分辨率扫描仪 实际使用下来效果非常棒，就是比较累人，需要一张一张的扫，毕竟没有扫描仪方便。 2. 放大照片​ 照片都是有些年头的了，那个年代还都是胶卷相机照的，本身效果就不太好，所以第一步就是把相片放大，利用 AI 补充一些细节。 ​ 在这使用的是一个高性能图像放大算法waifu2x ，这个算法最初是给动漫图片放大使用的（不愧是日本人开发的），但是实测UpPhoto模型对于照片的成像效果也非常不错，市面上所谓的无损放大大部分都是假的，一小部分又得收费，实际效果感觉没啥太大区别。而且这个算法还支持CUDA，网上 99%搜到的在线“无损”放大都是基于这个算法。那这么好用直接开整就完事了。 ​ 首先先下载waifu2x-caffe，这是waifu2x的Caffe版，也就是GUI（客户端）的版本，有简体中文的语言包，还支持GPU加速。 ​ 使用很简单，在releases里下载最新版本的，直接解压就能用。如果你的显卡比较新，支持GPU加速的话那么比直接CPU计算快上好几倍。配置GPU加速也很简单*(windows)*。 首先去英伟达下载CUDA和cuDNN。注意对应版本，比如我的显卡支持最新的CUDA，那么我下载的就是最新（2019-12）的cuda_10.2.89_441.22_win10.exe（国内网络环境不好，所以一定要下载local版的）。 然后下载cuDNN，cuDNN需要对应CUDA的版本，上面下载的是CUDA 10.2，所以在这下载cuDNN v7.6.5 (November 18th, 2019), for CUDA 10.2。 注意：cuDNN需要登录才能下载 下载完成之后之后就可以开始安装了 安装CUDA之前记得安装Visual Studio。两个软件都是下一步到底就行。 之后把cuDNN解压出来放到CUDA的安装目录里，我的是在默认安装目录：C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2。 环境变量会自动配置，网上的教程都过时了，一直下一步到结束就行。 然后点一下软件的cuDNN检查看看是否配置成功了。 ​ 当然不配置也不影响使用，就是会非常非常慢。之后就是中文界面的傻瓜操作了，选择需要转换的文件夹和输出的文件夹。自动降噪放大，3级，2x，UpPhoto 模型_（或者拿你的照片多试几次，挑一个效果最好的）_。点击开始之后就是漫长的等待了。我转换了1000 多张相片花了大概4 个多小时。 3. 压缩照片大小​ 照片放大以后位深度会比较大，整体照片体积也会很大，比我的一张照片大概就有50M左右，所以我们需要压缩一下，本来打算使用腾讯出的智图，效果还不错，但是依赖的imagemagick默认是CPU运行，GPU的版本还没编译成功，无奈放弃了。后来发现PS的压缩效果也很不错，所以直接就用PS了。PS本身就带录制功能，直接录制一下压缩的操作然后执行就行了，在这就不赘述了。 4. 搭建图床​ 后面我们需要用到图片的url，微信小程序也需要一个接口。所以在这搭建一个图床，或者使用其他免费的图床也可以（免费图床有随时挂掉/网络不稳定的几率，做好准备）。 ​ 我使用的是一个开源的图床服务Lychee 。这是一个基于PHP的图床服务，搭建也很简单。在这就不多说了，搜一下教程一大堆。 ​ 简单来说就是： clone项目 配置目录权限 在云供应商申请免费的ssh证书，配置https 配置mysql 配置php 配置nginx 打开地址输入数据库账号密码会自动建表 这个项目自带中文，在设置里改一下就可以了 5. AI 上色​ 上述工作完成后就是关键的一步。给黑白或者褪色的照片上色了。在这使用的是DeOldify这个项目，这应该是全世界最知名的开源AI上色库了。你可以下载到本地，作者在这说过本地搭建并不简单，而且我确实失败了*(头铁被锤爆了)*，不知道是windows上Docker的原因还是其他问题。 ​ 但是谷歌给大众提供了一个平台Colaboratory，官方简介： ​ Colaboratory是一个免费的 Jupyter笔记本环境，不需要进行任何设置就可以使用，并且完全在云端运行。 ​ 借助 Colaboratory，您可以编写和执行代码、保存和共享分析结果，以及利用强大的计算资源，所有这些都可通过浏览器免费使用。 ​ 简单来说这是一个谷歌开放的一款研究工具，主要用于机器学习的开发和研究。这款工具现在拥有非常好的GPU而且目前可以免费使用！ ​ 商业GPU免费使用！有没有？实测内存不够了居然还可以免费加！除了国内登不上简直没有其他缺点 🐶。 ​ 首先打开项目给建好的笔记地址 _(不保证最新，建议从GitHub上打开)_。第一步先选择复制到云端硬盘。因为笔记本身并不满足咱们的需求，所以需要对原代码进行改动，复制到自己的云端硬盘以后下次打开就可以直接使用了。 ​ 笔记复制到自己的云盘上以后第一步先挂载自己的云盘到Colab上。因为每次重新打开笔记的时候（重新打开浏览器之类的操作）都会重新分配新的服务器，所以要把自己云盘挂载上，训练成功的图片要存到自己的云盘上，否则重新打开/刷新以后就没有了。 挂载这一步的代码已经有了： 直接点击from google.colab import drive balabalabala前面的按钮 出现一个这样的链接https://accounts.google.com/o/oauth2/auth?client_id=*********，然后直接点击这个链接 登陆你的Google账号 获得一个很长的字符串 把那行字符串复制下来粘贴到出现的输入框里回车 看看左面文件选项卡下有没有你的网盘目录，没有就重新操作 ​ 挂载云盘成功以后每一个运行都点一下，等待执行完就可以了。执行到最后一步（Colorize!!）的时候可以随便搜一个黑白照片试一下效果。成功以后可以进行正式的训练了。 项目本身提供的代码一次只能训练一张，得手动执行 粘贴图片地址-训练-保存，这肯定不符合需求，像我有 1000 多张图片，一个一个整估计得明年过年才能训练完了。。。所以在这修改一下代码。 第一步把原本笔记里的最后一步清空，写下咱们的代码： 设置阈值，具体数字根据效果来，可以多试几次看看多大数值效果好(min: 7, max: 45) 1render_factor = 45 所有图片的url： 上面搭建图库就是为了这个，可以直接在network里找到所有图片的数组。格式化一下： 1你的图片数组.map(p =&gt; `你的域名${p.url}`); 然后把所有地址粘过来： 1paths=[&quot;地址1&quot;,&quot;地址2&quot;...] 定义一个内存释放的函数，训练的时候不会自动释放内存，次数多了直接就崩溃了，所以每训练完一张图片就回收一下内存： 123456def clean_mem(): torch.cuda.empty_cache() n = 2**14 a_2GB = np.ones((n, n)) # RAM: +2GB del a_2GB # RAM: -2GB gc.collect() 之后循环进行训练： 1234for i in range(len(paths)): clean_mem() image_path = colorizer.plot_transformed_image_from_url(url=paths[i], render_factor=render_factor, compare=False) shutil.copyfile(image_path,'/content/drive/My Drive/你的自定义文件夹地址/'+str(i)+'.png') ​ 现在直接点击前面的运行按钮就可以开始训练了，时间会很漫长，具体时间没看，大概 6,7 个小时才训练完成。别觉得慢，要是部署到家用机器上估计几天几夜打底吧（再提一嘴，谷歌真是太良心了，就算是2080TI Super也干不过免费分配的吧）。 ​ 等到所有图片计算完成后你可以在云盘上看到所有成功后的图片。在这把他们打成一个压缩包，共享出去，然后搜一个谷歌云盘真实地址解析的网站（搜一下有的是，在这就不挂了，没准几天就死链了）。拿到真实地址以后可以用迅雷下载，200M带宽跑满，美滋滋。 图片下载下来后再人工给不太满意的图片用ps修一下，大功告成。 微信小程序​ 在这我写了一个简单的小程序，实现了相册和图片的管理。使用taro以及 taro-ui构建。 yarn install npm run dev:weapp开发 npm run build:weapp打包小程序 结语​ 为了让我妈能在春节请朋好友装逼大会中胜出真是让我煞费苦心。不知道叔叔阿姨大爷大娘手里的泡脚桶啊，按摩仪呀啥的还香不香了 😂","link":"/2019/12/17/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BF%AE%E5%A4%8D%E7%85%A7%E7%89%87/"},{"title":"使用javascript实现经典算法","text":"冒泡排序 原理:重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。 js代码实现: 12345678910111213function bubbleSort(arr) { var len = arr.length; for (var i = 0; i &lt; len; i++) { for (var j = 0; j &lt; len - 1 - i; j++) { if (arr[j] &gt; arr[j+1]) { var temp = arr[j+1]; arr[j+1] = arr[j]; arr[j] = temp; }; }; }; return arr;}; 选择排序 原理:每一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。 选择排序是不稳定的排序方法（比如数组[5， 5， 3]第一次就将第一个[5]与[3]交换，导致第一个5挪动到第二个5后面）。 js代码实现: 12345678910111213141516function selectionSort(arr) { var len = arr.length; var minIndex, temp; for (var i = 0; i &lt; len - 1; i++) { minIndex = i; for (var j = i + 1; j &lt; len; j++) { if (arr[j] &lt; arr[minIndex]) { minIndex = j; }; }; temp = arr[i]; arr[i] = arr[minIndex]; arr[minIndex] = temp; }; return arr;}; 插入排序 原理:有一个已经有序的数据序列，要求在这个已经排好的数据序列中插入一个数，但要求插入后此数据序列仍然有序，这个时候就要用到一种新的排序方法——插入排序法,插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的、个数加一的有序数据，算法适用于少量数据的排序，时间复杂度为O(n^2)。是稳定的排序方法。插入算法把要排序的数组分成两部分：第一部分包含了这个数组的所有元素，但将最后一个元素除外（让数组多一个空间才有插入的位置），而第二部分就只包含这一个元素（即待插入元素）。在第一部分排序完成后，再将这个最后元素插入到已排好序的第一部分中。​ 插入排序的基本思想是：每步将一个待排序的记录，按其关键码值的大小插入前面已经排序的文件中适当位置上，直到全部插入完为止。 js代码实现: 1234567891011121314function insertionSort(arr) { var len = arr.length; var preIndex, current; for (var i = 1; i &lt; len; i++) { preIndex = i - 1; current = arr[i]; while(preIndex &gt;= 0 &amp;&amp; arr[preIndex] &gt; current) { arr[preIndex+1] = arr[preIndex]; preIndex--; }; arr[preIndex+1] = current; }; return arr;}; 归并排序 原理:将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。 js代码实现: 12345678910111213141516171819202122232425262728293031function mergeSort(arr) { //采用自上而下的递归方法 var len = arr.length; if(len &lt; 2) { return arr; }; var middle = Math.floor(len / 2), left = arr.slice(0, middle), right = arr.slice(middle); return merge(mergeSort(left), mergeSort(right));};function merge(left, right){ var result = []; while (left.length &amp;&amp; right.length) { if (left[0] &lt;= right[0]) { result.push(left.shift()); } else { result.push(right.shift()); } }; while (left.length) result.push(left.shift()); while (right.length) result.push(right.shift()); return result;}; 希尔排序 原理:是插入排序的一种又称“缩小增量排序”（Diminshing Increment Sort），是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。​ 希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。 js代码实现 123456789101112131415161718function shellSort(arr) { var len = arr.length, temp, gap = 1; while(gap &lt; len/3) { gap =gap*3+1; }; for (gap; gap &gt; 0; gap = Math.floor(gap/3)) { for (var i = gap; i &lt; len; i++) { temp = arr[i]; for (var j = i-gap; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j-=gap) { arr[j+gap] = arr[j]; }; arr[j+gap] = temp; }; }; return arr;}; 快速排序 原理:快速排序（Quicksort）是对冒泡排序的一种改进。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 js代码实现: 123456789101112131415161718192021222324252627282930function quickSort(arr, left, right) { var len = arr.length, partitionIndex, left = typeof left != 'number' ? 0 : left, right = typeof right != 'number' ? len - 1 : right; if (left &lt; right) { partitionIndex = partition(arr, left, right); quickSort(arr, left, partitionIndex-1); quickSort(arr, partitionIndex+1, right); }; return arr;};function partition(arr, left ,right) { //分区操作 var pivot = left, //设定基准值（pivot） index = pivot + 1; for (var i = index; i &lt;= right; i++) { if (arr[i] &lt; arr[pivot]) { swap(arr, i, index); index++; }; }; swap(arr, pivot, index - 1); return index-1;};function swap(arr, i, j) { var temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;}; 堆排序 原理:堆排序(Heapsort)是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位指定索引的元素。堆分为大根堆和小根堆，是完全二叉树。大根堆的要求是每个节点的值都不大于其父节点的值，即A[PARENT[i]] &gt;= A[i]。在数组的非降序排序中，需要使用的就是大根堆，因为根据大根堆的要求可知，最大的值一定在堆顶。 js代码实现 12345678910111213141516171819202122232425262728293031323334353637383940var len;function buildMaxHeap(arr) { len = arr.length; for (var i = Math.floor(len/2); i &gt;= 0; i--) { heapify(arr, i); };};function heapify(arr, i) { var left = 2 * i + 1, right = 2 * i + 2, largest = i; if (left &lt; len &amp;&amp; arr[left] &gt; arr[largest]) { largest = left; }; if (right &lt; len &amp;&amp; arr[right] &gt; arr[largest]) { largest = right; }; if (largest != i) { swap(arr, i, largest); heapify(arr, largest); };};function swap(arr, i, j) { var temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;};function heapSort(arr) { buildMaxHeap(arr); for (var i = arr.length-1; i &gt; 0; i--) { swap(arr, 0, i); len--; heapify(arr, 0); }; return arr;}; 计数排序 原理:计数排序是一个非基于比较的排序算法，该算法于1954年由 Harold H. Seward 提出。它的优势在于在对一定范围内的整数排序时，它的复杂度为Ο(n+k)（其中k是整数的范围），快于任何比较排序算法。[1-2] 当然这是一种牺牲空间换取时间的做法，而且当O(k)&gt;O(nlog(n))的时候其效率反而不如基于比较的排序（基于比较的排序的时间复杂度在理论上的下限是O(nlog(n)), 如归并排序，堆排序） js代码实现: 12345678910111213141516171819202122function countingSort(arr, maxValue) { var bucket = new Array(maxValue+1), sortedIndex = 0; arrLen = arr.length, bucketLen = maxValue + 1; for (var i = 0; i &lt; arrLen; i++) { if (!bucket[arr[i]]) { bucket[arr[i]] = 0; }; bucket[arr[i]]++; }; for (var j = 0; j &lt; bucketLen; j++) { while(bucket[j] &gt; 0) { arr[sortedIndex++] = j; bucket[j]--; }; }; return arr;}; 桶排序 原理:将数组分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。桶排序是鸽巢排序的一种归纳结果。当要被排序的数组内的数值是均匀分配的时候，桶排序使用线性时间（Θ（n））。但桶排序并不是 比较排序，他不受到 O(n log n) 下限的影响。 js代码实现 123456789101112131415161718192021222324252627282930313233343536function bucketSort(arr, bucketSize) { if (arr.length === 0) { return arr; }; var i; var minValue = arr[0]; var maxValue = arr[0]; for (i = 1; i &lt; arr.length; i++) { if (arr[i] &lt; minValue) { minValue = arr[i]; //输入数据的最小值 } else if (arr[i] &gt; maxValue) { maxValue = arr[i]; //输入数据的最大值 }; }; //桶的初始化 var DEFAULT_BUCKET_SIZE = 5; //设置桶的默认数量为5 bucketSize = bucketSize || DEFAULT_BUCKET_SIZE; var bucketCount = Math.floor((maxValue - minValue) / bucketSize) + 1; var buckets = new Array(bucketCount); for (i = 0; i &lt; buckets.length; i++) { buckets[i] = []; }; //利用映射函数将数据分配到各个桶中 for (i = 0; i &lt; arr.length; i++) { buckets[Math.floor((arr[i] - minValue) / bucketSize)].push(arr[i]); }; arr.length = 0; for (i = 0; i &lt; buckets.length; i++) { insertionSort(buckets[i]); //对每个桶进行排序，这里使用了插入排序 for (var j = 0; j &lt; buckets[i].length; j++) { arr.push(buckets[i][j]); }; }; return arr;}; 基数排序 原理:基数排序（radix sort）属于“分配式排序”（distribution sort），又称“桶子法”（bucket sort）或bin sort，顾名思义，它是透过键值的部份资讯，将要排序的元素分配至某些“桶”中，藉以达到排序的作用，基数排序法是属于稳定性的排序，其时间复杂度为O (nlog(r)m)，其中r为所采取的基数，而m为堆数，在某些时候，基数排序法的效率高于其它的稳定性排序法。 js代码实现 123456789101112131415161718192021222324var counter = [];function radixSort(arr, maxDigit) { var mod = 10; var dev = 1; for (var i = 0; i &lt; maxDigit; i++, dev *= 10, mod *= 10) { for(var j = 0; j &lt; arr.length; j++) { var bucket = parseInt((arr[j] % mod) / dev); if(counter[bucket]==null) { counter[bucket] = []; }; counter[bucket].push(arr[j]); }; var pos = 0; for(var j = 0; j &lt; counter.length; j++) { var value = null; if(counter[j]!=null) { while ((value = counter[j].shift()) != null) { arr[pos++] = value; }; }; }; }; return arr;};","link":"/2016/02/09/%E4%BD%BF%E7%94%A8javascript%E5%AE%9E%E7%8E%B0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95/"},{"title":"Rocket.Chat docker搭建私人&#x2F;团队聊天教程","text":"​ 双十一买的良心云不知道做点什么，看到有人在v2ex上问哪个开源聊天好，索性也搭一个玩玩。在这使用的是rocket.chat。 ​ 我的地址是https://chat.2077tech.com/channel，可以先看一看效果。 ​ 首先我的服务器是Ubuntu 18，但是没有使用snap。为了方便管理使用Docker来搭建。 首先更新一下系统 1sudo apt update &amp;&amp; sudo apt upgrade 然后安装 Docker和 Docker-compose。 由于我的docker是使用管理员权限安装的，所以下面有关docker的操作全都加上了sudo。正常是不需要的。 docker安装完成之后配置一下国内的镜像： 1sudo nano /etc/docker/daemon.json 写下内容： 123456789{ &quot;registry-mirrors&quot;: [ &quot;https://你申请的链接.mirror.aliyuncs.com&quot;, &quot;http://docker.mirrors.ustc.edu.cn&quot;, &quot;http://hub-mirror.c.163.com&quot; ], &quot;debug&quot;: true, &quot;experimental&quot;: true} 阿里云的docker镜像需要自己申请一下，免费的。 配置好国内镜像后下载image也会出现非常慢或者失败的情况，我对docker不太了解，估计是内部地址的问题。我的解决方案就是配置v2ray，秒下。如果没有条件的话就只能等了。 之后下载官方提供的Docker-compose ： 12cd 你的目录curl -L https://raw.githubusercontent.com/RocketChat/Rocket.Chat/develop/docker-compose.yml -o docker-compose.yml 或者可以参考我的配置： 1sudo nano ./docker-compose.yml 写入内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455version: &quot;2&quot;services: rocketchat: image: rocket.chat:latest command: bash -c 'for i in `seq 1 30`; do node main.js &amp;&amp; s=$$? &amp;&amp; break || s=$$?; echo &quot;Tried $$i times. Waiting 5 secs...&quot;; sleep 5; done; (exit $$s)' restart: unless-stopped volumes: - ./uploads:/app/uploads environment: - PORT=3000 - ROOT_URL=http://chat.2077tech.com - MONGO_URL=mongodb://mongo:27017/rocketchat - MONGO_OPLOG_URL=mongodb://mongo:27017/local - Accounts_UseDNSDomainCheck=True depends_on: - mongo ports: - 4955:3000 mongo: image: mongo:4.0 restart: unless-stopped volumes: - ./data/db:/data/db - ./data/dump:/dump command: mongod --smallfiles --oplogSize 128 --replSet rs0 --storageEngine=mmapv1 # this container's job is just run the command to initialize the replica set. # it will run the command and remove himself (it will not stay running) mongo-init-replica: image: mongo command: 'bash -c &quot;for i in `seq 1 30`; do mongo mongo/rocketchat --eval \\&quot;rs.initiate({ _id: ''rs0'', members: [ { _id: 0, host: ''localhost:27017'' } ]})\\&quot; &amp;&amp; s=$$? &amp;&amp; break || s=$$?; echo \\&quot;Tried $$i times. Waiting 5 secs...\\&quot;; sleep 5; done; (exit $$s)&quot;' depends_on: - mongo # hubot, the popular chatbot (add the bot user first and change the password before starting this image) hubot: image: rocketchat/hubot-rocketchat:latest restart: unless-stopped environment: - ROCKETCHAT_URL=服务器地址:端口号 - ROCKETCHAT_ROOM=GENERAL - ROCKETCHAT_USER=你的自定义用户名 - ROCKETCHAT_PASSWORD=你的自定义密码 - BOT_NAME=机器人名称 # you can add more scripts as you'd like here, they need to be installable by npm - EXTERNAL_SCRIPTS=hubot-help,hubot-seen,hubot-links,hubot-diagnostics depends_on: - rocketchat volumes: - ./scripts:/home/hubot/scripts # this is used to expose the hubot port for notifications on the host on port 3001, e.g. for hubot-jenkins-notifier ports: - 4956:8080 开启mongodb服务： 1sudo docker-compose up -d mongo 首次启动mongo时，还需要对其进行初始化，然后才能使用Rocket.Chat。 确保mongo处于运行状态，然后： 1sudo docker-compose up -d mongo-init-replica Mongo支持7 x 24的操作和实时备份。所以不需要太频繁地重新启动它。详细的可以查兰参考文档 mongodb已启动并正在运行之后： 1sudo docker-compose up -d rocketchat 如果需要机器人的话接下来启动hubot（记得配置ROCKETCHAT_USER 和ROCKETCHAT_PASSWORD参数）： 1sudo docker-compose up -d hubot 现在打开http://服务器地址:端口号就可以开始网页版的聊天了，手机版去各大商店下载Rocket.Chat的App就可以了。 接下来配置https，新建nginx配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657server{ listen 80; listen 443 ssl http2; server_name 你的地址; index index.php index.html index.htm default.php default.htm default.html; #SSL-START SSL相关配置，请勿删除或修改下一行带注释的404规则 #error_page 404/404.html; ssl_certificate 证书路径 ssl_certificate_key 证书key路径; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA'; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_session_timeout 180m; #SSL-END #ERROR-PAGE-START 错误页配置，可以注释、删除或修改 #error_page 404 /404.html; #error_page 502 /502.html; #ERROR-PAGE-END #PHP-INFO-START PHP引用配置，可以注释或修改 include enable-php-00.conf; #PHP-INFO-END #REWRITE-START URL重写规则引用,修改后将导致面板设置的伪静态规则失效 include /www/server/panel/vhost/rewrite/chat.2077tech.com.conf; #REWRITE-END location / { proxy_pass http://chat.2077tech.com:4955; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forward-For $proxy_add_x_forwarded_for; proxy_set_header X-Forward-Proto http; proxy_set_header X-Nginx-Proxy true; proxy_redirect off; } #禁止访问的文件或目录 location ~ ^/(\\.user.ini|\\.htaccess|\\.git|\\.svn|\\.project|LICENSE|README.md) { return 404; } #一键申请SSL证书验证目录相关设置 location ~ \\.well-known{ allow all; } access_log /www/wwwlogs/chat.2077tech.com.log; error_log /www/wwwlogs/chat.2077tech.com.error.log;} 如果访问不了，首先查看你的服务器防火墙是否允许端口通过，如果你安装了宝塔之类的面板也需要在安全里开启端口，并且云主机的厂商会有安全组策略，记得修改。 如果需要更新的话直接更新Docker的镜像就可以了： 1234sudo docker pull rocketchat/rocket.chat:developsudo docker-compose stop rocketchatsudo docker-compose rm rocketchatsudo docker-compose up -d rocketchat","link":"/2020/03/14/%E5%88%A9%E7%94%A8%20Rocket.Chat%E6%90%AD%E5%BB%BA%E7%A7%81%E4%BA%BA%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1/"},{"title":"利用AI修复被马赛克遮挡的文字","text":"​ 好久没有水文章了，最近在摸鱼的时候在GitHub上发现了一个名为 Depix的项目，截止目前已经8.4k的Star了。简介中说道： Depix is a tool for recovering passwords from pixelized screenshots. Depix是一个从像素化的截图中恢复密码的工具。 ​ 说白了就是利用深度学习恢复被打马赛克的文字。 先看效果： ​ 可以看到虽然没有完全恢复，但是基本也可以看出原图的文字了。由于线性盒式滤波是确定性算法，因此将相同的值进行像素化将始终导致相同的像素化块。 使用块的相同位置对相同文本进行像素化将产生相同的块值。 我们可以尝试对文本进行像素化以找到匹配的模式。 采用的解决方案就是：生成德布鲁因序列，将生成的序列粘贴到同一编辑器中，并进行截图。 该截图用作类似块的查找图像。 使用一、运行Example 克隆项目到本地并进入目录： 1git clone https://github.com/beurtschipper/Depix.git &amp;&amp; cd Depix 运行Demo看看是否能正确输出： 1python depix.py -p images/testimages/testimage3_pixels.png -s images/searchimages/debruinseq_notepad_Windows10_closeAndSpaced.png -o output.png 等待一会如果成功生成output.png并且和上面的截图差不多的话那就是成功了。 二、使用自己的图片尝试一下 准备一张马赛克图片。 准备自己的德布鲁因序列，用你的文字生成序列后使用第一步同样的工具进行截图。 在这提供一个js版的德布鲁因序列算法： 12345678910111213141516171819202122232425262728293031function debruijn(alphabet, wordlength) { const k= alphabet.length; const n= wordlength; if(k &lt;= 0 || n &lt;= 0) return ''; const a= []; for(let i= 0 ; i &lt; k*n ; ++i) a[i]= 0; let res= []; const db= function(t, p) { if(t &gt; n) { if(n%p == 0) { for(var i= 1 ; i &lt;= p ; ++i) res += alphabet[a[i]] + ' '; } } else { a[t]= a[t-p]; db(t+1, p); for(var j= a[t-p]+1 ; j &lt; k ; ++j) { a[t]= j; db(t+1, t); } } } db(1,1); let extra= ''; for(var i= 0, nremain= wordlength-1 ; nremain&gt;0 ; i += 2, --nremain) extra += res[i % res.length] + ' '; res += extra; return res;} 或者可以使用在线版的来生成。 然后运行程序： 1python depix.py -p 马赛克图片路径 -s 德布鲁因序列图片路径 -o 输出.png 运行后就可以看到效果了。 在这提供Colab的地址，可以在线运行查看效果。 无效果​ 如果看不到效果也很正常，因为此算法只适合线性过滤器的马赛克。懂的人都知道马赛克技术是一种利用与镶嵌画装饰艺术（Mosaic）类似原理的影像处理方法。此方法将影像特定区域的色阶细节劣化并造成色块打乱的效果。其实是破坏了原图像。由于马赛克算法的不同恢复的时候也没有办法做到统一处理。所以你的图片如果是在ps中加的马赛克滤镜那么是恢复不了的。","link":"/2020/12/20/%E5%88%A9%E7%94%A8AI%E4%BF%AE%E5%A4%8D%E8%A2%AB%E9%A9%AC%E8%B5%9B%E5%85%8B%E9%81%AE%E6%8C%A1%E7%9A%84%E6%96%87%E5%AD%97/"},{"title":"利用AI把2D图片转换为3D - 附带colab地址","text":"弗吉尼亚理工大学开源了一个图片转换为3D视频的项目，算法会根据模型训练出被遮挡的元素，同时提供了4种效果的输出。先看官方的输出示例： 放不了视频？你的浏览器太辣鸡了吧，赶紧换现代的浏览器。 算法会根据你提供的图片来生成3D视频。 环境要求 Linux (测试环境为 Ubuntu 18.04.4 LTS) Anaconda Python 3.7 (测试版本为 3.7.4) PyTorch 1.4.0 (测试版本为 1.4.0 for execution) 以及Python的依赖 首先初始化项目： 1234conda create -n 3DP python=3.7 anacondaconda activate 3DPpip install -r requirements.txtconda install pytorch==1.4.0 torchvision==0.5.0 cudatoolkit==10.1.243 -c pytorch 然后使用提供的脚本来下载模型： 12chmod +x download.sh./download.sh 运行 详细参数可以查看文档 把需要训练的jpg格式图片放到image文件夹中 然后运行: 根据配置的不同所需要的时间也不同，配置较低的话请耐心等待。 1python main.py --config argument.yml 最后生成的结果会输出为video/图片名_效果.mp4 如果想要修改默认配置可以查看文档并修改argument.yml配置文件。 我的测试图片： 输出的结果： 放不了视频？你的浏览器太辣鸡了吧，赶紧换现代的浏览器。 Colaboratory 如果不想在自己的机器上搭建，或没有趁（我）手（是）的（个）兵（穷）器（B）就可以使用谷歌的Colab来运行。Colab是什么在这就不多说了，直接上地址： 图片转3D.ipynb GitHub备份 我在在笔记里都写了注释，全部傻瓜式下一步就行了。 LICENSEMIT许可 源项目论文： 123456@inproceedings{Shih3DP20, author = {Shih, Meng-Li and Su, Shih-Yang and Kopf, Johannes and Huang, Jia-Bin}, title = {3D Photography using Context-aware Layered Depth Inpainting}, booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, year = {2020}}","link":"/2020/08/13/%E5%88%A9%E7%94%A8AI%E6%8A%8A2D%E5%9B%BE%E7%89%87%E8%BD%AC%E6%8D%A2%E4%B8%BA3D%20-%20%E9%99%84%E5%B8%A6colab%E5%9C%B0%E5%9D%80/"},{"title":"利用AI给你的小视频补帧到120 FPS（内有开车视频）","text":"​ 现在各种期间手机都开始用上 120 帧的显示屏，但是网上大部分的视频还都是 30 帧，只能人工眨眼补帧（←_←）。视频的帧率已经远远赶不上人民群众的需求了，所以有不少人都在研究如何把普通视频变成高帧率视频。 ​ 虽然SVP+potplayer可以实现实时补帧，但是文件无法保存，软件收费，只可以在windows上使用都是这个方案的弊端。所以在这找了两个可以实现补帧的开源项目： Super SloMo DAIN Super SloMo​ 首先第一种就是英伟达公布的一种算法Super SloMo，不过遗憾的是论文发布时并没有将代码和数据集公开，所以只能在视频中感受一下它的强大。 ​ 虽然官方没公布算法，但是一位在德州上学的大佬在GitHub上开源了他对 Super-SloMo 的 PyTorch 实现。 ​ 不过这个算法用的人比较少，可能是因为没有windows打包版的提高了门槛？有时间再试一下吧，在这就不赘述了。 DAIN​ 第二种就是来自上海交大的一个新的插帧算法DAIN。DAIN的代码已经开源，甚至开发人员还打包了一份Windows 安装程序，即使没有任何 AI 基础的用户也可以直接拿来用。不过在这别高兴太早，虽然有windows的打包版本，但是在我的电脑上，默认参数根本跑不了，降低网格后速度超级慢，1 个小时的视频大概需要1 周多才能完成，油管上的UP主测试几分钟的视频RTX 2080TI要跑好几个小时。所以要想使用windows版的RTX 2080TI勉勉强强，TESLA V100应该是比较好的选择。不过看着6w 块的TESLA V100 再看看钱包里的空气，只能一声叹息。不过好在还有谷歌这种无（财）私（大）奉（气）献（粗）的公司。在我之前的博客里 利用 AI 把老照片修复成彩色 4K 并实现微信小程序查看管理 提到过谷歌的google colab。这次还是使用它来实现。 ​ 首先还是先来段飙车视频，上面的是原版 30 帧的，下面是修复后 60 帧的： 放不了视频？你的浏览器太辣鸡了吧，赶紧换现代的浏览器。 如果你看不出来区别那要么你需要换个显示器，或者做个眼保健操。 dain for colab 的使用 首先定义一下需要的配置 12345678910111213141516171819202122232425262728293031323334353637383940################# 配置 ############################# INPUT_FILEPATH：输入文件的路径（相对于Google云盘的根目录）。# 例如，如果您将&quot;example.mkv&quot;文件保存在Google云盘中的&quot;videos&quot;文件夹中，则路径为：# videos/example.mkvINPUT_FILEPATH = &quot;DAIN/input.mkv&quot;# OUTPUT_FILE_PATH: 输出文件的路径（相对于Google云盘的根目录）。# 目标文件类型建议使用 mp4OUTPUT_FILE_PATH = &quot;DAIN/output.mp4&quot;################# DAIN 配置 ############################# TARGET_FPS：目标FPSTARGET_FPS = 60# 输入帧# 如果在Google云盘上有现成帧（00001.png, 00002.png）则改为云盘路径# Google云盘地址 `/content/gdrive/My Drive/`FRAME_INPUT_DIR = '/content/DAIN/input_frames'# 输出帧# 如果要将生成的帧存储到Google云盘，请使用GDrive中的位置。# Google云盘地址 `/content/gdrive/My Drive/`FRAME_OUTPUT_DIR = '/content/DAIN/output_frames'# 无缝循环# 通过将第一个帧也用作最后一个帧来创建无缝循环。SEAMLESS = False# 调整大小# 与原始输入帧相比，DAIN 帧有些“偏移/较小”。 调整大小可以部分缓解这种情况# 将帧设置为+2px的分辨率，并以起点（1,1）将结果裁剪为原始分辨率。# 如果没有此修复程序，DAIN往往会产生震动模糊，并且在诸如文本之类的静态元素中非常明显。# 用户可以更改插值方法。 建议使用方法cv2.INTER_CUBIC和cv2.INTER_LANCZOS4。# 当前默认值为 cv2.INTER_LANCZOS4.RESIZE_HOTFIX = True# ffmpeg生成视频后自动删除输出的PNG文件夹AUTO_REMOVE = True 然后挂载谷歌云盘，需要训练的视频和成果都放在网盘里方便储存。至于为什么非要挂载谷歌云盘就去上一次的文章看吧 填入授权码以后记得回车确定 123from google.colab import drivedrive.mount('/content/gdrive')print('谷歌云盘挂载成功！') 检查一下GPU，不合适的话重新分配一个。 P100: 16GB （正常） T4: 16GB （CUDA 会失败） P4: 8GB （正常） K80: 8GB （未随机到这个 GPU） 1!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv 安装依赖，这一步会消耗很长时间，耐心等待就可以了 12345678910111213141516171819202122232425from IPython.display import clear_output!git clone https://github.com/asdjgfr/Colab-DAIN.git /content/DAIN# 这步可能需要15分钟# 构建 DAIN.%cd /content/DAIN/my_package/!./build.shprint(&quot;构建第一步成功！&quot;)# 大概需要5分钟# Building DAIN PyTorch correlation package.%cd /content/DAIN/PWCNet/correlation_package_pytorch1_0!./build.shprint(&quot;构建第二步成功！&quot;)# 下载 pre-trained 模型%cd /content/DAIN!mkdir model_weights!wget -O model_weights/best.pth http://vllab1.ucmerced.edu/~wenbobao/DAIN/best.pth# 如果上面失效可以使用备用地址：# !wget -O model_weights/best.pth https://www.2077tech.com/files/dain/best.pth!CUDA_VISIBLE_DEVICES=0!sudo apt-get install imagemagick imagemagick-doc 检查一下原视频 123456789101112%shell yes | cp -f /content/gdrive/My\\ Drive/{INPUT_FILEPATH} /content/DAIN/import osfilename = os.path.basename(INPUT_FILEPATH)import cv2cap = cv2.VideoCapture(f'/content/DAIN/{filename}')fps = cap.get(cv2.CAP_PROP_FPS)if(fps/TARGET_FPS&gt;0.5): print(&quot;请定义一个更高的FPS，因为没有足够的时间用于新帧。旧FPS/新FPS应低于0.5，如果尝试补帧有可能会失败。&quot;) 提取原视频的帧，并删除带有透明通道的帧 12345678910111213141516171819202122232425262728293031# ffmpeg 提取 - 从源文件生成单个帧的PNG文件。%shell rm -rf '{FRAME_INPUT_DIR}'%shell mkdir -p '{FRAME_INPUT_DIR}'%shell ffmpeg -i '/content/DAIN/{filename}' '{FRAME_INPUT_DIR}/%05d.png'png_generated_count_command_result = %shell ls '{FRAME_INPUT_DIR}' | wc -lclear_output()pngs_generated_count = int(png_generated_count_command_result.output.strip())import shutilif SEAMLESS==True: pngs_generated_count += 1 original = str(FRAME_INPUT_DIR)+&quot;/00001.png&quot; target = str(FRAME_INPUT_DIR)+&quot;/&quot;+str(pngs_generated_count).zfill(5)+&quot;.png&quot; shutil.copyfile(original, target)print(f&quot;输入 FPS: {fps}&quot;)print(f&quot;{pngs_generated_count} 帧 PNG 生成！&quot;)# 检查图片是否拥有透明通道import subprocess as sp%cd {FRAME_INPUT_DIR}channels = sp.getoutput('identify -format %[channels] 00001.png')print (f&quot;{channels} 命中&quot;)# 如果拥有透明通道则删除if &quot;a&quot; in channels: print(&quot;检测到透明通道，即将删除！&quot;) print(sp.getoutput('find . -name &quot;*.png&quot; -exec convert &quot;{}&quot; -alpha off PNG24:&quot;{}&quot; \\;')) 等上面的都完成后就可以开始训练了 这一步会根据你要补得帧数，视频的分辨率，机器的配置等因素不同消耗不一样的时间，基本上几分钟的视频（30 FPS 转 60 FPS）都会需要几个小时 1234%shell mkdir -p '{FRAME_OUTPUT_DIR}'%cd /content/DAIN!python colab_interpolate.py --netName DAIN_slowmotion --time_step {fps/TARGET_FPS} --start_frame 1 --end_frame {pngs_generated_count} --frame_input_dir '{FRAME_INPUT_DIR}' --frame_output_dir '{FRAME_OUTPUT_DIR}' 等都完成后进行优化 放大和裁剪以匹配原始图像 1234567891011121314import numpy as np%cd {FRAME_OUTPUT_DIR}if(RESIZE_HOTFIX==True): images = [] for filename in os.listdir(f'{FRAME_OUTPUT_DIR}'): img = cv2.imread(os.path.join(f'{FRAME_OUTPUT_DIR}',filename)) part_filename = os.path.splitext(filename) if(part_filename[0].endswith('0')==False): dimension = (img.shape[1]+2, img.shape[0]+2) resized = cv2.resize(img, dimension, interpolation=cv2.INTER_LANCZOS4) crop = resized[1:(dimension[1]-1), 1:(dimension[0]-1)] cv2.imwrite(part_filename[0]+&quot;.png&quot;, crop)%cd /content/DAIN 最后合成视频 1234%cd {FRAME_OUTPUT_DIR}%shell ffmpeg -y -r {TARGET_FPS} -f image2 -pattern_type glob -i '*.png' '/content/gdrive/My Drive/{OUTPUT_FILE_PATH}'if(AUTO_REMOVE==True): !rm -rf {FRAME_OUTPUT_DIR}/* 如果原视频是有声音的，那么记得提取声音 123456%cd {FRAME_OUTPUT_DIR}%shell ffmpeg -i '/content/DAIN/{filename}' -acodec copy output-audio.aac%shell ffmpeg -y -r {TARGET_FPS} -f image2 -pattern_type glob -i '*.png' -i output-audio.aac -shortest '/content/gdrive/My Drive/{OUTPUT_FILE_PATH}'if(AUTO_REMOVE==True): !rm -rf {FRAME_OUTPUT_DIR}/* !rm -rf output-audio.aac ​ 现在你的视频就训练完成了，可以到你最开始定义的文件夹去下载，如果是按照我的教程来的话那就是在谷歌云盘的根目录下的DAIN文件夹里。 ​ 如果想要训练下一个视频的话记得清空之前输出的帧图片： 1!rm -rf {FRAME_OUTPUT_DIR}/* 之后从步骤 5 再次运行就可以了，依赖在空间收回之前只需要安装一次。 最后分享一下我的 Colab 笔记，只需要一直下一步就可以了。","link":"/2020/04/02/%E5%88%A9%E7%94%A8AI%E7%BB%99%E4%BD%A0%E7%9A%84%E5%B0%8F%E8%A7%86%E9%A2%91%E8%A1%A5%E5%B8%A7%E5%88%B0120%20FPS%EF%BC%88%E5%86%85%E6%9C%89%E5%BC%80%E8%BD%A6%E8%A7%86%E9%A2%91%EF%BC%89/"},{"title":"利用vps+nodejs爬虫实现国外软件的自动下载并且同步到百度网盘","text":"​ 买了一个国外的vps作为ss的服务器使用,但是一个月有1000g的流量根本用不完.后来想到在国内有一些网站的内容下载超级慢体验贼屎(比如git),所以利用node写了一个小爬虫,下载指定网站的exe|zip|rar软件,并且自动同步到百度网盘,美滋滋. 我的百度网盘分享 密码:8g3a 软件列表 git everything github地址 vps系统为centos 6 x 64node 版本9.x教程开始使用了cheerio 作为nodejs爬虫的框架,这是一个类似于jquery操作的框架,在这只是简单的使用. 每一步都写了注释,看不懂的话就直接用就可以了. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//引入内置request模块const request = require('request');//引入内置fs模块const fs = require('fs');//引入内置path模块const path = require('path');//引入cheerio模块,需要安装npm i cheerio -Sconst cheerio = require('cheerio');//需要下载的网站地址数组let downloadWeblist=[ 'http://www.voidtools.com/', 'https://git-scm.com/download/win'];//匹配后缀为exe,zip和rar的文件let reg=/(\\.exe|\\.zip|\\.rar)$/i;//匹配最后一个/后面的内容作为名字let reg2 = /([^/]+)$/;// 判断有没有http/httpslet reg3=/^(http)/;//遍历所有需要下载的网站for(let i=0;i&lt;downloadWeblist.length;i++){ //起个名字 let nowDownload=downloadWeblist[i]; //利用renquest模块去访问要下载的网站 request(nowDownload,(...data) =&gt;{ //访问成功 if (!data[0] &amp;&amp; data[1].statusCode == 200) { //网页加载完成后定义$,详情查看cheerio的api $ = cheerio.load(data[2]); //找到网页中所有的a标签 let result=$('a'); //遍历a标签 for(let i=0;i&lt;result.length;i++){ //如果包含exe,zip或rar的后缀 if(reg.test(result[i].attribs.href)){ //设置名字 let name=result[i].attribs.href.match(reg2)[0]; //链接起个名字 let link=result[i].attribs.href; //判断有没有http/https,如果有直接下载,没有加上下载网站的域名 if(reg3.test(link)){ try{ //下载到当前目录的download文件夹中,注意,没有这个文件夹会报错 request(link).pipe(fs.createWriteStream(path.join('./download',name))); }catch(e){ //错误信息 console.log(`&quot;${link}的${name}&quot;下载失败.(╥╯^╰╥).错误信息:${e}`); }; }else{ try { //下载到当前目录的download文件夹中,注意,没有这个文件夹会报错 request(`${nowDownload}${link}`).pipe(fs.createWriteStream(path.join('./download',name))); } catch (e) { //错误信息 console.log(`&quot;${nowDownload}${link}的${name}&quot;下载失败.(╥╯^╰╥).错误信息:${e}`); };//这 };//就是 };//传说中的 };//回调 };//地狱 });//吗};//? 可以先在本地试一下可不可以. 新建在同级目录下新建download文件夹,执行文件 1node app 如果download文件夹下出现文件的名字了表示下载成功,可以按ctrl+c 取消,如果没出现查看错误信息. 然后在服务器中安装nodejs,因为我是centos系统,所以使用yum安装 获取nodejs 资源 1curl --silent --location https://rpm.nodesource.com/setup_8.x | bash - 安装 1yum install -y nodejs 测试是否安装成功 1node -v 出现版本号则安装成功 如果node版本比较低,可以使用n 模块升级 全局安装n 1npm install n -g 升级到最新版 1n latest 升级完成后断开vps 重新连接**(不是重启)**,查看是否升级成功 1node -v nodejs 安装完成以后把文件上传到服务器,个人感觉FlashFXP 挺好用,带ui 界面 然后在服务器执行node app 看看是否能下载到vps 里**(别忘了在同级目录新建download文件夹)** ———————————-我是分割线———————– 现在已经可以成功的把文件下载到vps 里面了,接下来就需要上传到百度云了,在这用的是bpcs_uploader 插件,作者网站,作者博客 bpcs_uploader安装和使用 首先安装php 1yum install php 把项目clone到vps上 1git clone https://github.com/oott123/bpcs_uploader.git 为脚本添加权限 12cd bpcs_uploaderchmod +x bpcs_uploader.php 初始化脚本 1./bpcs_uploader.php quickinit 这个时候终端会询问你是否初始化，输入Y，然后会打印出许多文字，其中包括授权码。 在浏览器中访问百度授权申请。输入授权码，确定，成功后返回终端按回车键，看到屏幕上打印出了你百度网盘的容量，证明初始化完成。 完成以后就可以尝试同步一下,看看是否可以把vps的文件同步到百度网盘. 123456789101112//上传：./bpcs_uploader.php upload [path_local] [path_remote]//举例：./bpcs_uploader.php upload /root/test.txt /test/test.txt 则本地root目录下的test.txt文件会上传到百度云/我的应用数据/bpcs_uploader/test目录下//下载：./bpcs_uploader.php download [path_local] [path_remote]//删除文件：./bpcs_uploader.php delete [path_remote]//离线下载：./bpcs_uploader.php fetch [path_remote] [path_to_fetch] 可以同步以后就需要实现自动化了,使用命令只能手动同步,并且必须输入文件名,那么可以写一个shell脚本来完成同步. 1234567891011121314151617181920212223242526#!/bin/bash# 执行node爬虫把文件下载到服务器`node app`# 上传到百度云盘的根目录baidupan_DIR=&quot;/myVPS&quot;function searchFile(){ for file in `ls $1` do if [ -d $1&quot;/&quot;$file ] then ergodic $1&quot;/&quot;$file else local path=$1&quot;/&quot;$file #local name=$file #local size=`du --max-depth=1 $path|awk '{print $1}'` #echo $name $path $size #可以得到文件的名称，路径和大小，路径包含名称 /root/bpcs_uploader/bpcs_uploader.php upload $path $baidupan_DIR/$path fi done}#这个必须要，否则会在文件名中有空格时出错IFS=$'\\n' #这里是你要批量上传文件的路径searchFile &quot;/usr/syncdir/download&quot;exit 0 可以把以上代码复制以后存为.sh 文件进行执行,但是需要注意,如果在windows下编辑并保存以后再vps上执行会报错,使用vi 打开会发现行尾有^M 字符,所以需要去掉. 1vi -b upload.sh 打开文件后执行以下代码 注意!下面的^和M不是直接打出来的,而是ctrl+v 和ctrl+m1:%s/^M//g 替换完成后使用:wq保存保存并退出. 再次执行sh文件 1./upload.sh 查看是否可以在百度云同步成功. 爬虫有了,文件批量同步百度网盘有了,就差最后一步自动化了,可以使用crontab 进行定时任务. 执行: 12service crond status//查看crond是否为开启状态 其他操作: 12345service crond start //启动服务service crond stop //关闭服务service crond restart //重启服务service crond reload //重新载入配置service crond status //查看服务状态 执行 1crontab -e 使用vi输入: 10 2 * * 1 /你的路径/upload.sh 以上的意思为每周一的凌晨2点执行upload.sh 脚本一次 然后按下esc,输入:wq保存并退出 为了保险起见可以重启一下进程: 1service crond restart //重启服务 DONE当然如果没用明白没关系,你可以留言给我需要下载的外网资源,我来添加到爬虫里,然后可以使用我的百度网盘分享进行下载. 密码:8g3a.","link":"/2018/07/11/%E5%88%A9%E7%94%A8vps+nodejs%E7%88%AC%E8%99%AB%E5%AE%9E%E7%8E%B0%E5%9B%BD%E5%A4%96%E8%BD%AF%E4%BB%B6%E7%9A%84%E8%87%AA%E5%8A%A8%E4%B8%8B%E8%BD%BD%E5%B9%B6%E4%B8%94%E5%90%8C%E6%AD%A5%E5%88%B0%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98/"},{"title":"利用人工智能预测双色球","text":"google开发的tensorflow机器学习框架目前应该是人工智能开发的第一框架,不论从框架的设计,开源环境,还是商业化应用方面都是有着很好的体现.虽然前端暂时和人工智能没啥太大关系,不过科技发展这么快也没准.俗话说得好,梦想是要有的,万一实现了呢? 总的来说双色球的预测无非就是已经有了一堆数字(每一期的开奖结果)要找出一种规律然后计算出下一次的一组数字.这个规律由计算机去找,我们需要做的就是告诉电脑找规律的方向. 准备 index.html用作展示. shuangseqiu.js写代码 开始index.html随便布个局给一些样式. 没有用任何脚手架,所以直接在html里引入需要的js 12345678&lt;!--为了展示方便引入了vue--&gt;&lt;script src=&quot;https://cdn.bootcss.com/vue/2.5.17-beta.0/vue.min.js&quot;&gt;&lt;/script&gt;&lt;!--引入axios调用彩票接口--&gt;&lt;script src=&quot;https://cdn.bootcss.com/axios/0.18.0/axios.min.js&quot;&gt;&lt;/script&gt;&lt;!--引入tensorflow框架--&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/@tensorflow/tfjs&quot;&gt;&lt;/script&gt;&lt;!--引入自己写的js--&gt;&lt;script src=&quot;shuangseqiu.js&quot;&gt;&lt;/script&gt; shuangseqiu.js 首先准备双色球数据 123456789101112131415161718const data = [ { data: 2018088, value: [[4,10,25,26,30,33], [6]] }, { data: 2018086, value: [[2,7,17,21,23,26], [16]] }, { data: 2018087, value: [[1,5,10,16,18,31], [3]] }, { data: 2018088, value: [[3,5,12,29,30,32], [14]] }]; 或者调用现有接口并把数据格式处理一下 12345678910111213141516171819202122232425262728axios.get('https://bird.ioliu.cn/v1?url=http://f.apiplus.net/ssq-20.json') //由于我的博客是全站https,所以需要把http转https .then(res =&gt; { //拿到数据后把数据格式处理成想要的格式 let tmp = []; for (let i = 0, len = res.data.data.length; i &lt; len; i++) { let [red, blue] = [[], []]; let redTmp = res.data.data[i].opencode.match(/(\\S*)\\+/)[1].split(','); for (let j = 0, jlen = redTmp.length; j &lt; jlen; j++) { red.push(parseInt(redTmp[j])); } ; blue.push(parseInt(res.data.data[i].opencode.match(/\\+(\\S*)/)[1])); tmp.push({ data: res.data.data[i].expect, value: [red, blue] }); } ; //赋值给vue that.items = tmp; //调用forecast方法预测 that.forecast(); }) .catch(err =&gt; { alert('请求过快,请10秒后重试!'); console.log(`错误信息${err}`); }); 定义初始化数据 12345678910data: { //历史数据 items: [], //红球 redBalls: [0, 0, 0, 0, 0, 0], //蓝球 blueBalls: [0], //预测所使用的时间 useTime: 0} 定义formatData方法格式化数据 1234567891011121314151617181920212223242526272829formatData() { //格式化数据 let x = []; let y = []; let used = []; this.items.map((res, index) =&gt; { if (index !== 0) { let b = [...res.value[0], ...res.value[1]]; y.push(b); } else { let b = [...res.value[0], ...res.value[1]]; used.push(b); } ; if (index !== this.items.length - 1) { let b = [...res.value[0], ...res.value[1]]; x.push(b); } else { let b = [...res.value[0], ...res.value[1]]; used.push(b); } ; }); return { use: used, input: x, output: y };} 定义forecast方法用于预测 12345forecast() { //保存开始时间 const start = new Date().getTime(); 预测...} 在forecast方法里首先定义线性衰退模型 1let model = tf.sequential(); add方法添加一个图层实例,tf.layers.dense 创建一个输入输出维度为7的层 1model.add(tf.layers.dense({units: 7, inputShape: [7]})); 指定损失函数和优化器 1model.compile({loss: &quot;meanSquaredError&quot;, optimizer: &quot;sgd&quot;}); 格式化数据 1let r = this.formatData(); 输入,输出数据 1let [x,y]=[tf.tensor(r.input),tf.tensor(r.output)]; 训练模型 1model.fit(x, y); 张量 1let u = tf.tensor(r.use); 开始预测 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647model.predict(u).data().then(res =&gt; { res.map((ball, index) =&gt; { if (index &lt; 6) { // 限制红球结果 let balls = Math.abs(parseInt(ball)); if (balls === 0) { balls = 1; } ; if (balls &gt; 35) { balls = 35; } ; this.redBalls[index] = balls; } else { // 限制蓝球结果 let balls = Math.abs(parseInt(ball)); if (balls === 0) { balls = 1; } ; if (balls &gt; 16) { balls = 16; } ; this.blueBalls[0] = balls; } ; }); //定义一个set const tmp = new Set(this.redBalls); //判断是否有重复项,如果有就重新预测 if ([...tmp].length &lt; 6) { this.forecast(); return false; } ; //红球从小到大排序 this.redBalls.sort((a, b) =&gt; { return a &gt; b; }); //预测结束 //保存结束时间 const end = new Date().getTime(); //计算所用时间 this.useTime = end - start;}); 最后在页面中查看结果 完整代码 参考链接:TensorFlow.js · 起手式","link":"/2019/03/06/%E5%88%A9%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A2%84%E6%B5%8B%E5%8F%8C%E8%89%B2%E7%90%83/"},{"title":"利用手中的计算机或其他计算设备帮助新冠肺炎的研究","text":"​ 转眼已经20年底了，还有几天就到21年了。新的一年马上就要到了，但是病毒还在肆虐，国外大爆发，国内也时不时有新增病例，前几天看新闻病毒又变种了，也不知道什么时候才会结束。最近看到了一个项目：Fold for Covid，这是一个使用笔记本电脑，Raspberry Pi或其他备用计算机帮助应对COVID-19大流行的开源项目。项目名称叫rosetta-at-home。 Fold for Covid 是做什么的？​ Fold for Covid项目旨在通过几个简单的步骤轻松捐赠多余的计算能力来支持COVID-19研究。这项工作为华盛顿大学贝克实验室领导的Rosetta @ Home项目做出了贡献，该项目使用分布式计算来帮助科学家和医生寻找COVID-19的潜在治疗方法。 ​ 您的贡献有助于研究人员寻找与COVID-19上著名的spike蛋白结合的蛋白。通过发现这些结合蛋白，医生希望开发出能够阻止病毒进入健康细胞的药物。 ​ 说白了就是用手中闲置或愿意捐献的算力来帮助科学家和医生。这个项目可以运行在主流开发板，笔记本以及台式计算机上，提供镜像版和软件版。目前在全世界已经有6,760个设备在提供算力。 ​ 放大地图来看在国内也有很多人贡献了。 ​ 那么现在我们也来贡献一份力吧。 使用树莓派搭建​ 在这比较推荐使用树莓派或者其他开发板来运行，因为功耗低还可以7*24不间断的运行。 ​ 首先点击右上角的Get Started或者直接滚动到下面来下载镜像。如果是使用网线的直接点击Download balenaOS按钮来下载就可以。如果是使用无线的话就把开关拨到Wifi + Ethernet，并且在输入框中输入你wifi的账号密码，我的设备是由无线来连接网络的，所以在这输入无线的账号密码然后点击Download balenaOS下载镜像。 ​ 官方教程中是使用balenaEtcher来写入镜像，但是不知道什么原因在我写入镜像的过程中一直失败，安装版和便携版都是。。。所以在这我使用的是win32diskimager。两个软件使用过程基本一样，选择上一步下载解压出来的镜像写入到你的设备中就可以了。写入完成后开启机器，在路由器的管理面板中找到名为foldforcovid的设备，看一下对应的ip地址。 ​ 然后在浏览器中直接访问就可以看到了。如果出现连接失败就等一下，开机需要初始化。同样也可以直接连接显示器，这样就能看到项目的GUI了。 ​ 在管理页面中可以看到被分配的任务和状态，可以使用鼠标和键盘来操作任务的开始暂停和其他操作。 软件版的使用​ 如果没有开发板也想贡献一份力的话就可以直接下载软件版的，笔记本电脑也可以直接使用镜像来运行，镜像支持x86的架构，安装方式和树莓派的相同在这就不赘述了。 ​ 切换tab到Main Computer的选项下载BOINC来运行本项目。直接点击Download按钮下载后一直下一步就安装可以了。下载的时候有虚拟机版本的可选，经过我的测试软件版的会跑满CPU，如果想要使用电脑进行其他操作的话也可以下载虚拟机版本的，分配一些核心在后台跑就可以了。 ​ 安装完成后打开软件，选择rosetta-at-home这个项目，之后下一步来创建项目。 ​ 项目创建成功后需要等待加载列表和创建任务，如果网络不好可以尝试挂代理，软件支持http和socks5代理。等待任务创建成功后就可以看到任务的详情了： ​ 可以看到台式机的算例还是比树莓派强太多了，在任务命令里可以看到训练的模型，虽然看不懂0.0。 总结​ 自从做了开发，对阿波罗登月的指令模块以及登月模块进行过code review。部署过SpaceX 的火箭以及发射台系统。现在又参与了华盛顿大学贝克实验室对新冠肺炎的研究。以后出去别人问我是干什么的我就说： ​ 大家好，我是来自于GDG Hangzhou的成员，曾经对跨世纪登月计划进行过审核，部署过火箭数据管理系统，参加全球新冠肺炎研究并对其进行过贡献。想想996都有劲了。","link":"/2020/12/23/%E5%88%A9%E7%94%A8%E6%89%8B%E4%B8%AD%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%88%96%E5%85%B6%E4%BB%96%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87%E5%B8%AE%E5%8A%A9%E6%96%B0%E5%86%A0%E8%82%BA%E7%82%8E%E7%9A%84%E7%A0%94%E7%A9%B6/"},{"title":"利用现代浏览器所提供的强大 API 录制，回放并保存任意 web 界面中的用户操作","text":"在开发测试阶段作为开发人员你永远不知道你的测试和产品有什么沙雕操作，他们只会说 xxx 页面/功能有 bug。想要复现也很难。前段时间正好看到了rrweb这个项目，索性基于它实现了定时间隔录制、主动上报、存入数据库、统一查看等功能，可以再项目开发时引入，再也不怕 bug 复现了。 走过路过先来波 start项目地址 实测在windows下安装最新的MySQL8.0会报错，重置密码也不行，原因不明，解决办法是安装MySQL 5.7.25。MAC OS下安装最新版没有问题。 ✨ 特性 录制并回放任意 web 界面中的用户操作 前端封装+后端。 开箱即用。 支持跨域。 🖥 支持环境 Linux,MacOS,Windows。 现代浏览器和 IE11 及以上。 Electron 💽 后端架构 基于NodeJS 数据库使用MySQL 服务框架使用express4 💻 前端架构 录制基于rrweb http请求默认依赖axios可配置为jQuery以及任何与jQuery结构相同的库 回放页面前端框架使用VUE UI框架使用Element 回放基于rrewb-player 📦 安装 安装MySQL并配置./server/mysql.config里的端口号及用户密码 安装NodeJS 进入项目目录 安装依赖 1npm i #国内使用cnpm 启动项目 1node server operationRecord.js 参数 123456789101112131415161718const record = new Record({ url: &quot;/operationRecord/add&quot;, //后台服务器url，如未修改服务器文件，应为：服务端ip+/operationRecord/add name: &quot;不知名的测试人员&quot;, //提交人，会显示在统计页面。默认：unknow projectName: &quot;test&quot;, //需要连接的表名 ajaxFn: $, //ajax 提交函数，默认依赖axios，如果项目中使用的是jquery直接写$,可以使用人和和jquery结构一致的ajax库 msg: &quot;你这东西有bug啊&quot;, //提交bug信息，最多255 isReport: &quot;1&quot;, //是否认为上报，1：是，0：否。默认：0 interval: &quot;2000&quot;, //提交间隔，默认10秒，单位ms success: function(res) { console.log(`成功的回调${res}`); }, error: function(err) { console.log(`失败的回调${err}`); }});//方法record.destroy(); //销毁console.log(record); //查看属性 🔨 示例123456789101112131415161718192021222324252627282930&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot; /&gt; &lt;title&gt;test&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;test&lt;/h1&gt; &lt;input type=&quot;text&quot; /&gt; &lt;button&gt;测试&lt;/button&gt; &lt;button&gt;回放&lt;/button&gt; &lt;script src=&quot;./js/axios.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;./js/operationRecord.js&quot;&gt;&lt;/script&gt; &lt;script&gt; let a = new Record({ url: &quot;ip地址+/operationRecord/add&quot;, name: &quot;liu&quot;, projectName: &quot;testProject&quot;, msg: &quot;测试信息&quot;, interval: 20000, success: function(res) { console.log(res); } }); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 打开http://localhost:9527/查看结果 📖 目录结构12345678910111213141516171819202122232425262728293031├── .git├── .gitignore├── README.md├── datas // 录制数据储存目录├── node_modules├── package.json├── public // 静态文件目录├── ├── .DS_Store├── ├── css // css文件├── ├── ├── element.min.css├── ├── ├── fonts // 字体文件├── ├── ├── ├── element-icons.ttf├── ├── ├── ├── element-icons.woff├── ├── ├── player.min.css├── ├── ├── reset.min.css├── ├── ├── style.css // 自定义样式├── ├── index.html├── ├── js // js文件├── ├── ├── axios.min.js├── ├── ├── element.min.js├── ├── ├── operationRecord.js├── ├── ├── player.min.js├── ├── ├── replay.js├── ├── ├── vue.js├── ├── replayer.html├── readme.js├── server // 服务器文件├── ├── local-zh.config // 表名中英文对应├── ├── mysql.config // mysql配置文件├── ├── mysql.js // mysql操作├── server.js // server 🤝 参与共建 提交 pr 提交 issue","link":"/2019/01/29/%E5%88%A9%E7%94%A8%E7%8E%B0%E4%BB%A3%E6%B5%8F%E8%A7%88%E5%99%A8%E6%89%80%E6%8F%90%E4%BE%9B%E7%9A%84%E5%BC%BA%E5%A4%A7%20API%20%E5%BD%95%E5%88%B6%EF%BC%8C%E5%9B%9E%E6%94%BE%E5%B9%B6%E4%BF%9D%E5%AD%98%E4%BB%BB%E6%84%8F%20web%20%E7%95%8C%E9%9D%A2%E4%B8%AD%E7%9A%84%E7%94%A8%E6%88%B7%E6%93%8D%E4%BD%9C/"},{"title":"听说要干掉node.js？用Deno实现价值上亿的AI核心算法试一下","text":"Deno他来了来了，他带着成吨的知识走来了 Deno的1.0版本出来以后可以预见一大波的： 学不动了 再不学就被淘汰了 Deno的xx实现原理 PHP最牛逼 …… 创造Deno的原因​ Deno 是 Ryan Dahl 在2017年创立的。这位巨佬同时也是 Node.js 的创始人，从2007年一直到2012年，他后来把 Node.js 移交给了其他开发者之后，就跑去搞研究人工智能了。但是相传他不是很喜欢 Python，所以时间久了就想搞一个 JavaScript 的人工智能开发框架。等到他再回过头捡起 Node.js，发现这个项目已经背离了他的初衷，有一些无法忽视的问题。 ​ 巨佬的说法是： But why!? Isn’t this exactly what Node does?JavaScript &amp; the web have changed significantly since Node was designed in 2009: Promises. async functions Async iterators/generatos ES Modules Typed ArraysNode has problems: Problems with its module system. with centralized distribution Lots of legacy APIs that must be supported No security model An explosion of tooling (grunt, gulp, webpack, babel, parcel, typescript, is-node, …) ​ 简单来说ES6 标准引入了大量新的语法特性。其中，影响最大的语法有两个：Promise 接口（以及 async 函数）和 ES 模块。Node.js 对这两个新语法的支持，都不理想。由于历史原因，Node.js 必须支持回调函数（callback），导致异步接口会有 Promise 和回调函数两种写法；同时，Node.js 自己的模块格式 CommonJS 与 ES 模块不兼容，导致迟迟无法完全支持 ES 模块。 ​ 其次就是众所周知的npm问题:) ​ 再次，Node.js 的功能也不完整，导致外部工具层出不穷，初始化一个项目先来一吨依赖：webpack，babel，typescript、eslint、prettier…… ​ 由于上面这些原因，巨佬决定放弃 Node.js，从头写一个替代品，彻底解决这些问题。deno 这个名字就是来自 Node 的字母重新组合，表示”拆除 Node.js“（de = destroy, no = Node.js）。 ##### 根据[官网](https://deno.land/)的说明： ​ Deno是使用V8并内置于Rust的JavaScript和TypeScript的简单，现代且安全的运行时。 默认为安全。除非明确启用，否则没有文件，网络或环境访问权限。 开箱即用地支持TypeScript。 仅发送一个可执行文件。 具有内置的实用程序，例如依赖项检查器（deno info）和代码格式化程序（deno fmt）。 拥有一组保证能与Deno一起使用的经过审查（审核）的标准模块：deno.land/std 安装​ Deno与Node.js不同的是Deno只有一个可执行文件，所有操作都通过这个文件完成，同时也是跨平台的。所以可以直接在GitHub release上下载对系统的二进制文件或利用官方提供的脚本进行下载安装： 使用 PowerShell: 1iwr https://deno.land/x/install/install.ps1 -useb | iex 使用 Chocolatey: 1choco install deno 使用 Scoop: 1scoop install deno 注意 ​ Deno 具有安全控制，默认情况下脚本不具有读写权限。如果脚本未授权，就读写文件系统或网络，会报错。必须使用参数，显式打开权限才可以。 ​ Deno 只支持 ES 模块，跟浏览器的模块加载规则一致。没有 npm，没有 npm_modules 目录，没有require()命令（即不支持 CommonJS 模块），也不需要package.json文件。 ​ 所有模块通过 URL 加载，比如import { bar } from &quot;https://foo.com/bar.ts&quot;（绝对 URL）或import { bar } from './foo/bar.ts'（相对 URL）。因此，Deno 不需要一个中心化的模块储存系统，可以从任何地方加载模块。 ​ 但是，Deno 下载模块以后，依然会有一个总的目录，在本地缓存模块，因此可以离线使用。 ​ 首先可以尝试官方的Hello world： 1deno run https://deno.land/std/examples/welcome.ts 会输出：Welcome to Deno 🦕 尝试创建一个简单的http server： 新建hello world.ts ，写入内容： 123456import { serve } from &quot;https://deno.land/std@0.50.0/http/server.ts&quot;;const s = serve({ port: 1927 });console.log(&quot;http://localhost:1927/&quot;);for await (const req of s) { req.respond({ body: &quot;Hello World\\n&quot; });} 如果直接像node一样去执行： 1deno run .\\welcome.ts 那么会得到一个错误： 1234567error: Uncaught PermissionDenied: network access to &quot;0.0.0.0:1927&quot;, run again with the --allow-net flag at unwrapResponse ($deno$/ops/dispatch_json.ts:43:11) at Object.sendSync ($deno$/ops/dispatch_json.ts:72:10) at Object.listen ($deno$/ops/net.ts:51:10) at listen ($deno$/net.ts:152:22) at serve (https://deno.land/std@0.50.0/http/server.ts:261:20) at file:jiu bu gei ni kan 因为 Deno 的安全限制这里需要加上参数--allow-net允许脚本联网： 1deno run --allow-net .\\welcome.ts 打开http://localhost:1927/你会看到熟悉的Hello World! 利用Deno实现上亿的Ai算法​ 我知道你进来就是馋我的算法，以后靠这个融到资了别忘了请我喝冰阔落。 首先新建一个index.html作为展示用 内容： 123&lt;dl&gt;&lt;/dl&gt;&lt;textarea id=&quot;msg&quot; rows=&quot;10&quot;&gt;&lt;/textarea&gt;&lt;button&gt;发送&lt;/button&gt; 加上点样式是我对UI最后的倔强： 12345678910111213141516171819202122232425textarea,dl { width: 300px;}dl { height: 400px; border: 1px solid #000; overflow: hidden auto;}dd { margin-inline-start: 50%; background-color: #9eea6a; border: 1px solid #9eea6a;}dt { width: 50%; border: 1px solid #e7e7e7;}dd,dt { margin-top: 10px; margin-bottom: 10px; border-radius: 2px; padding: 0 3px;} 实现简单的逻辑： 点击发送与炒鸡AI进行对话 12345678910111213141516171819202122const msgDom = document.querySelector(&quot;#msg&quot;);const dl = document.querySelector(&quot;dl&quot;);document.querySelector(&quot;button&quot;).addEventListener(&quot;click&quot;, () =&gt; { const { value } = msgDom; const dd = document.createElement(&quot;dd&quot;); dd.innerText = value; dl.appendChild(dd); msgDom.value = &quot;&quot;; fetch(&quot;http://localhost:1927/ask&quot;, { method: &quot;post&quot;, headers: { &quot;Content-Type&quot;: &quot;application/json&quot;, }, body: JSON.stringify({ msg: value }), }) .then((res) =&gt; res.json()) .then((data) =&gt; { const dt = document.createElement(&quot;dt&quot;); dt.innerText = data.msg; dl.appendChild(dt); });}); 新建server.ts作为后端： 引入server和router 1import { Application, Router } from &quot;https://deno.land/x/oak/mod.ts&quot;; 设置编码格式： 1const decoder = new TextDecoder(&quot;utf-8&quot;); 读取index.html作为模板： 1const body = decoder.decode(await Deno.readFile(&quot;./index.html&quot;)); 在这可以看到Deno异步返回的都是Promise，并且允许在async外使用await。 新建服务： 12const app = new Application();const router = new Router(); 对于不同路由进行处理： 首页直接加载index.html 1234router .get(&quot;/&quot;, ({ response }) =&gt; { response.body = body; }) 实现价值上亿的自然语言处理： 1234567891011121314post(&quot;/ask&quot;, async ({ response, request }) =&gt; { const { value } = await request.body(); response.body = JSON.stringify({ msg: value.msg.replace(/(吗|我|？|\\?)/gi, (str: string) =&gt; { if (/(吗|么)/.test(str)) { return &quot;&quot;; } else if (/(？|\\?)/.test(str)) { return &quot;！&quot;; } else if (str === &quot;我&quot;) { return &quot;你&quot;; } }), });}); 应用路由并： 12app.use(router.routes());await app.listen(`localhost:1927`); 启动脚本： 在这注意，因为用到了读取文件的功能，所以需要显示的指定允许Deno读物文件，添加启动参数--allow-read 12# 允许网络以及文件读取权限deno run --allow-net --allow-read .\\server.ts 在页面中打开http://localhost:1927/查看效果： 个人感受​ 相对Node.js来讲作为前端使用起来没有太大区别，至于该不该使用Ryan Dahl 已经把主要的优缺点都讲了。其实最主要的问题就是生态可不可以建立起来，如果社区的生态建立出来了到时候不用也得用了。 ​ Deno本身是Ryan Dahl 想替代Python而制作的，希望JavaScript可以蚕食Python在AI的份额，切图仔摇身一变变成调参仔，想到自己以后有可能成为一名 人工智能开发工程师 真是吹牛逼都有劲了:)。","link":"/2020/05/14/%E5%90%AC%E8%AF%B4%E8%A6%81%E5%B9%B2%E6%8E%89node.js%EF%BC%9F%E7%94%A8Deno%E5%AE%9E%E7%8E%B0%E4%BB%B7%E5%80%BC%E4%B8%8A%E4%BA%BF%E7%9A%84AI%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95%E8%AF%95%E4%B8%80%E4%B8%8B/"},{"title":"周杰伦新歌《MOJITO》UHD4k【官方MV】","text":"不废话，直接放视频。 视频无法播放记得用现代浏览器~ 在线 4K，小水管不用试了。 在线观看以及下载地址： 放不了视频？你的浏览器太辣鸡了吧，赶紧换现代的浏览器。 下载地址： onedrive","link":"/2020/06/12/%E5%91%A8%E6%9D%B0%E4%BC%A6%E6%96%B0%E6%AD%8C%E3%80%8AMOJITO%E3%80%8BUHD4k%E3%80%90%E5%AE%98%E6%96%B9MV%E3%80%91/"},{"title":"基于frp或nps的远程遥控手机实现钉钉远程打卡","text":"​ 想要实现远程控制手机已知比较好的商业解决方案有Teamviewer和向日葵。不过价格对于我这种偶尔有需求的穷逼来讲确实不太合适。索性自己搭建一个。 ​ 对比网上的其他方案优点就是： 直接控制手机，不光可以钉钉打卡，所有手机的操作都可以做。 控制是基于adb的，不存在钉钉更新后插件失效的问题，也没有被检测的风险。 一次搭建永久使用，不需要更新。 用的都是10K+开源，不存在广告病毒之类的。 ADB是什么？ 全称Android Debug Bridge。安卓平台调试桥，是连接Android手机与PC端的桥梁，通过adb可以管理、操作模拟器和设备，如安装软件、查看设备软硬件参数、系统升级、运行shell命令等。 ​ 理想状态是手机直接控制手机，就像Teamviewer或向日葵那样，但是找了好几天也没看到有人做这个，无奈只能折中一下使用电脑来控制了。 ​ 经过研究方案有两种，一种需要远程设备（被控制端）连接电脑，第二种就是控制端是电脑。 基于frp的方案​ 基本原理就是控制端 （手机，电脑，开发板等终端）通过frp控制被控制端 （电脑，开发板等windows或linux系统的设备）然后被控制端通过adb来控制手机。 在服务器上搭建frp 首先下载frp，在release中找到对应自己系统的版本。 解压之后服务器需要的是frps和frps.ini，其他文件可以删掉了。 编辑frps.ini: 1234567891011[common]# 绑定端口，根据自己的情况修改bind_port = 7000# 管理面板的端口，根据自己的情况修改dashboard_port = 7500# 管理面板的用户名，起一个别人猜不到的dashboard_user = admin# 管理面板的密码dashboard_pwd = 123456# 自定义tokentoken = 123456 之后直接启动就可以了./frps -c ./frps.ini 在这我是用pm2来管理启动项： 1pm2 start -x './frps' -n frp -- -c ./frps.ini 配置frp客户端 还是下载对应系统的frp。我的客户端是win 10 x64的，所以下载frp_0.32.1_windows_amd64.zip 下载后解压，客户端需要的是frpc.exe和frpc.ini，其他不需要的可以删除了。 编辑配置文件frpc.ini： 12345678910111213141516[common]server_addr = 你的服务器ip# 上面配置的bind_portserver_port = 7000# 上面配置的自定义tokentoken=123456[给你的客户端起个名字，会显示在管理面板中]# 链接类型type = tcp# 本地iplocal_ip = 127.0.0.1# 内网穿透的本地端口，因为需要使用windows远程桌面，所以填默认的3389，如果你修改过mstsc的端口那就按照修改的填写local_port = 3389# 远程端口remote_port = 7003 配置好之后可以启动试试frpc.exe -c ./frpc.ini 可以写一个bat来一键启动： 1234chcp 65001@echo. ******点击右上角关闭按钮或连续两次Ctrl+C关闭******frpc.exe -c ./frpc.inipause 启动成功后可以试着用其他设备控制这台电脑，windows直接启动mstsc，手机下载RD Client。利用你的服务器ip和上面设置的远程端口（7003）微软自家东西的配套做的还是非常良心的，免费、好用： 连接成功后就可以使用电脑控制手机了。 在这下载scrcpy，这是一个开源免费在电脑显示手机画面并控制手机的工具 (投屏/录屏/免Root) 如果你只有一个设备，直接双击scrcpy.exe就可以开始控制了，如果有多个设备则执行一下 .\\adb.exe devices找到你的设备，之后.\\scrcpy.exe -s 设备ID就可控制了 到这一步就可以实现远程控制了，但是如果远程的电脑关机了就不行了。实现远程关机很简单，到网上随便买个智能插座，然后把bios设置成通电自动开机就可以了。 基于nps的方案​ 上面基于frp的方案需要远程有电脑，有的人可能不方便，基于nps的可以免除远程的电脑。 原理和frp一样，都是内网穿透，因为nps提供安卓版本的，所以可以直接使用。 nps是一款轻量级、高性能、功能强大的内网穿透代理服务器。目前支持tcp、udp流量转发，可支持任何tcp、udp上层协议（访问内网网站、本地支付接口调试、ssh访问、远程桌面，内网dns解析等等……），此外还支持内网http代理、内网socks5代理、p2p等，并带有功能强大的web管理端。 在服务器上搭建nps 根据你的系统下载nps 解压，执行sudo ./nps install来安装 nps默认配置文件使用了80，443，8080，8024端口 80与443端口为域名解析模式默认端口 8080为web管理访问端口 8024为网桥端口，用于客户端与服务器通信 服务器上肯定有其他项目，所以不能占用80和443等端口，在这修改nps.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182appname = nps#Boot mode(dev|pro)runmode = dev#HTTP(S) proxy port, no startup if emptyhttp_proxy_ip=0.0.0.0http_proxy_port=8001https_proxy_port=8443https_just_proxy=true#default https certificate settinghttps_default_cert_file=conf/server.pemhttps_default_key_file=conf/server.key##bridgebridge_type=tcpbridge_port=8024bridge_ip=0.0.0.0# Public password, which clients can use to connect to the server# After the connection, the server will be able to open relevant ports and parse related domain names according to its own configuration file.public_vkey=123#Traffic data persistence interval(minute)#Ignorance means no persistence#flow_store_interval=1# log level LevelEmergency-&gt;0 LevelAlert-&gt;1 LevelCritical-&gt;2 LevelError-&gt;3 LevelWarning-&gt;4 LevelNotice-&gt;5 LevelInformational-&gt;6 LevelDebug-&gt;7log_level=7#log_path=nps.log#Whether to restrict IP access, true or false or ignore#ip_limit=true#p2p#p2p_ip=127.0.0.1#p2p_port=6000#webweb_host=a.o.comweb_username=你的用户名web_password=你的密码web_port = 7501web_ip=0.0.0.0web_base_url=web_open_ssl=falseweb_cert_file=conf/server.pemweb_key_file=conf/server.key# if web under proxy use sub path. like http://host/nps need this.#web_base_url=/nps#Web API unauthenticated IP address(the len of auth_crypt_key must be 16)#Remove comments if needed#auth_key=testauth_crypt_key =1234567812345678#allow_ports=9001-9009,10001,11000-12000#Web management multi-user loginallow_user_login=falseallow_user_register=falseallow_user_change_username=false#extensionallow_flow_limit=falseallow_rate_limit=falseallow_tunnel_num_limit=falseallow_local_proxy=falseallow_connection_num_limit=falseallow_multi_ip=falsesystem_info_display=false#cachehttp_cache=falsehttp_cache_length=100#get origin iphttp_add_origin_header=false#pprof debug options#pprof_ip=0.0.0.0#pprof_port=9999 启动nps sudo nps start。 然后访问http://你的ip:7501/，看到管理界面就是成功了。 然后再面板上新增一个客户端，之后在TCP隧道中配置内网穿透： 模式：TCP隧道 服务端端口：7111（根据自己情况填写） 目标 (IP:端口)：5555 （adb的远程调试端口） 之后安装安卓版的nps，填写你的服务器ip:端口和刚才配置的唯一验证密钥 之后在你的控制端（比如你家里的电脑）打开scrcpy，执行： 1.\\scrcpy.exe -s 服务器IP:7004 现在你就可以成功在家控制在单位的手机了。 这种方案免除了被控制端的电脑，也就是被控制端（比如单位）只有一部手机就可以了，而且也不需要买智能插座了。 缺点就是软件是直接运行在手机上的，某些系统会自动把进程杀掉，如果后台被清理了那就没办法了。 总结​ frp的方案是远程控制你的电脑，然后通过远程的电脑控制远程的手机。控制端可以使电脑，手机等各种设备。 ​ nps是直接控制远程的手机，但是控制端只能是电脑，而且被控制端可能存在杀后台等情况。 ​ 两种方法各有利弊，大家可以根据自己的情况进行选择。","link":"/2020/04/24/%E5%9F%BA%E4%BA%8Efrp%E6%88%96nps%E7%9A%84%E8%BF%9C%E7%A8%8B%E6%89%8B%E6%9C%BA%E9%81%A5%E6%8E%A7/"},{"title":"小心你的数据！我在谷歌搜到了我的账号密码！解决方法之Bitwarden_rs搭建教程","text":"密码泄露 之前一直听说有各种沙雕公司明文储存你的账号密码，前几年还没当回事，但是现在各种网站，App都要求注册，数据也越来越重要。作为一个网络人一直用的是一个密码肯定不安全，而且在TG的社工机器人那查到了我的所有个人信息，包括密码这种敏感数据。同样今天我在谷歌成功搜到了我的账号密码，你没看错，我在搜索引擎中搜到了我的账号密码。 虽然给数据泄露的公司发了邮件，他们处理也很快，但是泄露都不知道是什么时候的事了，而且对于其中QQ邮箱的尝试登陆了几个试试，确实有的账号密码是正确的。 所有网站使用同一个密码就意味着但凡有任何一个网站被脱裤，那么黑客就可以拿着账号密码登陆任何没有二次验证的网站。于是为了解决这个问题就有了这篇教程。 解决方案 每一个网站都生成独一无二的密码，网站+特定密码，比如优酷设置密码yk123456，微博设置wb123456。但是这么做第一比较容易破解，第二比较容易忘，比如建设银行的密码就可以有好几种写法jsyh123456,jh123456,js123456，容易把自己搞混。 那么第二种解决方案就是软件生成随机的密码，让软件帮忙自动填入。现在的现代手机和浏览器都支持自动填充账号密码，那么需要解决的就是用哪款软件。市面上的这种软件有很多，经过筛选最后剩下两种： 1Password Bitwarden 1Password 商业化的软件保证稳定性，公司成立时间长有优秀的解决方案，界面好看，使用方便。唯一的缺点就是贵，虽然有利用家庭订购合购钻漏洞的，但是这种方案相当于把密码从可信任的公司交给了个人，省着点钱简直就是本末倒置。那么想我这种穷B就只能用第二种方案了。 Bitwarden Bitwarden是一个开源的，全平台的密码管理解决方案。并且支持私有部署。功能上完全可以满足需求。 搭建教程 Bitwarden本身是由.NET Core 3.1 SDK开发的，并且使用SQL Server 2017，这就导致了对服务器的要求有些高，后来发现了bitwarden_rs： 这是一个用Rust编写的Bitwarden服务器API实现，与Bitwarden客户端兼容。 Bitwarden_rs相对于官方版本对服务器的要求要底，但是对于大量用户来讲没有官方版的好。由于就是几个人用，所以在这我们使用的是bitwarden_rs。 安装Docker和Docker Compose，网上教程太多了，就不在这赘述了。 首先新建一个目录用来存放Bitwarden的数据 1mkdir /你的路径/bitwarden &amp;&amp; cd /你的路径/bitwarden 新建配置文件： 1sudo nano config.env 并写入配置： 12345SIGNUPS_ALLOWED=trueINVITATIONS_ALLOWED=trueDATABASE_URL=/data/bitwarden.dbROCKET_WORKERS=10WEB_VAULT_ENABLED=true 配置文件： SIGNUPS_ALLOWED 是否允许注册，在这我们先允许不然一会不能新建第一个用户。 INVITATIONS_ALLOWED 是否允许邀请注册。 DATABASE_URL 数据库地址，相对于配置文件的目录。 ROCKET_WORKERS 设置服务器使用几个线程。10 是默认值，你可以根据机器性能和个人需求适当调整。 WEB_VAULT_ENABLED 设置是否开启 Web 客户端。如果开启，可以通过访问你的域名来打开 Web 客户端，用户登录后即可通过网页管理密码。 然后新建docker的描述文件： 1sudo nano docker-compose.yml 写入配置文件： 12345678910111213version: '3'services: bitwarden: image: mprasil/bitwarden:latest container_name: bitwarden restart: always volumes: - ./data:/data env_file: - config.env ports: - &quot;映射的端口:80&quot; 配置文件准备好后配置nginx反向代理到http://localhost:映射的端口。 启动服务： 1docker-compose up -d 启动成功后在浏览器中打开你的地址就可以访问到Bitwarden的web端。在页面中注册好账号后就可以使用了。如果你之前用过其他的密码管理工具Bitwarden同样支持导入。Bitwarden支持的格式基本覆盖了所有密码管理工具： 支持格式 - Bitwarden (json) - Bitwarden (csv) - LastPass (csv) - Chrome (csv) - Firefox (csv) - KeePass 2 (xml) - 1Password (1pif) - Dashlane (json) - 1Password 6 and 7 Windows (csv) - Ascendo DataVault (csv) - Avast Passwords (csv) - Avira (csv) - Blur (csv) - Clipperz (html) - Enpass (csv) - Enpass (json) - F-Secure KEY (fsk) - GNOME Passwords and Keys/Seahorse (json) - Kaspersky Password Manager (txt) - KeePassX (csv) - Keeper (csv) - Meldium (csv) - mSecure (csv) - Myki (csv) - Opera (csv) - Padlock (csv) - Passbolt (csv) - PassKeep (csv) - Passman (json) - Passpack (csv) - Password Agent (csv) - Password Boss (json) - Password Dragon (xml) - Password Safe (xml) - PasswordWallet (txt) - RememBear (csv) - RoboForm (csv) - SafeInCloud (xml) - SaferPass (csv) - SplashID (csv) - Sticky Password (xml) - True Key (csv) - Universal Password Manager (csv) - Vivaldi (csv) - Zoho Vault (csv) 注册成功后关闭用户注册： 在配置文件中把SIGNUPS_ALLOWED设置为false。 然后删除并重建容器，因为映射了数据库所以数据不会被删除： 1docker-compose down &amp;&amp; docker-compose up -d 到此为止服务端就搭建完成了，在设备上下载软件后在设置中填入你的服务器地址，用刚才注册的账号密码注册就可以开始使用了。 总结 密码的保护现在尤为重要，大家一定要保护好自己的账号密码。对于没有能力搭建的同学可以找一个会搭建的然后大家一起用，或者直接使用1password。至于其他免费的软件，只需要记住一句话免费的永远都是最贵的！。","link":"/2020/05/22/%E5%B0%8F%E5%BF%83%E4%BD%A0%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%81%E6%88%91%E5%9C%A8%E8%B0%B7%E6%AD%8C%E6%90%9C%E5%88%B0%E4%BA%86%E6%88%91%E7%9A%84%E8%B4%A6%E5%8F%B7%E5%AF%86%E7%A0%81%EF%BC%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E4%B9%8BBitwarden_rs%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"},{"title":"开源一个可扩展的WebGL图片切换组件","text":"在线预览 github地址 参数： el[DOM]:绑定的DOM元素，默认是body。 images[Array]:需要切换的图片地址的数组，两张。 width[Number]：宽。 height[Number]：高。 transImg[String]:切换效果的图片url，默认是一张大理石效果的图片。 vertexSrc,ragmentSrc[String]:包含GLSL程序代码的字符串。 方法： on() 变化图片为第二张。 off()变化图片为第一张。 toggle()切换图片。 onComplete()动画结束时的回调。 示例： HTML: 1234567&lt;ul&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt;&lt;/ul&gt;&lt;script src=&quot;./js/TweenMax.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;./js/gltrans.js&quot;&gt;&lt;/script&gt; javascript: 123456789101112131415161718192021222324let els = document.querySelectorAll('li');let arr = [];for (let i = 0, len = els.length; i &lt; len; i++) { let test = new GLTransition({ el: els[i], images: [ './assets/1.jpg', './assets/2.jpg',], width: 1024, height: 512, }); test.GLTrans(); els[i].querySelector('canvas').addEventListener('click', function (params) { //切换 test.toggle(); }); els[i].querySelector('canvas').addEventListener('mouseenter', function (params) { test.on(); }); els[i].querySelector('canvas').addEventListener('mouseleave', function (params) { test.off(); });};","link":"/2018/05/20/%E5%BC%80%E6%BA%90%E4%B8%80%E4%B8%AA%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84WebGL%E5%9B%BE%E7%89%87%E5%88%87%E6%8D%A2%E7%BB%84%E4%BB%B6/"},{"title":"利用函数的惰性载入提高javascript代码性能","text":"假装有个需求我们现在需要写一个 foo 函数，这个函数返回首次调用时的 Date 对象，注意是首次。 普通方法123456var t;function foo() { if (t) return t; t = new Date() return t;} 问题有两个，一是污染了全局变量，二是每次调用 foo 的时候都需要进行一次判断。 首先解决污染全局变量的问题 闭包12345678var foo = (function() { var t; return function() { if (t) return t; t = new Date(); return t; }})(); 函数对象123456//函数也是一种对象，利用这个特性，我们也可以解决这个问题。function foo() { if (foo.t) return foo.t; foo.t = new Date(); return foo.t;} 不过依旧没有解决调用时都必须进行一次判断的问题。 解决的方案就是称之为惰性载入的技巧。​ 所谓惰性载入，就是说函数的if分支只会执行一次，之后调用函数时，直接进入所支持的分支代码。 有两种实现惰性载入的方式，第一种事函数在第一次调用时，对函数本身进行二次处理，该函数会被覆盖为符合分支条件的函数，这样对原函数的调用就不用再经过执行的分支了， 我们可以用下面的方式使用惰性载入重写 foo(). 1234567var foo = function() { var t = new Date(); foo = function() { return t; }; return foo();}; 常见应用举例在DOM 事件添加中，为了兼容现代浏览器和万恶的 IE 浏览器，我们需要对浏览器环境进行一次判断： 12345678function addEvent (type, el, fn) { if (window.addEventListener) { el.addEventListener(type, fn, false); } else if(window.attachEvent){ el.attachEvent('on' + type, fn); }} ​ 每次调用 addEvent 函数的时候，它都要对浏览器所支持的能力进行检查，首先检查是否支持 addEventListener 方法，如果不支持，再检查是否支持 attachEvent 方法。 这个过程在 addEvent 函数每次调用的时候都要走一遍，其实，如果浏览器支持其中的一种方法，那么他就会一直支持了，就没有必要再进行其他分支的检测了， 也就是说，if 语句不必每次都执行，代码可以运行的更快一些。 123456789101112function addEvent (type, el, fn) { if (window.addEventListener) { addEvent = function (type, el, fn) { el.addEventListener(type, fn, false); } } else if(window.attachEvent){ addEvent = function (type, el, fn) { el.attachEvent('on' + type, fn); } }} ​ 在这个惰性载入的 addEvent() 中，if 语句的每个分支都会为 addEvent 变量赋值，有效覆盖了原函数。 最后一步便是调用了新赋函数。下一次调用 addEvent() 的时候，便会直接调用新赋值的函数，这样就不用再执行 if 语句了。 ​ 上面这种方法会在函数第一次调用时损失一点性能,有可能造成用户第一次使用功能时产生卡顿.使用闭包可以解决这个问题. 123456789101112var addEvent = (function(){ if (window.addEventListener) { return function (type, el, fn) { el.addEventListener(type, fn, false); } } else if(window.attachEvent){ return function (type, el, fn) { el.attachEvent('on' + type, fn); } }})(); ​ 虽然利用闭包在第一次调用函数时就不会损失性能了，但是会在代码加载时会损失一点性能。所以只能具体情况具体分析了.","link":"/2016/10/05/%E6%83%B0%E6%80%A7%E5%87%BD%E6%95%B0/"},{"title":"批量爬取哈勃望远镜在生日当天拍摄的宇宙照片","text":"​ NASA公布了2019年哈勃望远镜每一天拍摄的宇宙照片（除了2月29日），由于网站在国外，而且有一些图片的清晰度不够高，所以利用爬虫爬取所有图片并且通过AI修复为 6X。 5.31 9.21 2.19 3.27 不想看技术相关的直接拉到最下面查看下载地址。 ​ 首先分析地址找到了data.csv，所有图片的地址都在里面。那么第一步提取其中的地址： 读取文件123const rl = readline.createInterface({ input: fs.createReadStream(path.join(__dirname, &quot;./data.csv&quot;)),}); 格式化地址123456789101112rl.on(&quot;line&quot;, (line) =&gt; { const res = line.split(&quot;,&quot;); const len = res.length; const date = new Date(res[0]); list.push({ name: `${date.getFullYear()}-${date.getMonth() + 1}-${date.getDate()}`, title: res[2], shootingDate: res[len - 1], url: `https://imagine.gsfc.nasa.gov/hst_bday/images/${res[1]}`, directions: res.slice(3, len - 2).join(&quot; &quot;), });}); 地址格式化之后按照时间排一下顺序，然后下载就可以了123456789101112131415rl.on(&quot;close&quot;, function () { list.splice(0, 1); list.sort((t1) =&gt; (t2) =&gt; new Date(t1).getTime() - new Date(t2).getTime()); fs.writeFileSync(path.join(__dirname, &quot;res.json&quot;), JSON.stringify(list)); const finishDownloadList = fs.readdirSync(path.join(__dirname, &quot;download&quot;)); list .filter((item) =&gt; !finishDownloadList.includes(item.name)) .forEach(async (item) =&gt; { console.log(item.name); console.log(item.url); await download(item.url, path.join(__dirname, &quot;download&quot;, item.name), { filename: `${item.name}-${item.title}${path.extname(item.url)}`, }); });}); 然后使用waifu2x-caffe进行图片的放大修复。在这我自定义添加后缀为-ai。经过长时间的运损后把已经生成的图片进行分类，一个日期的放到一个文件夹中12345678910111213141516files.forEach((file) =&gt; { const arr = file.split(&quot;-&quot;); const dir = arr.slice(0, 3).join(&quot;-&quot;); const name = arr.slice(3).join(&quot;_&quot;); const fileName = `${dir}_${name}`; fs.renameSync( path.resolve(__dirname, &quot;download&quot;, &quot;1&quot;, file), path.resolve(__dirname, &quot;download&quot;, &quot;1&quot;, fileName) ); const p = path.resolve(__dirname, &quot;download&quot;, dir); fs.ensureDirSync(p); fs.copyFileSync( path.resolve(__dirname, &quot;download&quot;, &quot;1&quot;, fileName), path.resolve(p, fileName) );}); ​ 这样我们就获取了NASA公布的生日当天哈勃望远镜拍摄的照片。 ​ 技术细节基本没人看，所以在这给大家提供现成的下载地址： 链接：https://pan.baidu.com/s/1lo__x7hqEydZKtsBZh9-HA 提取码：afum 压缩包解压密码均为：2077tech.com","link":"/2020/04/15/%E6%89%B9%E9%87%8F%E7%88%AC%E5%8F%96%E5%93%88%E5%8B%83%E6%9C%9B%E8%BF%9C%E9%95%9C%E5%9C%A8%E7%94%9F%E6%97%A5%E5%BD%93%E5%A4%A9%E6%8B%8D%E6%91%84%E7%9A%84%E5%AE%87%E5%AE%99%E7%85%A7%E7%89%87/"},{"title":"抛弃老旧的Powershell和祖传Cmder拥抱更现代的Windows Terminal（安装与美化）","text":"在2020年5月19日微软发布了Windows Terminal 1.0正式版。powershell也将在2022年12月3日终止维护。windows的终端一直都被人诟病，样式巨丑，命令和其他平台不统一等等。终于，微软在 announcement at Microsoft Build 2019上公布了全新开发的Windows Terminal，漂亮方便的同时还解决了开发方式存在差异的痛点。话不多说，先上效果图： 安装 安装方法很简单，在这提供两种安装方法： 直接打开电脑自带的Microsoft Store，然后搜索windows terminal安装即可。 当然由于某些未知原因，Microsoft Store总会显示无法连接，那么就可以在微软的GitHub Release里直接下载最新的安装包（xxx.msixbundle）。下载完成后直接双击安装就可以了。 启动 windows terminal安装后的启动文件为wt.exe，所以可以在运行、地址栏或者其他终端内直接输入wt就可以打开。 当然也可以把它加到右键菜单中方便使用： 首先新建一个文本文件，命名为xxx.reg，然后输入以下内容： 12345678Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\wt]@=&quot;Windows terminal here&quot;&quot;Icon&quot;=&quot;ico文件路径&quot;[HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\wt\\command]@=&quot;C:\\\\Users\\\\你的用户名\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\wt.exe&quot; @=&quot;Windows terminal here&quot;就是右键时显示的文字。 Icon就是右键菜单里的图标，可以在网上找一个喜欢的图标，或者可以直接使用我的图标。 最后需要注意的就是需要把你的用户名位置替换成你电脑的用户名。保存之后双击导入注册表就可以在右键菜单看到了。 右键菜单设置完以后有一个小问题就是默认打开的路径不是文件夹的路径，在这我们点击windows terminal的设置，会弹出一个json文件，在profiles.defaults中添加&quot;startingDirectory&quot;: &quot;.&quot;，如果你是使用vs code编辑的话会有自动提示。 美化 默认样式虽然比powershell好很多但是也比较普通，同样我们可以通过设置来定制自己的主题，比如添加透明度或者毛玻璃效果。 e.g. ： 1234567891011121314151617181920{ &quot;background&quot;: &quot;#282A36&quot;, &quot;black&quot;: &quot;#21222C&quot;, &quot;blue&quot;: &quot;#BD93F9&quot;, &quot;brightBlack&quot;: &quot;#6272A4&quot;, &quot;brightBlue&quot;: &quot;#D6ACFF&quot;, &quot;brightCyan&quot;: &quot;#A4FFFF&quot;, &quot;brightGreen&quot;: &quot;#69FF94&quot;, &quot;brightPurple&quot;: &quot;#FF92DF&quot;, &quot;brightRed&quot;: &quot;#FF6E6E&quot;, &quot;brightWhite&quot;: &quot;#FFFFFF&quot;, &quot;brightYellow&quot;: &quot;#FFFFA5&quot;, &quot;cyan&quot;: &quot;#8BE9FD&quot;, &quot;foreground&quot;: &quot;#F8F8F2&quot;, &quot;green&quot;: &quot;#50FA7B&quot;, &quot;purple&quot;: &quot;#FF79C6&quot;, &quot;red&quot;: &quot;#FF5555&quot;, &quot;white&quot;: &quot;#F8F8F2&quot;, &quot;yellow&quot;: &quot;#F1FA8C&quot;} 当然如果你跟我一样，对于UI只停留在好看不好看的层次上，那么自己设计主题肯定是不靠谱，好在有大神帮忙解决了问题。 首先打开主题网站，网站中提供了超多的现成主题进行选择，挑好之后直接点击COPY THEME，然后回到seetings.json，把复制的主题粘贴在schemes这个数组里，然后在profiles.defaults中添加colorScheme:你的主题名字即可。我使用的主题是Homebrew-Dark。配置文件为： 123456789101112131415161718192021{ &quot;name&quot;: &quot;Homebrew&quot;, &quot;black&quot;: &quot;#000000&quot;, &quot;red&quot;: &quot;#990000&quot;, &quot;green&quot;: &quot;#00a600&quot;, &quot;yellow&quot;: &quot;#999900&quot;, &quot;blue&quot;: &quot;#0000b2&quot;, &quot;purple&quot;: &quot;#b200b2&quot;, &quot;cyan&quot;: &quot;#00a6b2&quot;, &quot;white&quot;: &quot;#bfbfbf&quot;, &quot;brightBlack&quot;: &quot;#666666&quot;, &quot;brightRed&quot;: &quot;#e50000&quot;, &quot;brightGreen&quot;: &quot;#00d900&quot;, &quot;brightYellow&quot;: &quot;#e5e500&quot;, &quot;brightBlue&quot;: &quot;#0000ff&quot;, &quot;brightPurple&quot;: &quot;#e500e5&quot;, &quot;brightCyan&quot;: &quot;#00e5e5&quot;, &quot;brightWhite&quot;: &quot;#e5e5e5&quot;, &quot;background&quot;: &quot;#000000&quot;, &quot;foreground&quot;: &quot;#00ff00&quot;} 最后添加透明度和毛玻璃效果即可，同样是在profiles.defaults中添加&quot;acrylicOpacity&quot;: 0.7,&quot;useAcrylic&quot;: true,，保存即可生效。 安装模块 美化完成后就是功能的扩展了，想要把wt配置成on-my-zsh那样还需要安装几个扩展： 首先以管理员方式启动wt，然后安装posh-git： 1Install-Module posh-git -Scope CurrentUser 如果此前没有安装 NuGet 提供程序，则此时会提示安装 NuGet；如果此前没有开启执行任意脚本，此处也会提示执行脚本。如果没有权限执行脚本，可能需要先执行 Set-ExecutionPolicy Bypass。 安装 oh-my-posh 1Install-Module oh-my-posh -Scope CurrentUser 然后输入Import-Module oh-my-posh后发现tab自动补全等功能就可以使用了。 如果你退出wt再打开会发现功能消失了，必须再次import才可以，所以在终端中输入$profile ，每次启动wt的时候都会加载这个文件，所以直接在文件中添加Import-Module oh-my-posh即可。 最后安装需要的字体，下载解压后直接执行install.ps1会自动安装。然后在profiles.defaults中添加&quot;fontFace&quot;: &quot;Anonymous Pro for Powerline&quot;即可。 每次启动展示系统信息： 截图中的功能也是一个插件ScreenFetch 。 安装方式同上： 1Install-Module windows-screenfetch -Scope CurrentUser 选择Y或者A即可安装。 安装好后执行screenfetch，同样在profile 文件中添加命令，每次启动就都可以执行。 现在（2020.05.21）安装的screenfetch存在一个BUG，如果你的资源管理器中存在不可识别的盘符，那么会得到不能除0的报错，这个已经解决，但是没有发布，所以我们打开GitHub，把本地的Data.psm1内容替换为GitHub上的Data.psm1的内容即可。 总结 至此Windows Terminal安装美化完成，删除了祖传的Cmder还有点不舍呢。","link":"/2020/05/21/%E6%8A%9B%E5%BC%83%E8%80%81%E6%97%A7%E7%9A%84Powershell%E5%92%8C%E7%A5%96%E4%BC%A0Cmder%E6%8B%A5%E6%8A%B1%E6%9B%B4%E7%8E%B0%E4%BB%A3%E7%9A%84Windows%20Terminal%EF%BC%88%E5%AE%89%E8%A3%85%E4%B8%8E%E7%BE%8E%E5%8C%96%EF%BC%89/"},{"title":"掌控你的智能家居 - homeassistant详细搭建教程","text":"前言​ 作为专业的hello world工程师，新装修房子肯定是要整一套智能家居的。虽然小米的智能家居方案已经很不错了，但是也没法100%的满足需求。而且各个厂商都有自己的生态系统，小米的小爱同学对应的是米家，苹果的siri对应的是HomeKit。想用siri控制非HomeKit的设备显然不可以，HomeKit解决方案的价格也不是我这种傲（穷）骨（人）可以玩得转的，所以为了实现各个厂商的互通就有了home-assistant这个项目。 home-assistant 具体的介绍就不多说了，简单来讲home-assistant是一个智能设备平台，它可以调度上千种智能设备（截止到2020 08 11官方公布支持1622种），包括常见的米家，Amazon Alexa，Google Assistant，Google Cast，宜家等等，基本上覆盖了市面上所有常见的设备。具体列表可以在官网公布的支持列表中查看。 准备工作 后面简称home-assistant为hass 首先需要准备一个可以运行hass系统的硬件，hass基于python，所以支持windows,mac os和linux各种发行版。作为需要7x24运行的系统PC肯定不行了，功耗太高，所以在这使用树莓派作为基础平台。树莓派的特点在这就不多说了，本次我购买的是树莓派4B。 树莓派系统 树莓派本身有官方系统，不过网评一般，所以在这安装的是Ubuntu 20.04.1 LTS。之前找过一个Debian-Pi-Aarch64 ★ 全新树莓派64位系统。性能很不错，就是系统依赖会有问题。树莓派的性能太低了，做点啥时间太长，所以放弃折腾直接使用官方的Ubuntu 20.04。 系统的安装不多说了，下载镜像之后使用Win32DiskImager傻瓜式一键安装，唯一需要注意的是下载的系统是压缩包，记得把img镜像解压出来再安装。 连接WIFI 不得不说第三方优化的就是方便，上面的Debian-Pi-Aarch64配置wifi极为方便。ubuntu的坑就是按照官方文档来还是失败，而且网上的都是老版本的配置方法。 经过多次尝试总结了Ubuntu 20.04的WIFI配置方法： 安装完系统后先用有线连接你的路由器。 在路由器的管理界面找到树莓派的IP，如果你跟我一样安装的是ubuntu 20，那么路由器里的名称也应该叫ubuntu。 找到树莓派的IP后使用ssh登陆，初始用户名和密码都是ubuntu。首次登录后需要设置一个新密码，然后使用新密码重新登陆一下。 成功连接树莓派后就可以配置wifi了： 打开/etc/cloud/cloud.cfg.d/99-disable-network-config.cfg文件 1sudo nano /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg 把network: {config: disabled}写入到文件中，不用格式化。 创建/etc/netplan/01-netcfg.yaml文件并编辑： 1sudo nano /etc/netplan/01-netcfg.yaml 把wifi配置添加到上面的文件中： 12345678910network: version: 2 renderer: networkd wifis: wlan0: dhcp4: true optional: true access-points: &quot;你的wifi名称&quot;: password: &quot;wifi密码&quot; 在这需要注意，如果你连接的是5G wifi的话记得对应树莓派支持的信道和路由器的信道，否则是连接不上的。 应用配置并重启 123456# 如果配置有错误会在这一步提示出来sudo netplan generate# 这一步有可能会有systemctl的错误提示，忽略即可sudo netplan apply# 重启系统拔掉有线就连接上wifi了sudo reboot 环境配置 首先需要一些基础环境配置 切换apt的源为清华镜像：1sudo nano /etc/apt/sources.list 删除掉里面的所有内容，然后添加下面的内容： 12345678910111213# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse# 预发布软件源，不建议启用# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse 如果你跟我一样使用的是树莓派或者其他ARM架构的硬件则需要使用ubuntu-ports镜像，把地址替换为https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ 123456789# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-security main restricted universe multiverse 安装前置依赖 在这我们使用pyenv来管理Python，所以先安装一下前置依赖： 更新apt 1sudo apt update &amp;&amp; sudo apt upgrade 安装依赖 1sudo apt-get install -y gcc make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev 安装pyenv pyenv使您可以轻松地在多个版本的Python之间切换。它简单，简单，遵循UNIX的一站式工具传统。 可以按照官方的方法来手动安装，同时官方提供了一键安装脚本： 1curl https://pyenv.run | bash 一般会遇到ssl的问题，可以直接把脚本下载到本地来进行安装： 脚本地址：https://github.com/pyenv/pyenv-installer/raw/master/bin/pyenv-installer 运行： 1bash pyenv-installer.sh 不要使用sudo。滥用权限有可能导致一系列问题。 等待脚本执行完成后把环境变量添加到系统中： 1sudo nano ~/.bashrc 添加： 123export PATH=&quot;/home/ubuntu/.pyenv/bin:$PATH&quot;eval &quot;$(pyenv init -)&quot;eval &quot;$(pyenv virtualenv-init -)&quot; 1source ~/.bashrc 运行pyenv version查看pyenv版本。 运行pyenv versions查看本机python版本，注意这里多个s。 安装hass pyenv安装成功后我们就可以安装管理python了。 hass需要Pyrhon 3.7及以上，实测3.6也可以，不过会提示失去支持。3.8版本依赖会报错，所以我们安装Python 3.7.8。 如果对于你的网速有信心可以直接执行pyenv install 3.7.8。由于国内网络原因在这使用本地安装，首先使用各种方法去python官网下载Python-3.7.8.tar.xz，可以使用迅雷等p2p软件。然后把下载好的软件放到~/.pyenv/cache文件夹下，cache文件夹没有可以自己新建一个。然后执行pyenv install 3.7.8等待就可以了，期间没有安装进度，等待提示成功即可。 python安装完成后就可以安装hass了。首先全局配置清华pip源： 1pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple 升级pip 1pip install pip -U 利用venv 创建虚拟环境： 12cd 任何想要的目录python3 -m venv hass 进入虚拟环境并激活 12cd hasssource bin/activate 安装hass 1python3 -m pip install homeassistant 需要等待一段时间。。。 启动hass 123hass# 或者启动hass后打开web uihass --open-ui 第一次启动hass需要下载一些依赖，启动成功后在浏览器中打开地址即可： 如果有宝塔之类的面板记得在防火墙中放行8123端口 打开http:你的ip:8123 出现面板就是安装成功了，如果失败就再次执行hass 结语到此hass就搭建完成了，已经完成了智能家居联动的最重要步骤，后面的添加使用等有时间再出教程吧。","link":"/2020/08/11/%E6%8E%8C%E6%8E%A7%E4%BD%A0%E7%9A%84%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85%20-%20homeassistant%E8%AF%A6%E7%BB%86%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"},{"title":"树莓派变身电视盒子","text":"​ 之前来杭州的时候买的天猫魔盒越来越卡了，真是不明白为什么配置这么低还一直推送更新系统。最近更新以后简直都不能用了，回到桌面卡死，投屏卡死，切换菜单卡个好几秒，体验真是太差了。正好手里有个吃灰派4B。4B的配置还可以， 1.5GHz Cortex A72和4G的运存做电视盒子肯定是没问题了。一开始想刷Android TV了，但是看了一下不支持硬解，想了一下一个电视整那些花里胡哨的也没啥用，想要搞等房子装修好了再说吧。后来又找到了libreelec和openelec这两个媒体中心软件套件。由于openelec没有正式版支持树莓派4B，所以直接选用libreelec。 安装​ libreelec是一种Linux发行版，设计用于家庭影院PC，基于Kodi（以前的XBMC）媒体播放器。既然是完整的Linux发行版那么直接烧录就可以了。 ​ 首先在官网下载libreelec，在这注意不要选他提供的下载器，因为众所周知的原因下载会非常慢。直接滚动到下面选择RASPBERRY PI 4使用下载软件直接下载镜像就可以了（或者点击这里直接下载2020.09.25截止的最新版）。 下载以后解压得到LibreELEC-RPi4.arm-9.2.5.img。 下载Win32 Disk Imager，软件自带中文，选择你的sd卡盘符直接烧录就可以了。 烧录完成后插上电源，连上电视开机就行。 设置中文​ 开机之后会弹出设置向导，在设置SSH的地方可以选择开启并修改一个自己能记住的密码方便后面使用。完成设置向导后首先打开设置，选择Interface，把Fonts修改为Arial Based。这一步要先做，不然设置成中文后会乱码。 ​ 把下方切换为Advanced，然后选中Regional下的Language。打开后切换为Chinese (Simple)，这时候会进行下载，网路不好的话会下一会，等待就可以了。 ​ 等待安装完成就软件就会自动变成中文的了。 直播源​ 喜欢看电视的可以自己手动添加m3u8的直播源，在这有一个开源项目包括了国内外的直播源，不过国外的直播源速度肯定不理想。我一般都是手机投屏或者看本地的4K电影，所以在这就不赘述怎么配置了，复制地址就好。 配置Clash​ 因为平时会看Youtube，家里的网件太旧了，刷的梅林不支持新的加密协议（等我装修了一定要买个高端的华硕），所以干脆在树莓派里搭个Clash直接用了。 ​ 首先下载Clash，在这就不提供下载地址了，自己去Github的release下载就行，4B是ARM架构的，别下错了。把下载的二进制重命名为clash。 使用ssh连接树莓派，ip在设置里或者路由器的管理页面都能看到。ssh推荐mobaxterm，个人版免费足够用了，别再用和谐版的putty了，风险太大。 ​ 输入ip和用户名密码连接树莓派。用户名是root，密码是之前在设置向导里设置的密码，如果没改过默认密码就是libreelec。 ​ 连接好以后找个地方新建一个clash文件夹并且把刚才下载的clash上传到里面。运行一下输出如下信息就是能正常使用： 1INFO[0000] HTTP proxy listening at: 127.0.0.1:7890 ​ 如果卡在下载mmdb文件这里了那就下载Country.mmdb之后放到~/.config/clash文件夹里。再次运行./clash看看能不能正常启动。 ​ 正常启动后在~/.config/clash中修改config.yaml为你的代理配置文件。如果把配置文件放到其他地方了别忘了把Country.mmdb也挪过去然后使用-d来指定配置文件夹。在当前文件夹里新建startClash.sh，并写入： 123./clash#如果不用默认的配置文件那就指定一下配置文件夹#./clash -d 配置文件夹 ​ 之后nano /storage/.config/autostart.sh（libreELEC本身就是root用户了所以没有sudo命令）写入： 1nohup 你的clash路径/startClash.sh &amp; ​ 根据官方文档的说明autostart.sh会阻塞开机，所以需要在后台运行的脚本记得用括号括起来。 clash配置完成后可以手动启动一下或者重启一次。之后在kodi的设置里面把代理添上就可以了。 遥控​ 安卓下载yatse，ios的话直接搜kodi找一个遥控器下载就可以了。遥控器的话听说小米的蓝牙遥控器可以直接使用，但是还得花钱买就不试了。 ​ 由于树莓派4B不支持WOL所以使用手机开机是不行了，动手能力强的可以自己给树莓派加个红外开关，我在这直接使用智能开关来控制了，临时用的东西就不搞那么复杂了。","link":"/2020/09/25/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%8F%98%E8%BA%AB%E7%94%B5%E8%A7%86%E7%9B%92%E5%AD%90/"},{"title":"没有人会和你说的HTTP中GET与POST的区别","text":"GET和POST是HTTP请求的两种基本方法，要说它们的区别，接触过WEB开发的人都能说出一二。 最直观的区别就是GET把参数包含在URL中，POST通过request body传递参数。 你可能自己写过无数个GET和POST请求，或者已经看过很多权威网站总结出的他们的区别，你非常清楚知道什么时候该用什么。 当你在面试中被问到这个问题，你的内心充满了自信和喜悦。 你轻轻松松的给出了一个“标准答案”： GET在浏览器回退时是无害的，而POST会再次提交请求。 GET产生的URL地址可以被Bookmark，而POST不可以。 GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST么有。 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET参数通过URL传递，POST放在Request body中。 （本标准答案参考自w3schools） “很遗憾，这不是我们要的回答！” WTF?!?!?!?! 新机呲挖一呲冒黑套呲,真相只有一个: 如果我告诉你GET和POST本质上没有区别你信吗？ 让我们扒下GET和POST的外衣，坦诚相见吧！ GET和POST是什么？HTTP协议中的两种发送请求的方法。HTTP是什么？HTTP是基于TCP/IP的关于数据如何在万维网中如何通信的协议。 HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接。GET和POST能做的事情是一样一样的。你要给GET加上request body，给POST带上url参数，技术上是完全行的通的。 那么，“标准答案”里的那些区别是怎么回事？在万维网世界中，TCP就像汽车，我们用TCP来运输数据，它很可靠，从来不会发生丢件少件的现象。但是如果路上跑的全是看起来一模一样的汽车，那这个世界看起来是一团混乱，送急件的汽车可能被前面满载货物的汽车拦堵在路上，整个交通系统一定会瘫痪。为了避免这种情况发生，交通规则HTTP诞生了。HTTP给汽车运输设定了好几个服务类别，有GET, POST, PUT, DELETE等等，HTTP规定，当执行GET请求的时候，要给汽车贴上GET的标签（设置method为GET），而且要求把传送的数据放在车顶上（url中）以方便记录。如果是POST请求，就要在车上贴上POST的标签，并把货物放在车厢里。当然，你也可以在GET的时候往车厢内偷偷藏点货物，但是这是很不光彩；也可以在POST的时候在车顶上也放一些数据，让人觉得傻乎乎的。HTTP只是个行为准则，而TCP才是GET和POST怎么实现的基本。 但是，我们只看到HTTP对GET和POST参数的传送渠道（url还是requrest body）提出了要求。“标准答案”里关于参数大小的限制又是从哪来的呢？ 在万维网世界中，还有另一个重要的角色：运输公司。不同的浏览器（发起http请求）和服务器（接受http请求）就是不同的运输公司。 虽然理论上，你可以在车顶上无限的堆货物（url中无限加参数）。但是运输公司可不傻，装货和卸货也是有很大成本的，他们会限制单次运输量来控制风险，数据量太大对浏览器和服务器都是很大负担。业界不成文的规定是，（大多数）浏览器通常都会限制url长度在2K个字节，而（大多数）服务器最多处理64K大小的url。超过的部分，恕不处理。如果你用GET服务，在request body偷偷藏了数据，不同服务器的处理方式也是不同的，有些服务器会帮你卸货，读出数据，有些服务器直接忽略，所以，虽然GET可以带request body，也不能保证一定能被接收到哦。 好了，现在你知道，GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。 你以为本文就这么结束了？图样图森破. 我们的大BOSS还等着出场呢。。。 这位BOSS有多神秘？当你试图在网上找“GET和POST的区别”的时候，那些你会看到的搜索结果里，从没有提到他。他究竟是什么呢。。。 GET和POST还有一个重大区别，简单的说： GET产生一个TCP数据包；POST产生两个TCP数据包。 长的说： 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）； 而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。 也就是说，GET只需要汽车跑一趟就把货送到了，而POST得跑两趟，第一趟，先去和服务器打个招呼“嗨，我等下要送一批货来，你们打开门迎接我”，然后再回头把货送过去。 因为POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效。因此Yahoo团队有推荐用GET替换POST来优化网站性能。但这是一个坑！跳入需谨慎。为什么？ GET与POST都有自己的语义，不能随便混用。 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。 现在，当面试官再问你“GET与POST的区别”的时候，你就可以开始你的表演(装逼)了.","link":"/2017/06/01/%E6%B2%A1%E6%9C%89%E4%BA%BA%E4%BC%9A%E5%92%8C%E4%BD%A0%E8%AF%B4%E7%9A%84HTTP%E4%B8%ADGET%E4%B8%8EPOST%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"淘宝双十一 遇见十年前的自己 - 移动端视频解决方案","text":"兼容iOS与安卓。 双十一案例： 然后腾讯政务的找到我说两天要做个差不多的宣传黑龙江。我一想这么简单的东西有钱拿最主要的是还能宣传家乡那肯定妥妥的。 白天还的上班，周期又太短做的太仓促有一些不完善的地方，在这用意念修复一下吧 首先看到这个案例想到的肯定是转换为canvas进行播放，但是直接使用canvas在安装上面个video一样不能自动播放，所以想到一招把视频转换为帧图片然后用js控制播放。想法很天真，不过做起来就不对了。 解决方案一首先作为面对搜索引擎编程的我google了一下果然有现成的库canvid，使用很简单，用ffmpeg导出图片再用montage合成一下大功告成。在电脑的chrome 70.0.3538.102上测试了一下没问题，只要再把音频同步一下就 ok 了。秉着科学严谨的态度在手机上打开 视频花了？？？经过一顿瞎杰宝测试和猜测，在安卓手机上（_安卓不好使 ios 的就没测_）的精灵图大于一定尺寸以后就回出现问题，所以说要么视频必须很短，要么把长视频分割成几个短视频再用js控制播放。要求视频每一个都很短肯定是不行的，分割视频又太麻烦也不行。 解决方案二再一次google之后发现了第二种解决方案，使用ts格式的视频。 .ts 文件格式是 MPEG 的『传输流』(transport stream)，用以将视频、音频信息打包方便在有线电视网络、卫星链路、或无线电广播。这个格式最开始是用于广播的。后来它也被用在如数字录影机等场合。 简单理解就是可以做直播的那种。 在这有个现成的库：jsmpeg 使用方法很简单，API就不翻译了。原作者没有提供开始，_播放中_，结束的回调，在这把它们加上jsmpeg 增加回调。 新增回调： preload – 是否在实例化后马上预加载视频，autoplay设置为true时，此项将强行设置为true。 Default false. onended() – 视频播放到最后一帧后回调，如果loop设置为true，则每次结束均回调。 Default undefined. onended() – 视频播放到最后一帧后回调，如果loop设置为true，则每次结束均回调。 Default undefined. oncanplay() – 当文件就绪可以开始播放时（缓冲已足够开始时），无论preload如何设置，这个回调都会出现。 Default undefined. onpreload() – 预加载时实时回调。回传 1 个参数：加载进度，即当前加载量/所需总量。如果开启了progressive，这个回调参数的总量以第一个块的大小来算。 Default undefined. onplay() – 每次从暂停或者加载完成开始播放时。 Default undefined. 之后就简单多了 安装FFmpeg Mac os在安装的时候有可能会遇到brew的权限问题，搜一下全是解决方案，在这就不说了。 然后转换mp4文件为ts格式的。 1ffmpeg -i in.mp4 -f mpegts -codec:v mpeg1video -codec:a mp2 -b 0 out.ts 更多参数： 1234ffmpeg -i in.mp4 -f mpegts \\ -codec:v mpeg1video -s 960x540 -b:v 1500k -r 30 -bf 0 \\ -codec:a mp2 -ar 44100 -ac 1 -b:a 128k \\ out.ts 然后就可以开始写逻辑了： 1234567//新建播放器var player = new JSMpeg.Player('video.ts', { canvas: document.querySelector('.video'), loop: false, autoplay: true});... 你以为这就完事了？鲁迅曾经说过：喜欢js的真正原因是因为它总有事情可以做。 解决了安卓上面的问题，拿到iOS设备上一测，没声音。作者在其个人网站上有这么一段话： Audio Unlocking on iOSYou gotta love the shit that Apple throws into Web devs faces from time to time. One of those things is the need to unlock audio on a page before you can play anything. Basically, audio playback can only be started as a response to a user action. You click on a button, audio plays. This makes sense. I won’t argue against it. You don’t want to have audio blaring at you unannounced when you visit a page. What makes it shitty, is that Apple neither provided a way to cleanly unlock Audio nor a way to ask the WebAudio Context if it’s unlocked already. What you do instead, is to play an Audio source and continually check if it’s progressing. You can’t chek immediately after playing, though. No, no. You have to wait a bit! 翻译过来就是： iOS 上的音频解锁你将要爱上苹果时不时扔到 Web 开发人员脸上的麻烦。其中之一就是在播放任何内容之前都需要在页面上解锁音频。总的来说，音频播放只能作为对用户操作的响应而启动。你点击了一个按钮，音频则播放了。 这是有道理的。我不反驳它。当你访问某个网页时，你不希望在未经通知的情况下发出声音。 是什么让它变得糟糕透顶呢？是因为苹果公司既没有提供一种利索的解锁音频的方法，也没有提供一种方法来查询 WebAudio Context 是否已经解锁。你所要做的就是播放一个音频源并不断检查是否正在顺序播放。尽管如此，在播放之后你还不能马上检查。是的，你必须等一会！ 说白了就是在iOS上是不允许自动播放声音的，而且苹果公司也没提供相应的API，所以在iOS设备上还是推荐使用video解决。 如果得要用jsmpeg，这有一个hack方法 在设计上诱导用户点击，然后： 1234567891011121314var player = new JSMpeg.Player(url);document.addEventListener(&quot;touchstart&quot;, function() { // 手动启动audio，解除新的ios audio不能自动播放的问题 var audio = document.createElement(&quot;audio&quot;); audio.autoplay = &quot;autoplay&quot;; audio.volume = 0; // tmp.aac 是一个极短的没有声音的音频 audio.src = &quot;tmp.aac&quot;; // 手动触发audiocontext,让其从suspended变为running模式 player.audioOut.unlock(function() { player.volume = 1; player.unlockstate = true; });}); 总的来说，要想在移动端实现视频自动播放，安卓使用类似于 jsmpeg的解决方案，iOS上依旧使用video。如果是类似于GIF那种的短视频可以使用上面提到的canvid，效果比GIF好，大小比视频小而且不会出现兼容问题。","link":"/2019/11/12/%E6%B7%98%E5%AE%9D%E5%8F%8C%E5%8D%81%E4%B8%80%20%E9%81%87%E8%A7%81%E5%8D%81%E5%B9%B4%E5%89%8D%E7%9A%84%E8%87%AA%E5%B7%B1/"},{"title":"腾讯UP2017 3D粒子效果在网页端实现","text":"这段时间加班累成狗，终于尾声了，水一篇提升一下百度活跃度。 点击 预览 先看一下效果。 获取模型使用常规的 3D 建模软件即可。拿到 3D 模型之后再进行处理，处理的软件使用的是Blender兼容性比较好的是 fbx 格式，然后通过给 Blender 安装插件之后，将模型转换为便于 three.js 读取的 JSON 格式。当然我并不会建模，所以直接从UP2017 腾讯互动娱乐年度发布会 - 腾讯互动娱乐 上直接把粒子模型“偷”下来： 初始工作首先，初始化 threejs 三大元素：场景，相机，渲染器。我们需要一个用于切换的载体粒子体系和多个环境粒子体系（为了简单，在这只初始化了一个上下转动的环境粒子体系）。 1234567891011121314151617181920212223camera = new THREE.PerspectiveCamera( 105, window.innerWidth / window.innerHeight, 300, 10000);camera.position.z = 750;// 初始化场景scene = new THREE.Scene();//雾化scene.fog = new THREE.FogExp2(0x05050c, 0.0005);//初始化rendererrenderer = new THREE.WebGLRenderer();renderer.setPixelRatio(window.devicePixelRatio);renderer.setSize(window.innerWidth, window.innerHeight);container.appendChild(renderer.domElement);// 初始化geometrygeometry = new THREE.Geometry();around = new THREE.Geometry();// 初始化贴图const textureLoader = new THREE.TextureLoader();// 圆点const mapDot = textureLoader.load(&quot;assets/gradient.png&quot;); 初始化载体粒子体系：载体粒子体系的粒子数量要比所有模型的顶点数量的最大值还要大，这样才能保证切换到每一个模型，都不会出现缺失的情况，而多余的点呢就让他们从头开始重叠好了。当然不是越多越好，我的电脑是 MBP2018，20000 的时候就开始力不从心了，30000 直接无响应 1234567891011121314151617181920for (let i = 0; i &lt; 15000; i++) { const vertex = new THREE.Vector3(); vertex.x = 800 * Math.random() - 400; vertex.y = 800 * Math.random() - 400; vertex.z = 800 * Math.random() - 400; geometry.vertices.push(vertex); geometry.colors.push(new THREE.Color(255, 255, 255));}material = new THREE.PointsMaterial({ size: 4, sizeAttenuation: true, color: 0xffffff, transparent: true, opacity: 1, map: mapDot});material.vertexColors = THREE.VertexColors;particles = new THREE.Points(geometry, material);scene.add(particles); 将获取到的 3D 模型，通过 JSONLoader 加载后，得到的 geometry 对象放入一个数组 glist 中，用于模型切换。 加载模型 loadObject： 新版的threejs在r98 → r99的时候废弃了JSONLoader,模型在网站也比较久了，ObjectLoader也不能加载，所以要么使用旧版的，要么单独下载JSONLoader。 r98 → r99 WebGLRenderTarget.texture.generateMipmaps is now set to false by default. There is a new (not backwards compatible) implementation for SSAOShader and SSAOPass. JSONLoader has been removed from core. It is now located in examples/js/loaders/deprecated/LegacyJSONLoader.js. Removed Geometry support from ObjectLoader. You have to include LegacyJSONLoader if you still want to load geometry data of type Geometry. Removed Geometry support from SkinnedMesh. Use BufferGeometry instead. Removed SkinnedMesh.initBones(). The SkinnedMesh constructor does not build the bone hierarchy anymore. You have to do this by yourself and then call SkinnedMesh.bind() in order to bind the prepared skeleton. 在这引入最新的three.min.js和LegacyJSONLoader： 12&lt;script src=&quot;./js/three.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;./js/LegacyJSONLoader.js&quot;&gt;&lt;/script&gt; 加载模型 loadObject： 12345678const loader = new THREE.LegacyJSONLoader();loader.load(&quot;assets/qr.json&quot;, function(geo, materials) { geo.center(); geo.normalize(); geo.scale(800, 800, 800); glist.push(geo);}); 添加页面事件监听 按住鼠标拖动，可以旋转场景中的粒子体系。 滚动鼠标滚轮，切换模型。 手机上点击页面切换模型。 1234567891011121314151617181920212223242526272829303132333435363738function onDocumentMouseMove(event) { if (!canMouseMove) { return false; } geometry.rotateY(((event.pageX - mouseX) / 2000) * 2 * Math.PI); geometry.rotateX(((event.pageY - mouseY) / 2000) * 2 * Math.PI); event.preventDefault(); mouseX = event.pageX; mouseY = event.pageY;}function onDocumentMouseWheel(e) { canMouseMove = false; if (flag) { return false; } e.deltaY &gt; 0 ? objIndex++ : objIndex--; if (objIndex &gt; 4) { objIndex = 0; } else if (objIndex &lt; 0) { objIndex = 4; } tweenObj(objIndex); flag = true;}function onDocumentTouchStart() { canMouseMove = false; if (flag) { return false; } objIndex++; if (objIndex &gt; 4) { objIndex = 0; } tweenObj(objIndex); flag = true;} 切换动画使用的tweenjs 12345678910111213141516171819202122232425function tweenObj(index) { let ani = null; geometry.vertices.forEach(function(e, i, arr) { ani = new TWEEN.Tween(e); const length = glist[index].vertices.length; const o = glist[index].vertices[i % length]; ani .to( { x: o.x, y: o.y, z: o.z }, 1000 ) .easing(TWEEN.Easing.Exponential.In) .delay(400 * Math.random()) .start(); }); //动画完成时的回调 ani.onComplete(function(params) { canMouseMove = true; flag = false; });} 使用tween.delay(animationDuration*Math.random());是动画不那么生硬。 最后渲染整个画面： 12345678function render() { around.rotateX(Math.PI / 1000); TWEEN.update(); camera.lookAt(scene.position); geometry.verticesNeedUpdate = true; geometry.colorsNeedUpdate = true; renderer.render(scene, camera);} TWEEN.update()和geometry.verticesNeedUpdate = true共同决定了粒子体系切换动画可以展示出来。 GitHub 地址 总结还有很多地方不完善： 切换时旋转画面会导致粒子位置计算错误，撕裂模型，暂时在切换时禁止了旋转事件。 雾化的位置和原版有很大差异，原版使用了三方的composer，这里用的是alteredq的一系列EffectComposer，包括过亮效果、暗角、电视效果等。 KV的动画没有实现裙边的效果。 二维码的材质还是点，所以扫不出来，可以把材质的map设置为null即可是方形（没有纹理默认方形）。 12345new THREE.PointsMaterial({ ... map: null, //texture ...}); 流畅度方面，使用vertex shader性能可能更好，感觉好高深，等大神踩踩坑。 参考链接： threejs+tweenjs 实现 3D 粒子模型切换。 3D 粒子效果在网页端实现分享。","link":"/2018/07/07/%E8%85%BE%E8%AE%AFUP2017%203D%E7%B2%92%E5%AD%90%E6%95%88%E6%9E%9C%E5%9C%A8%E7%BD%91%E9%A1%B5%E7%AB%AF%E5%AE%9E%E7%8E%B0%E8%85%BE%E8%AE%AFUP2017%203D%E7%B2%92%E5%AD%90%E6%95%88%E6%9E%9C%E5%9C%A8%E7%BD%91%E9%A1%B5%E7%AB%AF%E5%AE%9E%E7%8E%B0/"},{"title":"苹果自带日历软件显示中国节假日","text":"直接用现代浏览器点开下面的连接即可，不好使就换自带的Safari 订阅中国节假日","link":"/2019/05/10/%E8%8B%B9%E6%9E%9C%E8%87%AA%E5%B8%A6%E6%97%A5%E5%8E%86%E8%BD%AF%E4%BB%B6%E6%98%BE%E7%A4%BA%E4%B8%AD%E5%9B%BD%E8%8A%82%E5%81%87%E6%97%A5/"},{"title":"前端跨域的几种解决办法","text":"CORS请求原理​ 基本上目前所有的浏览器**(IE10及其以下不可以,解决方案就是给用户下载一个chrome并把图标变成IE的๑乛◡乛๑)**都实现了CORS标准,其实目前几乎所有的浏览器ajax请求都是基于CORS机制的,只不过可能平时前端开发人员并不关心而已(所以说其实现在CORS解决方案主要是考虑后台该如何实现的问题)。 什么是CORS?原文:跨域资源共享 CORS 详解(阮一峰) 一、简介CORS需要浏览器和服务器同时支持。目前，所有浏览器都支持该功能，IE浏览器不能低于IE10。 整个CORS通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS通信与同源的AJAX通信没有差别，代码完全一样。浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。 因此，实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信。 二、两种请求浏览器将CORS请求分成两类：简单请求（simple request）和非简单请求（not-so-simple request）。 只要同时满足以下两大条件，就属于简单请求。 （1) 请求方法是以下三种方法之一： HEAD GET POST （2）HTTP的头信息不超出以下几种字段： Accept Accept-Language Content-Language Last-Event-ID Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain 凡是不同时满足上面两个条件，就属于非简单请求。 浏览器对这两种请求的处理，是不一样的。 三、简单请求3.1 基本流程对于简单请求，浏览器直接发出CORS请求。具体来说，就是在头信息之中，增加一个Origin字段。 下面是一个例子，浏览器发现这次跨源AJAX请求是简单请求，就自动在头信息之中，添加一个Origin字段。 123456GET /cors HTTP/1.1Origin: http://api.123456.plusHost: api.alice.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... 上面的头信息中，Origin字段用来说明，本次请求来自哪个源（协议 + 域名 + 端口）。服务器根据这个值，决定是否同意这次请求。 如果Origin指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应。浏览器发现，这个回应的头信息没有包含Access-Control-Allow-Origin字段（详见下文），就知道出错了，从而抛出一个错误，被XMLHttpRequest的onerror回调函数捕获。注意，这种错误无法通过状态码识别，因为HTTP回应的状态码有可能是200。 如果Origin指定的域名在许可范围内，服务器返回的响应，会多出几个头信息字段。 1234Access-Control-Allow-Origin: http://api.123456.plusAccess-Control-Allow-Credentials: trueAccess-Control-Expose-Headers: FooBarContent-Type: text/html; charset=utf-8 上面的头信息之中，有三个与CORS请求相关的字段，都以Access-Control-开头。 （1）Access-Control-Allow-Origin 该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。 （2）Access-Control-Allow-Credentials 该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。 （3）Access-Control-Expose-Headers 该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。上面的例子指定，getResponseHeader('FooBar')可以返回FooBar字段的值。 3.2 withCredentials 属性上面说到，CORS请求默认不发送Cookie和HTTP认证信息。如果要把Cookie发到服务器，一方面要服务器同意，指定Access-Control-Allow-Credentials字段。 1Access-Control-Allow-Credentials: true 另一方面，开发者必须在AJAX请求中打开withCredentials属性。 12var xhr = new XMLHttpRequest();xhr.withCredentials = true; 否则，即使服务器同意发送Cookie，浏览器也不会发送。或者，服务器要求设置Cookie，浏览器也不会处理。 但是，如果省略withCredentials设置，有的浏览器还是会一起发送Cookie。这时，可以显式关闭withCredentials 1xhr.withCredentials = false; 需要注意的是，如果要发送Cookie，Access-Control-Allow-Origin就不能设为星号，必须指定明确的、与请求网页一致的域名。同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传，其他域名的Cookie并不会上传，且（跨源）原网页代码中的document.cookie也无法读取服务器域名下的Cookie。 四、非简单请求4.1 预检请求非简单请求是那种对服务器有特殊要求的请求，比如请求方法是PUT或DELETE，或者Content-Type字段的类型是application/json。 非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为”预检”请求（preflight）。 浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。 下面是一段浏览器的JavaScript脚本。 12345var url = 'http://api.alice.com/cors';var xhr = new XMLHttpRequest();xhr.open('PUT', url, true);xhr.setRequestHeader('X-Custom-Header', 'value');xhr.send(); 上面代码中，HTTP请求的方法是PUT，并且发送一个自定义头信息X-Custom-Header。 浏览器发现，这是一个非简单请求，就自动发出一个”预检”请求，要求服务器确认可以这样请求。下面是这个”预检”请求的HTTP头信息。 12345678OPTIONS /cors HTTP/1.1Origin: http://api.bob.comAccess-Control-Request-Method: PUTAccess-Control-Request-Headers: X-Custom-HeaderHost: api.alice.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... “预检”请求用的请求方法是OPTIONS，表示这个请求是用来询问的。头信息里面，关键字段是Origin，表示请求来自哪个源。 除了Origin字段，”预检”请求的头信息包括两个特殊字段。 （1）Access-Control-Request-Method 该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法，上例是PUT。 （2）Access-Control-Request-Headers 该字段是一个逗号分隔的字符串，指定浏览器CORS请求会额外发送的头信息字段，上例是X-Custom-Header。 4.2 预检请求的回应服务器收到”预检”请求以后，检查了Origin、Access-Control-Request-Method和Access-Control-Request-Headers字段以后，确认允许跨源请求，就可以做出回应。 123456789101112HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 01:15:39 GMTServer: Apache/2.0.61 (Unix)Access-Control-Allow-Origin: http://api.123456.plusAccess-Control-Allow-Methods: GET, POST, PUTAccess-Control-Allow-Headers: X-Custom-HeaderContent-Type: text/html; charset=utf-8Content-Encoding: gzipContent-Length: 0Keep-Alive: timeout=2, max=100Connection: Keep-AliveContent-Type: text/plain 上面的HTTP回应中，关键的是Access-Control-Allow-Origin字段，表示http://api.bob.com可以请求数据。该字段也可以设为星号，表示同意任意跨源请求。 1Access-Control-Allow-Origin: * 如果浏览器否定了”预检”请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段。这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被XMLHttpRequest对象的onerror回调函数捕获。控制台会打印出如下的报错信息。 12XMLHttpRequest cannot load http://api.alice.com.Origin http://api.123456.plus is not allowed by Access-Control-Allow-Origin. 服务器回应的其他CORS相关字段如下。 1234Access-Control-Allow-Methods: GET, POST, PUTAccess-Control-Allow-Headers: X-Custom-HeaderAccess-Control-Allow-Credentials: trueAccess-Control-Max-Age: 1728000 （1）Access-Control-Allow-Methods 该字段必需，它的值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。注意，返回的是所有支持的方法，而不单是浏览器请求的那个方法。这是为了避免多次”预检”请求。 （2）Access-Control-Allow-Headers 如果浏览器请求包括Access-Control-Request-Headers字段，则Access-Control-Allow-Headers字段是必需的。它也是一个逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在”预检”中请求的字段。 （3）Access-Control-Allow-Credentials 该字段与简单请求时的含义相同。 （4）Access-Control-Max-Age 该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是20天（1728000秒），即允许缓存该条回应1728000秒（即20天），在此期间，不用发出另一条预检请求。 4.3 浏览器的正常请求和回应一旦服务器通过了”预检”请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。 下面是”预检”请求之后，浏览器的正常CORS请求。 1234567PUT /cors HTTP/1.1Origin: http://api.123456.plusHost: api.alice.comX-Custom-Header: valueAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... 上面头信息的Origin字段是浏览器自动添加的。 下面是服务器正常的回应。 12Access-Control-Allow-Origin: http://api.bob.comContent-Type: text/html; charset=utf-8 上面头信息中，Access-Control-Allow-Origin字段是每次回应都必定包含的。 五、与JSONP的比较CORS与JSONP的使用目的相同，但是比JSONP更强大。 JSONP只支持GET请求，CORS支持所有类型的HTTP请求。JSONP的优势在于支持老式浏览器，以及可以向不支持CORS的网站请求数据。 ajax跨域的表现ajax请求时,如果存在跨域现象,并且没有进行解决,会有如下表现:(注意，是ajax请求，请不要说为什么http请求可以，而ajax不行，因为ajax是伴随着跨域的，所以仅仅是http请求ok是不行的) 注意:具体的后端跨域配置请看题纲位置。 第一种现象:No 'Access-Control-Allow-Origin' header is present on the requested resource,并且The response had HTTP status code 404 出现这种情况的原因如下： 本次ajax请求是“非简单请求”,所以请求前会发送一次预检请求(OPTIONS) 服务器端后台接口没有允许OPTIONS请求,导致无法找到对应接口地址 解决方案: 后端允许options请求 第二种现象:No 'Access-Control-Allow-Origin' header is present on the requested resource,并且The response had HTTP status code 405 这种现象和第一种有区别,这种情况下，后台方法允许OPTIONS请求,但是一些配置文件中(如安全配置),阻止了OPTIONS请求,才会导致这个现象 解决方案: 后端关闭对应的安全配置. 第三种现象:No 'Access-Control-Allow-Origin' header is present on the requested resource,并且status 200 这种现象和第一种和第二种有区别,这种情况下，服务器端后台允许OPTIONS请求,并且接口也允许OPTIONS请求,但是头部匹配时出现不匹配现象 比如origin头部检查不匹配,比如少了一些头部的支持(如常见的X-Requested-With头部),然后服务端就会将response返回给前端,前端检测到这个后就触发XHR.onerror,导致前端控制台报错 解决方案: 后端增加对应的头部支持. 第四种现象:heade contains multiple values '*,*' 表现现象是，后台响应的http头部信息有两个Access-Control-Allow-Origin:* 说实话，这种问题出现的主要原因就是进行跨域配置的人不了解原理，导致了重复配置，如: 常见于.net后台(一般在web.config中配置了一次origin,然后代码中又手动添加了一次origin(比如代码手动设置了返回*)) 常见于.net后台(在IIS和项目的webconfig中同时设置Origin:*) 解决方案(一一对应): 建议删除代码中手动添加的*，只用项目配置中的即可 建议删除IIS下的配置*，只用项目配置中的即可 如何解决ajax跨域JSONP方式解决跨域问题jsonp解决跨域问题是一个比较古老的方案(实际中不推荐使用),这里做简单介绍(实际项目中如果要使用JSONP,一般会使用JQ等对JSONP进行了封装的类库来进行ajax请求) 实现原理JSONP之所以能够用来解决跨域方案,主要是因为 脚本拥有跨域能力,而JSONP正是利用这一点来实现。 实现流程JSONP的实现步骤大致如下(参考了来源中的文章) 客户端网页网页通过添加一个元素，向服务器请求JSON数据，这种做法不受同源政策限制 123456789101112131415function addScriptTag(src) { var script = document.createElement('script'); script.setAttribute(&quot;type&quot;,&quot;text/javascript&quot;); script.src = src; document.body.appendChild(script);}window.onload = function () { addScriptTag('http://example.com/ip?callback=foo');}function foo(data) { console.log('response data: ' + JSON.stringify(data));}; 请求时,接口地址是作为构建出的脚本标签的src的,这样,当脚本标签构建出来时,最终的src是接口返回的内容 服务端对应的接口在返回参数外面添加函数包裹层 123foo({ &quot;test&quot;: &quot;testData&quot;}); 由于元素请求的脚本，直接作为代码运行。这时，只要浏览器定义了foo函数，该函数就会立即调用。作为参数的JSON数据被视为JavaScript对象，而不是字符串，因此避免了使用JSON.parse的步骤。 注意,一般的JSONP接口和普通接口返回数据是有区别的,所以接口如果要做JSONO兼容,需要进行判断是否有对应callback关键字参数,如果有则是JSONP请求,返回JSONP数据,否则返回普通数据 使用注意 基于JSONP的实现原理,所以JSONP只能是“GET”请求,不能进行较为复杂的POST和其它请求,所以遇到那种情况,就得参考下面的CORS解决跨域了(所以如今它也基本被淘汰了) CORS解决跨域问题CORS的原理上文中已经介绍了，这里主要介绍的是，实际项目中，后端应该如何配置以解决问题(因为大量项目实践都是由后端进行解决的)，这里整理了一些常见的后端解决方案: PHP后台配置PHP后台得配置几乎是所有后台中最为简单的,遵循如下步骤即可: 第一步:配置Php 后台允许跨域 1234&lt;?phpheader('Access-Control-Allow-Origin: *');header('Access-Control-Allow-Headers: Origin, X-Requested-With, Content-Type, Accept');//主要为跨域CORS配置的两大基本信息,Origin和headers 第二步:配置Apache web服务器跨域(httpd.conf中) 原始代码 1234&lt;Directory /&gt; AllowOverride none Require all denied&lt;/Directory&gt; 改为以下代码 123456&lt;Directory /&gt; Options FollowSymLinks AllowOverride none Order deny,allow Allow from all&lt;/Directory&gt; Node.js后台配置(express框架)Node.js的后台也相对来说比较简单就可以进行配置。只需用express如下配置: 1234567891011121314app.all('*', function(req, res, next) { res.header(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); res.header(&quot;Access-Control-Allow-Headers&quot;, &quot;X-Requested-With&quot;); res.header(&quot;Access-Control-Allow-Methods&quot;, &quot;PUT,POST,GET,DELETE,OPTIONS&quot;); res.header(&quot;X-Powered-By&quot;, ' 3.2.1') //这段仅仅为了方便返回json而已 res.header(&quot;Content-Type&quot;, &quot;application/json;charset=utf-8&quot;); if(req.method == 'OPTIONS') { //让options请求快速返回 res.sendStatus(200); } else { next(); }}); JAVA后台配置JAVA后台配置只需要遵循如下步骤即可: 第一步:获取依赖jar包 下载 cors-filter-1.7.jar, java-property-utils-1.9.jar 这两个库文件放到lib目录下。(放到对应项目的webcontent/WEB-INF/lib/下) 第二步:如果项目用了Maven构建的,请添加如下依赖到pom.xml中:(非maven请忽视) 12345&lt;dependency&gt; &lt;groupId&gt;com.thetransactioncompany&lt;/groupId&gt; &lt;artifactId&gt;cors-filter&lt;/artifactId&gt; &lt;version&gt;[ version ]&lt;/version&gt;&lt;/dependency&gt; 其中版本应该是最新的稳定版本,CORS过滤器 第三步:添加CORS配置到项目的Web.xml中( App/WEB-INF/web.xml) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;!-- 跨域配置--&gt; &lt;filter&gt; &lt;!-- The CORS filter with parameters --&gt; &lt;filter-name&gt;CORS&lt;/filter-name&gt; &lt;filter-class&gt;com.thetransactioncompany.cors.CORSFilter&lt;/filter-class&gt; &lt;!-- Note: All parameters are options, if omitted the CORS Filter will fall back to the respective default values. --&gt; &lt;init-param&gt; &lt;param-name&gt;cors.allowGenericHttpRequests&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cors.allowOrigin&lt;/param-name&gt; &lt;param-value&gt;*&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cors.allowSubdomains&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cors.supportedMethods&lt;/param-name&gt; &lt;param-value&gt;GET, HEAD, POST, OPTIONS&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cors.supportedHeaders&lt;/param-name&gt; &lt;param-value&gt;Accept, Origin, X-Requested-With, Content-Type, Last-Modified&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cors.exposedHeaders&lt;/param-name&gt; &lt;!--这里可以添加一些自己的暴露Headers --&gt; &lt;param-value&gt;X-Test-1, X-Test-2&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cors.supportsCredentials&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cors.maxAge&lt;/param-name&gt; &lt;param-value&gt;3600&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;!-- CORS Filter mapping --&gt; &lt;filter-name&gt;CORS&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 请注意,以上配置文件请放到web.xml的前面,作为第一个filter存在(可以有多个filter的) 第四步:可能的安全模块配置错误(注意，某些框架中-譬如公司私人框架，有安全模块的，有时候这些安全模块配置会影响跨域配置，这时候可以先尝试关闭它们) JAVA Spring Boot配置仅列举简单的全局配置 1234567891011121314151617@Configurationpublic class CorsConfig { private CorsConfiguration buildConfig() { CorsConfiguration corsConfiguration = new CorsConfiguration(); corsConfiguration.addAllowedOrigin(&quot;*&quot;); corsConfiguration.addAllowedHeader(&quot;*&quot;); corsConfiguration.addAllowedMethod(&quot;*&quot;); return corsConfiguration; } @Bean public CorsFilter corsFilter() { UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(&quot;/**&quot;, buildConfig()); return new CorsFilter(source); }} 新建配置，然后添加Configuration注解即可配置成功 PS：这一部分方法是收录的，没有亲身实践过，但根据反馈，理论上可行 NET后台配置.NET后台配置可以参考如下步骤: 第一步:网站配置 打开控制面板，选择管理工具,选择iis;右键单击自己的网站，选择浏览;打开网站所在目录,打开web.config文件: 注释:&lt;add verb=&quot;OPTIONS&quot; allowed=&quot;false&quot;/&gt; 在&lt;httpProtocol&gt;&lt;/httpProtocol&gt;里添加 12&lt;add name=&quot;Access-Control-Allow-Headers&quot; value=&quot;*&quot; /&gt;&lt;add name=&quot;Access-Control-Allow-Methods&quot; value=&quot;GET,POST,PUT,DELETE,OPTIONS&quot; /&gt; 然后重启网站 请注意,如果配置仍然出问题,可以考虑增加更多的headers允许,比如: 1&quot;Access-Control-Allow-Headers&quot;:&quot;X-Requested-With,Content-Type,Accept,Origin&quot; 第二步:其它更多配置,如果第一步进行了后,仍然有跨域问题，可能是: 接口中有限制死一些请求类型(比如写死了POST等)，这时候请去除限 制 接口中，重复配置了Origin:*，请去除即可 IIS服务器中，重复配置了Origin:*，请去除即可 代理请求方式解决接口跨域问题注意，由于接口代理是有代价的，所以这个仅是开发过程中进行的。 与前面的方法不同，前面CORS是后端解决，而这个主要是前端对接口进行代理，也就是: 前端ajax请求的是本地接口 本地接口接收到请求后向实际的接口请求数据，然后再将信息返回给前端 一般用node.js即可代理 关于如何实现代理，这里就不重点描述了，方法和多，也不难，基本都是基于node.js的。 搜索关键字node.js,代理请求即可找到一大票的方案。 OPTIONS预检的优化1Access-Control-Max-Age: 这个头部加上后，可以缓存此次请求的秒数。 在这个时间范围内，所有同类型的请求都将不再发送预检请求而是直接使用此次返回的头作为判断依据。 非常有用，可以大幅优化请求次数. 关于跨域还有以下三种解决方案 设置document.domain=my.com 使用websocket通信 图片Ping 由于不怎么常用,所以大家可以自行百度. 参考链接:ajax跨域，这应该是最全的解决方案了","link":"/2016/05/11/%E5%89%8D%E7%AB%AF%E8%B7%A8%E5%9F%9F%E7%9A%84%E5%87%A0%E7%A7%8D%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"},{"title":"鸿蒙OS 2.0 开发体验","text":"​ 昨天（北京时间 2020年9月10日）华为鸿蒙OS 2.0正式发布，预计明年华为手机全面支持。同时公布了面向开发者的BATE版。 ​ 看了一下文档，同时支持java和js。那必须整一个试试。 安装 IDE​ 首先去官网下载HUAWEI DevEco Studio，目前只有windows版。下载后解压安装。 jetbrains家的社区版，有那味了。 ​ 安装后直接启动： ​ 因为都是jetbrains家的开源版，所以和android studio基本一致。启动后发现现在只支持电视和可穿戴设备的模板，除了Lite都提供了java和js的模板。在这我们新建一个可穿戴设备的模板： ​ 目录结构如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222.└── HWDemo ├── HWDemo.iml ├── build │ └── outputs │ └── hap │ └── debug │ └── tv │ └── entry-debug-unsigned.hap ├── build.gradle ├── entry │ ├── build │ │ ├── generated │ │ │ └── source │ │ │ └── r │ │ │ └── ResourceTable.java │ │ ├── intermediates │ │ │ ├── dex │ │ │ │ └── debug │ │ │ │ └── classes.dex │ │ │ ├── external_libs │ │ │ │ └── debug │ │ │ │ ├── compile_libs_file.index │ │ │ │ └── package_libs_file.index │ │ │ ├── javac │ │ │ │ └── debug │ │ │ │ ├── classes │ │ │ │ │ ├── META-INF │ │ │ │ │ │ └── MANIFEST.MF │ │ │ │ │ ├── classes.jar │ │ │ │ │ └── com │ │ │ │ │ └── example │ │ │ │ │ └── hwdemo │ │ │ │ │ ├── HWDemo.class │ │ │ │ │ ├── MainAbility.class │ │ │ │ │ └── ResourceTable.class │ │ │ │ └── java_file.index │ │ │ ├── merge_profile │ │ │ │ └── debug │ │ │ │ └── config.json │ │ │ ├── merge_res │ │ │ │ └── debug │ │ │ │ ├── merge_res_file.index │ │ │ │ └── original_res │ │ │ │ └── res │ │ │ │ ├── drawable │ │ │ │ │ └── icon.png │ │ │ │ └── values │ │ │ │ └── strings.xml │ │ │ ├── res │ │ │ │ └── debug │ │ │ │ ├── jsManifest │ │ │ │ │ └── default │ │ │ │ │ └── manifest.json │ │ │ │ ├── jsResources │ │ │ │ │ ├── base │ │ │ │ │ │ ├── element │ │ │ │ │ │ └── media │ │ │ │ │ │ └── icon.png │ │ │ │ │ └── rawfile │ │ │ │ └── rich │ │ │ │ ├── R.txt │ │ │ │ ├── assets │ │ │ │ │ └── js │ │ │ │ │ └── default │ │ │ │ │ ├── app.bin │ │ │ │ │ ├── app.js │ │ │ │ │ ├── app.js.map │ │ │ │ │ ├── common │ │ │ │ │ │ ├── img-large.png │ │ │ │ │ │ ├── img-small.png │ │ │ │ │ │ ├── logo.png │ │ │ │ │ │ ├── plus-black.png │ │ │ │ │ │ └── plus-white.png │ │ │ │ │ ├── i18n │ │ │ │ │ │ ├── en-US.json │ │ │ │ │ │ └── zh-CN.json │ │ │ │ │ ├── manifest.json │ │ │ │ │ └── pages │ │ │ │ │ └── index │ │ │ │ │ ├── index.bin │ │ │ │ │ ├── index.js │ │ │ │ │ └── index.js.map │ │ │ │ ├── config.json │ │ │ │ ├── resources │ │ │ │ │ ├── base │ │ │ │ │ │ └── media │ │ │ │ │ │ ├── attributes.key │ │ │ │ │ │ ├── constants.key │ │ │ │ │ │ ├── contents.key │ │ │ │ │ │ ├── icon.png │ │ │ │ │ │ └── nodes.key │ │ │ │ │ └── rawfile │ │ │ │ └── resources.index │ │ │ ├── shell │ │ │ │ ├── build │ │ │ │ │ ├── dex │ │ │ │ │ │ └── debug │ │ │ │ │ │ └── classes.dex │ │ │ │ │ ├── javac │ │ │ │ │ │ └── debug │ │ │ │ │ │ ├── classes │ │ │ │ │ │ │ └── com │ │ │ │ │ │ │ └── example │ │ │ │ │ │ │ └── hwdemo │ │ │ │ │ │ │ ├── MainAbilityShellActivity.class │ │ │ │ │ │ │ ├── R$drawable.class │ │ │ │ │ │ │ ├── R$string.class │ │ │ │ │ │ │ ├── R.class │ │ │ │ │ │ │ └── ShellHWDemo.class │ │ │ │ │ │ ├── classes.jar │ │ │ │ │ │ └── index.txt │ │ │ │ │ ├── mergedManifest │ │ │ │ │ │ └── debug │ │ │ │ │ │ └── AndroidManifest.xml │ │ │ │ │ ├── res │ │ │ │ │ │ └── debug │ │ │ │ │ │ ├── cut_entry │ │ │ │ │ │ │ ├── AndroidManifest.xml │ │ │ │ │ │ │ ├── classes.dex │ │ │ │ │ │ │ ├── res │ │ │ │ │ │ │ │ └── drawable │ │ │ │ │ │ │ │ └── icon.png │ │ │ │ │ │ │ └── resources.arsc │ │ │ │ │ │ ├── cut_entry.zip │ │ │ │ │ │ ├── entry │ │ │ │ │ │ │ ├── AndroidManifest.xml │ │ │ │ │ │ │ ├── classes.dex │ │ │ │ │ │ │ ├── res │ │ │ │ │ │ │ │ └── drawable │ │ │ │ │ │ │ │ └── icon.png │ │ │ │ │ │ │ └── resources.arsc │ │ │ │ │ │ ├── entry.zip │ │ │ │ │ │ ├── r │ │ │ │ │ │ │ └── com │ │ │ │ │ │ │ └── example │ │ │ │ │ │ │ └── hwdemo │ │ │ │ │ │ │ └── R.java │ │ │ │ │ │ └── res.zip │ │ │ │ │ └── simplifyManifest │ │ │ │ │ └── AndroidManifest.xml │ │ │ │ └── src │ │ │ │ └── main │ │ │ │ ├── AndroidManifest.xml │ │ │ │ ├── java │ │ │ │ │ └── com │ │ │ │ │ └── example │ │ │ │ │ └── hwdemo │ │ │ │ │ ├── MainAbilityShellActivity.java │ │ │ │ │ └── ShellHWDemo.java │ │ │ │ └── res │ │ │ │ ├── drawable │ │ │ │ │ └── icon.png │ │ │ │ └── values │ │ │ │ └── strings.xml │ │ │ └── shell_output │ │ │ └── debug │ │ │ ├── cut │ │ │ │ └── entry_unsigned_cut_entry.apk │ │ │ ├── entry_signed_entry.apk │ │ │ └── entry_unsigned_entry.apk │ │ └── outputs │ │ └── hap │ │ └── debug │ │ ├── entry-debug-unsigned.hap │ │ └── hapInfo.json │ ├── build.gradle │ ├── entry.iml │ ├── libs │ ├── node_modules │ ├── package.json │ └── src │ ├── main │ │ ├── config.json │ │ ├── java │ │ │ └── com │ │ │ └── example │ │ │ └── hwdemo │ │ │ ├── HWDemo.java │ │ │ └── MainAbility.java │ │ ├── js │ │ │ └── default │ │ │ ├── app.js │ │ │ ├── common │ │ │ │ ├── img-large.png │ │ │ │ ├── img-small.png │ │ │ │ ├── logo.png │ │ │ │ ├── plus-black.png │ │ │ │ └── plus-white.png │ │ │ ├── i18n │ │ │ │ ├── en-US.json │ │ │ │ └── zh-CN.json │ │ │ └── pages │ │ │ └── index │ │ │ ├── index.css │ │ │ ├── index.hml │ │ │ └── index.js │ │ └── resources │ │ ├── base │ │ │ ├── element │ │ │ │ └── string.json │ │ │ └── media │ │ │ └── icon.png │ │ └── rawfile │ └── test │ └── java │ └── com │ └── example │ └── hwdemo │ └── MainAbilityTest.java ├── gradle │ └── wrapper │ ├── gradle-wrapper.jar │ └── gradle-wrapper.properties ├── gradle.properties ├── gradlew ├── gradlew.bat ├── local.properties ├── settings.gradle └── tree.txt118 directories, 101 files ​ 新建项目后需要等待安装SDK，在这不得不吐槽一下，都是huawei.com的地址了速度居然慢到爆炸，挂了代理速度才上来，ping了一下是北京华为云的服务器，真是实力劝退。 ​ 等待结束后就可以下一步了。 开启虚拟机​ 在菜单中选中Tools&gt;HVD Manager首次开启需要下载资源。下载成功后点击Refresh会在浏览器中弹出登陆页面。 如果你没注册过华为的开发者账号那就打开Chrome的无痕窗口或者其他浏览器进行实名注册。这一步的原因是他这个验证有BUG，会一直跳转实名注册》验证成功》登陆成功》没了？？？ ​ 在这还得吐槽一下，实名认证你要我银行卡号干什么？要给我打钱吗？ ​ 登陆成功后就会刷新出列表，只有两个机器，一个是TV的一个是可穿戴设备的。在这我们选择可穿戴设备的虚拟机。 Hello World​ 虚拟机开启后新建的模板自带一个Hello World的Demo。js开发相关的文件在项目目录/entry/src/main/js里面，修改entry/src/main/js/default/pages/index下的hml,css,js文件并重新运行就可以看见效果了。 ​ 在安装依赖的时候发现了uni相关的内容。而且点击运行就可以出现效果，估计js开发的内容也是运行在webview里的。 体验​ 没啥好说的，做开发的都明白。反正Linux是开源的Android也是开源的，基于Linux是系统基于Android的当然也可以叫系统（OS）。别的不说，营销是真恶心。 ​ 一波体验下来Flutter恐成最大赢家。最大输家应该就是华为云了，真是实力劝退🐶。 ​ 希望鸿蒙能做起来，这样又有新饭恰了。 ​ 不说了，学Dart去了。","link":"/2020/09/11/%E9%B8%BF%E8%92%99OS%202.0%20%E5%BC%80%E5%8F%91%E4%BD%93%E9%AA%8C/"},{"title":"Linux 常用命令及举例(不定时更新)","text":"20181107更新买了一台mbp，用到命令的时候也多了，也好长时间没更新博客了，趁着过节（立冬）更新一波。 ​ 用了20多年的windows 导致不太习惯使用终端有的时候使用什么linux 命令的时候还得现查 ,所以干脆就总结一下,分享出来,也算是写一个备忘录了(岁数大了记性都不好了,送礼的多送几盒脑白金吧). 包管理器apt-get Debian/Ubuntu系统包管理器1234567891011121314151617181920212223# 命令:update - 检索 新的包列表upgrade - 升级 可更新的所有软件包install - 安装 新软件包（pkg是libc6不是libc6.deb）remove - 删除 软件包autoremove - 自动删除 所有未使用的软件包purge - 删除 软件包和配置文件clean - 清除 已下载的归档文件autoclean - 清除 旧的下载的档案文件check - 验证 是否有损坏的依赖download - 下载 二进制包到当前目录 # 选项：-q ：不输出任何信息-qq ：除了错误之外，没有输出-d ：仅下载，不要安装或解压缩存档-y ：对所有确定询问都选择 Yes，并且不提示-f ：尝试纠正 被破坏依赖关系的系统-m ：如果存档是可定位的，则尝试继续-u ：显示升级包的列表-b ：在获取源代码包后构建源包 # 更多的命令可以用 apt-get --help 查看。 e.g.1234567891011121314151617181920212223242526272829# 检索 新的包列表apt-get update # 升级 可更新的所有软件包（注意这个命令会升级所有的软件包，所以会升级很长时间）apt-get upgrade # 安装 Nginx 软件包apt-get install nginx # 卸载 Nginx 软件包apt-get remove nginx # 卸载 Nginx 软件包 并删除所有相关配置文件apt-get remove --purge nginx # 在安装软件和卸载的时候，为了避免误操作，都会询问是否继续，每次都要输入 y 来确定会很麻烦，可以加上 -y 参数# 安装 Nginx 软件包 并不显示确定提示apt-get install nginx -y # 卸载 Nginx 软件包，删除所有相关配置文件 并不显示提示apt-get remove --purge nginx -y # 清除 旧的/无用 的软件包apt-get clean &amp;&amp; apt-get autoclean # 下载 Nginx 二进制软件包到当前目录，但不解压和安装apt-get download nginx -d # 更多的命令可以用 apt-get --help 查看。 yum CentOS系统包管理器123456789101112131415161718192021222324252627282930313233# 命令： update - 检索 新的包列表upgrade - 升级 软件包search - 搜索 软件包install - 安装 软件包list - 列出 软件包或者软件包组info - 显示软件包或者软件包组的详细信息erase - 删除 软件包（这两个命令一样）remove - 删除 软件包（这两个命令一样）groupinfo - 显示 有关包组的详细信息groupinstall - 安装 软件包组（就像一种软件合集）grouplist - 列出 可用的软件包组groupremove - 删除 软件包组check - 检查 软件包check-update - 检查 可更新的软件包clean - 清除 缓存目录内的软件包deplist - 列出 一个包的依赖关系distribution-synchronization - 同步 已安装的软件包到最新的版本downgrad - 降级 一个软件包reinstall - 重新安装 软件包（自动删除重装）repolist - 显示 配置的软件包仓库resolvedep - 确定 软件包需要的依赖关系 # 选项：-t ：容忍错误-C ：完全从系统缓存运行，不要更新缓存-R 分钟 ：最大命令等待时间-q ：安静的操作-y ：对于所有问题回答是--nogpgcheck ：禁用gpg签名检查 # 更多的命令可以用 yum --help 查看。 e.g.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 检索 新的包列表yum update # 安装 Nginx 软件包yum install nginx # 安装 Development Tools 软件包组（这个软件包组中包含了编译所需的软件）# 注意：当软件包或者软件包组的名字中包含空格的时候，请把 软件包或软件包组 加上双引号！yum groupinstall &quot;Development Tools&quot; # 卸载 Nginx 软件包yum erase nginx / yum remove nginx # 卸载 Development Tools 软件包组yum groupremove &quot;Development Tools&quot; # 升级 所有可更新的软件包yum upgrade # 升级 Nginx 可更新的软件包yum upgrade nginx # 在安装软件和卸载的时候，为了避免误操作，都会询问是否继续，每次都要输入 y 来确定会很麻烦，可以加上 -y 参数# 安装 Nginx 软件包 并不显示确定提示yum install nginx -y # 卸载 Nginx 软件包 并不显示确定提示yum erase nginx -y / yum remove nginx -y # 搜索 Nginx 软件包是否存着yum search nginx # 列出 可用的软件包yum list # 列出 可用的软件包组yum grouplist # 清除 缓存目录中的所有软件包yum clean # 清除 缓存目录中的 Nginx 软件包yum clean nginx # 重装 Nginx 软件包yum reinstall nginx # 更多的命令可以用 yum --help 查看。 文件/文件夹 操作以下除特殊说明，默认当前目录为/root mkdir 新建 文件夹1234# 在当前文件夹新建一个 bash 文件夹，完整的绝对路径就是 /root/bashmkdir bash # 更多的命令可以用 mkdir --help 查看。 cd 进入 文件夹123456789# 你当前在 /root目录中，使用这个命令会进入 /root/bash目录，这是相对路径cd bash# 如果你不在 /root目录中的话，就不能用上面的相对路径了，就需要绝对路径cd /root/bash————————————————————————————————————————————————————————————————————————————# 假设你当前在 /root/bash目录中，使用相对路径，你可以用这个命令进入上一级 /root目录， .. 代表相对路径 上级目录cd ..# 当然你也可以用绝对路径来进入上一级 /root目录cd /root cp 复制或重命名 文件/文件夹1234567891011121314151617181920212223242526272829303132333435363738394041# 复制当前目录内的 log.txt文件到 /var目录cp log.txt /var/log.txt # 复制当前目录内的 bash文件夹到 /home目录cp -R bash /home/bash—————————————————————————————————————# 复制当前目录内的所有.txt后缀的文件到 /var/log目录cp *.txt /var/log # 复制当前目录内的所有以 123456.plus开头的文件到 /var/log目录cp 123456.plus* /var/log # 复制当前目录内的所有以 123456.plus开头 以.txt后缀结尾的文件到 /var/log目录cp 123456.plus*.txt /var/log—————————————————————————————————————# 假设当前目录是 /root/123456.plus/log，要把这个目录中的所有.txt后缀的文件复制到上一级目录 /root/123456.plus，那么这样做cp *.txt .. # .. 就是相对路径，代表上一级目录，当然你也可以用绝对路径，这样更不容易出错cp *.txt /root/123456.plus—————————————————————————————————————# 重命名当前目录内的 log.txt文件为 log2.txtcp log.txt log2.txt # 复制当前目录内的 log.txt文件到 /var目录并重命名为 log1.txtcp log.txt /var/log1.txt # 复制当前目录内的 bash文件夹到 /home目录并重命名为 bash2cp -R bash /home/bash2—————————————————————————————————————# 复制当前目录内的 log.txt文件到 /var目录，但是 /var 目录中已经存着 log.txt，那么会提示 cp: overwrite `/var/log.txt'? 可以用 -f 强制覆盖cp -f log /var/log.txt # 大家可能会发现，当你使用 cp -f 强制覆盖的时候，依然会询问你是否覆盖，这是因为 CP 为了避免你手误，默认加上了 -i 参数（该参数代表每次覆盖必须询问）。# 所以想要避免 CP 默认的 -i 参数，只需要在 CP 命令前面加上斜杠即可 “/”/cp -f log /var/log.txt # 复制当前目录内的 log.txt log1.txt log2.txt文件和 log233目录到 /home/log目录中cp -R log.txt log1.txt log2.txt log233 /home/log # 更多的命令可以用 cp --help 查看。 mv 移动或重命名 文件/文件夹123456789101112131415161718# 关于 mv 命令，可以参考上面 cp 的使用方法，没什么区别，只是一个是复制，一个是移动，把上面 cp 命令改成 mv 就能套用了。 # 移动当前目录内的 log.txt文件到 /var目录mv log.txt /var/log.txt # 移动当前目录内的 bash文件夹到 /home目录mv bash /home/bash—————————————————————————————————————# 重命名当前目录内的 log.txt文件为 log2.txtmv log.txt log2.txt # 复制当前目录内的 log.txt文件到 /var目录并重命名为 log1.txtmv log.txt /var/log1.txt # 复制当前目录内的 bash文件夹到 /home目录并重命名为 bash2mv bash /home/bash2 # 更多的命令可以用 mv --help 查看。 rm 删除 文件/文件夹123456789101112131415161718192021222324252627282930# 删除当前目录下的 log.txt文件rm log.txt # 删除当前目录下所有.txt后缀的文件rm *.txt # 使用 rm 命令删除时，会提示你是否确定删除，输入 y 即删除，输入 n 则取消# rm: remove regular file `log.txt'? y—————————————————————————————————————# 删除当前目录下所有.txt后缀的文件rm *.txt # 删除当前目录下所有以 123456.plus开头的文件rm 123456.plus* # 删除当前目录下所有以 123456.plus开头 以.txt后缀结尾的文件rm 123456.plus*.txt—————————————————————————————————————# 当你用 rm 删除目录的时候会发现提示这不是一个文件# rm bash# rm: cannot remove `bash': Is a directory# 可以加上 -r 来归递删除目录及其目录下的内容rm -r bash—————————————————————————————————————# 因为为了避免手误删除错误，所以 rm默认是加上了 -i 的参数，也就是每一次删除文件/目录都会提示，如果觉得烦可以用 -rf 参数rm -rf bash # rm -rf 这个命令请慎重使用，而且千万不要使用 rm -rf / 或者 rm -rf /* 之类的命令(系统自杀)，可能会让你系统爆炸，所以使用请慎重！ # 更多的命令可以用 rm --help 查看。 查看/编辑文件 操作ls 显示目录中文件123456789101112131415161718192021# 显示当前目录下的所有文件ls -a—————————————————————————————————————# 命令后面加上 绝对路径/相对路径 就会显示指定文件夹内的所有文件ls -a bash/log # 相对路径，当前目录是 /root ，欲查看的目录是 /root/bash/logls -a /root/bash/log # 绝对路径， 当前目录是 /root ，欲查看的目录是 /root/bash/log # 更多的命令可以用 ls --help 来查看。# 显示当前目录下的所有文件ls -a————————————————————————————————————————————————————————————————————————————# 命令后面加上 绝对路径/相对路径 就会显示指定文件夹内的所有文件ls -a bash/log# 相对路径，当前目录是 /root ，欲查看的目录是 /root/bash/logls -a /root/bash/log# 绝对路径， 当前目录是 /root ，欲查看的目录是 /root/bash/log # 更多的命令可以用 ls --help 来查看。 du 查看 文件/文件夹 占用磁盘空间的大小12345678910-h ：以人类易读的方式显示-a ：显示 目录占用的磁盘空间大小，并显示其下目录和文件占用磁盘空间的大小-s ：显示 目录占用的磁盘空间大小，但不显示其下子目录和文件占用的磁盘空间大小-c ：显示几个目录或文件占用的磁盘空间大小，还要统计它们的总和--apparent-size：显示目录或文件自身的大小-l ：统计硬链接占用磁盘空间的大小-L ：统计符号链接所指向的文件占用的磁盘空间大小# 待写... # 更多的命令可以用 du --help 来查看。 e.g.12345678910# 假设当前位于 /root 目录下，则显示 /root 文件夹的大小，但不显示其子目录和文件的大小du -sh # 假设当前位于 /root 目录下，则显示 /root 文件夹的大小，并显示其子目录和文件的大小du -ah # 假设当前位于 /root 目录下，则显示 /root 文件夹下的所有文件夹的大小及其总和du -lh --max-depth=1 # 更多的命令可以用 du --help 来查看。 cat 查看文件内容假设 text.txt文件的内容为： 12345678滚滚长江东逝水浪花淘尽英雄 是非成败转头空 青山依旧在几度夕阳红 查看文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 查看 text.txt文件的所有内容cat text.txt# 输出示例如下滚滚长江东逝水浪花淘尽英雄 是非成败转头空 青山依旧在几度夕阳红 # 查看 text.txt文件的所有内容，并对所有行编号cat -n text.txt# 输出示例如下： 1 滚滚长江东逝水 2 浪花淘尽英雄 3 4 5 是非成败转头空 6 7 青山依旧在 8 几度夕阳红 # 查看 text.txt文件的所有内容，并对非空行编号cat -b text.txt# 输出示例如下： 1 滚滚长江东逝水 2 浪花淘尽英雄 3 是非成败转头空 4 青山依旧在 5 几度夕阳红 # 查看 text.txt文件的所有内容，并对非空行编号，且不输出多行空行cat -bs text.txt# 输出示例如下： 1 滚滚长江东逝水 2 浪花淘尽英雄 3 是非成败转头空 4 青山依旧在 5 几度夕阳红 清空文件： 12345# 清空当前目录中的 log.txt 文件cat /dev/null &gt; log.txt # 清空 /var目录中的 log.txt 文件cat /dev/null &gt; /var/log.txt 写入文件： 1234567891011121314151617# 写入文本到当前目录中的 log.txt文件中(加入文本到文件内容最后)cat &gt;&gt; log.txt &lt;&lt;-EOF浪花淘尽英雄是非成败转头空青山依旧在几度夕阳红EOF # 清空文件并写入文本到 /var目录中的 log.txt文件中(先清空后写入)cat &gt; /var/log.txt &lt;&lt;-EOF浪花淘尽英雄是非成败转头空青山依旧在几度夕阳红EOF # 更多的命令可以用 cat --help 来查看。 head 查看文件内容（主要用于正查）12345-c 数字：显示指定文件的前 xx 字节的内容（bytes）-n 数字：显示指定文件的前 xx 行的内容-q ：不显示包含指定文件名的文件头（当使用 head打开多个文件的时候，会去在每个文件输出结果的顶部添加一个包含文件名的文件头用于区分） # 更多的命令可以用 head --help 来查看。 e.g.假设 text.txt文件的内容为： 12345滚滚长江东逝水浪花淘尽英雄是非成败转头空青山依旧在几度夕阳红 12345678910111213141516171819202122232425262728# 查看 text.txt文件的全部内容head text.txt # 查看 text.txt文件的前 4字节的内容head -c 4 text.txt # 输出示例滚滚长江 # 查看 text.txt文件的前 2行的内容head -n 2 text.txt # 输出示例滚滚长江东逝水浪花淘尽英雄 # 查看 text.txt文件的从倒数第2行到行首的内容head -n -2 text.txt # 输出示例滚滚长江东逝水浪花淘尽英雄是非成败转头空 # 查看 text.txt text1.txt text2.txt文件的前 3行内容head -n 3 text.txt text1.txt text2.txt # 更多的命令可以用 head --help 来查看。 tail 查看文件内容（主要用于倒查）12345-c 数字：如果数字为正数(例如 -c +5)，显示指定文件从行首第 xx 字节到最后的内容；如果数字为负数(例如 -c -5)，显示指定文件从行尾第 xx 字节到最后内容。-n 数字：如果数字为正数(例如 -c +3)，显示指定文件从行首第 xx 行到最后的内容；如果数字为负数(例如 -c -3)，显示指定文件从行尾第 xx 行到最后的内容。-f ：即时输出文件变化后增加的内容，也就是监视一个文件的内容变化（常用于监视日志输出），使用 Ctrl＋C 终止 # 更多的命令可以用 tail --help 来查看。 e.g.假设 text.txt文件的内容为： 12345滚滚长江东逝水浪花淘尽英雄是非成败转头空青山依旧在几度夕阳红 1234567891011121314151617181920212223242526# 查看 text.txt文件的全部内容tail log.txt # 查看 text.txt文件从行首 第25字节到最后的内容tail -c +25 text.txt # 查看 text.txt文件从行尾 第4字节到最前面的内容tail -c -4 log.txt # 查看 text.txt文件的从第2行到最后一行的内容tail -n +2 log.txt # 查看 text.txt文件的后 2行的内容tail -n -2 log.txt # 持续查看（监视） text.txt文件的变化内容（新增加的内容），使用 Ctrl＋C 终止tail -f log.txt # 查看 text.txt text.txt text.txt文件的前 3行内容tail -n 3 text.txt text1.txt text2.txt # 更多的命令可以用 tail --help 来查看。 sed 查看/编辑文件内容1234-i ：操作后应用保存到原文件（如果不加这个参数，那么任何修改都不会影响原文件里的内容，只会把结果输出）# 待写... # 更多的命令可以用 sed --help 来查看。 e.g.123456789101112131415161718192021222324252627282930# 查看 log.txt 第3行的内容sed '3p' text.txt # 查看 log.txt 第2-8行的内容sed '2,8p' text.txt # 删除 log.txt 第4行sed -i '4d' text.txt # 删除 log.txt 第3-7行sed -i '3,7d' text.txt # 删除 log.txt 第1行sed -i '1d' text.txt # 删除 log.txt 最后1行sed -i '$d' text.txt # 删除 log.txt 文件中所有包含 233内容的行sed -i '/233/d' text.txt # 替换 log.txt 文件中所有 233为666sed -i 's/233/666/' text.txt # 替换 log.txt 文件中所有 /ver 为 啦啦啦/，因为有斜杠，所以需要使用 \\ 转义，但是单引号会导致无法转义，所以要改成双引号。sed -i &quot;s/\\/ver/啦啦啦\\//&quot; text.txt # 待写... # 更多的命令可以用 sed --help 来查看。 vi、vim、nano 编辑文件内容vi 介绍 vi 是Linux很棒的一个文本编辑器，不过也存在一些缺点，比如操作略麻烦。而 vim就相当于 vi的扩展或者加强版，主要介绍 vim。 vim 介绍 vim 相当于 vi的扩展或者加强版，一些系统只安装了 vi，所以想要用 vim还需要手动安装( yum install vim -y / apt-get install vim -y)，安装 vim后，会自动替换或者说整合 vi。 当你使用 vi 命令的时候，首先进入的是 命令行模式，这个模式就是 vi 自身的功能，而点击 I 键 后就会进入编辑模式(插入模式)，这时候就可以直接输入字符了，这个就是 vim的扩展功能了。当修改完成后，按 ESC键 即可退出编辑模式回到命令行模式，这时候输入 :wq 并回车代表保存并退出，如果不想保存可以使用 :q! 不保存强制退出。 vim的命令行 命令很多，在这列出最常用的一些。 1234567891011121314151617181920212223242526272829# 打开当前目录下的 log.txt文件，如果没有那么会新建 log.txt文件（安装vim后，使用 vi和 vim打开文件没区别）vi log.txtvim log.txt # 在命令行模式下，直接输入以下 符号和字母(区分大小写)## 进入编辑模式（插入模式，按 Esc键 即可返回命令行模式）i## 删除光标当前所在的一行dd## 删除文件内所有内容dddG## 复制光标当前所在的一行yy## 粘贴刚才复制的一行内容p## 撤销上个操作（误操作可以用这个恢复）u## 保存当前文件（ : 是英文的冒号）:w## 另存当前文件内容为 log2.txt:w log2.txt## 退出当前文件:q## 不保存 并强制退出当前文件:q!## 保存并退出当前文件:wq # 更多的命令可以用 vi --help / vim --help 来查看。 nano 介绍 nano 没怎么用过,全是使用vi或者vim，一些系统也默认安装了这个 文本编辑器，在一些地方比 vim好用，不过已经习惯了 vim。 1234567891011121314# 打开当前目录下的 log.txt文件，如果没有那么会新建 log.txt文件nano log.txt # 进入后直接就可以输入修改文本内容了，修改后我们可以使用这个 按键保存内容Ctrl+O # 如果不需要编辑了，那么可以用这个 按键退出当前文件Ctrl+X # 如果你在退出前已经修改但没有保存，那么会提醒你是否保存，如果保存就输入 y ，不保存输入 n# 然后就会让你输入要保存的文件名（默认原文件名，所以直接按 Enter回车即可，除非你要另存为其他文件名）Enter # 更多的命令可以在 nano 编辑界面中按 F1键 查看。 解压缩 操作在Linux中经常会下载到压缩文件，而压缩文件的格式有很多，比如 zip、rar、gz、xz、tar.gz、tar.xz等。 比较常见的就是各种 .tar、.tar.xz、.tar.gz、.tar.bz、.tar.bz2、.tar.Z 后缀压缩包，这几个的解压缩命令基本一样，说明一下参数的意义。 12345678910-x 是从压缩文件提取(解压)文件出来，所以在解压命令中都有这个参数。-c ：创建一个新的压缩包文件，所以在压缩命令中都有这个参数。-f ：指定要解压的压缩包文件或要压缩的文件/文件夹，所以这个参数必须放在 解压缩命令参数的最后，然后后面跟着 要解压到压缩包文件或要压缩的文件/文件夹。-j ：解压缩 bz / bz2 格式的参数-J ：解压缩 xz / lzip 格式的参数-z ：解压缩 gz / tgz 格式的参数-Z ：解压缩 Z 格式的参数-v ：详细列出解压缩过程中处理的文件 # 更多的命令可以用 tar --help 来查看。 tar gz zip等 解压 压缩包 示例123456789101112131415161718192021222324252627282930313233343536# 解压后缀为 .tar 的压缩包tar -xf log.tar—————————————————————————————————————# 解压后缀为 .tar.xz 的压缩包tar -xJf log.tar.xz—————————————————————————————————————# 解压后缀为 .tar.gz 的压缩包，有两个方法tar -xzf log.tar.gz—————————————————————————————————————# 解压后缀为 .gz 的压缩包，有两个方法，如提示命令不存在，请安装 yum install gzip -y / apt-get install gzip -ygzip -d log.gzgunzip log.gz—————————————————————————————————————# 解压后缀为 .bz / .bz2 / tar.bz2 的压缩包，有两个方法bzip2 -d log.bzbunzip2 log.bztar -jxf log.tar.bz bzip2 -d log.bz2bunzip2 log.bz2tar -jxf log.tar.bz2—————————————————————————————————————# 解压后缀为 .Z / tar.Z 的压缩包，有两个方法uncompress log.Z log.txtuncompress log.Z log—————————————————————————————————————tar xZf log.tar.Z log.txttar xZf log.tar.Z log—————————————————————————————————————# 解压后缀为 .rar 的压缩包，如提示命令不存在，请安装 yum install unrar -y / apt-get install unrar -y ，注意 rar 和 unrar 是分开的unrar x log.rar—————————————————————————————————————# 解压后缀为 .zip 的压缩包，如提示命令不存在，请安装 yum install unzip -y / apt-get install unzip -y，注意 zip 和 unzip 是分开的unzip log.zip # 更多的命令可以用 tar --help / gzip --help / unrar --help / unzip --help 来查看。 压缩 文件/文件夹 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.tar 压缩包tar -cf log.tar log.txttar -cf log.tar log—————————————————————————————————————# 如果要压缩多个文件和文件夹，那么只需要在后面一直加下去即可tar -cf log.tar log.txt test.txt log bash—————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.tar.xz 压缩包，以下的其他后缀压缩命令都是一样tar -cJf log.tar.xz log.txttar -cJf log.tar.xz log—————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.tar.gz 压缩包tar -czf log.tar.gz log.txttar -czf log.tar.gz log—————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.gz 压缩包gzip log.gz log.txtgzip log.gz log—————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.tar.bz 压缩包暂时没查到—————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.bz / log.tar.bz / log.bz2 / log.tar.bz2压缩包bzip2 -z log.txtbzip2 -z log tar cjf log.tar.bz2 log.txttar cjf log.tar.bz2 log—————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.Z / log.tar.Z 压缩包compress log.txtcompress log tar cZf log.tar.Z log.txttar cZf log.tar.Z log—————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.rar 压缩包，如提示命令不存在，请安装 yum install rar -y / apt-get install rar -y ，注意 rar 和 unrar 是分开的unrar a log.rar log.txtunrar a log.rar log—————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.zip 压缩包，如提示命令不存在，请安装 yum install zip -y / apt-get install zip -y ，注意 zip 和 unzip 是分开的zip log.zip log.txtzip log.zip log # 更多的命令可以用 tar --help / gzip --help / rar --help / zip --help 来查看。 下载相关wget 下载工具wget 是Linux系统最常用的工具之一，命令行方式的多功能下载工具，支持HTTP，HTTPS和FTP协议。 123456789101112131415161718# 只介绍最常用的参数# 如果提示命令不存在，那么使用 yum install wget -y / apt-get install wget -y 来安装（有一些非常精简的系统可能会没装） -b ：启动后，后台下载-q ：安静模式（不输出任何信息）-c ：断点续传下载文件-O ：指定下载后的文件名（可使用绝对路径目录+文件名）-P ：指定下载后的文件目录（-P只能指定下载目录，并不能指定文件名）-t ：设置重试次数（0代表无限）-T ：设置超时时间（单位：秒）-N ：只获取比本地新的文件（新的覆盖旧的）-4 ：仅连接至 IPv4地址-6 ：仅连接至 IPv6地址--limit-rate=xxxk :限制下载速度（k代表KB/S）--post-data ：通过POST方式发送数据--no-check-certificate ：不验证服务器的SSL证书 # 更多的命令可以用 wget --help 来查看。 e.g.123456789101112131415161718192021222324252627282930313233343536373839# 下载一个文件到当前目录wget https://softs.wtf/100MB.bin # 下载文件到当前目录并重命名为 200MB.binwget -O &quot;200MB.bin&quot; https://softs.wtf/100MB.bin # 下载文件到 /root目录（-P只能指定下载目录，并不能指定文件名）wget -P &quot;/root&quot; https://softs.wtf/100MB.bin # 下载文件到 /root/123456.plus目录并重命名为 200MB.binwget -O &quot;/root/123456.plus/200MB.bin&quot; https://softs.wtf/100MB.bin # 下载文件完成之前 wget进程结束了，那么可以使用断点续传重新下载中断的文件（前提是下载服务器支持断点续传）wget -c https://softs.wtf/100MB.bin # 通过后台下载文件到 /root/123456.plus目录并重命名为 200MB.binwget -b -O &quot;/root/123456.plus/200MB.bin&quot; https://softs.wtf/100MB.bin# Continuing in background, pid 2333.# Output will be written to `wget-log'.# 后台下后，你可以使用以下命令来查看下载进度：tail -f wget-log # 有时候一些Linux系统中的SSL证书不完整，会导致下载一些 HTTPS网站文件的时候会验证SSL证书失败，可以这样做# 不验证服务器SSL证书，下载文件到当前目录并重命名为 200MB.binwget --no-check-certificate -O &quot;200MB.bin&quot; https://softs.wtf/100MB.bin # 使用wget发送POST请求数据wget --post-data &quot;user=123456.plus&amp;passwd=123456&quot; https://xxx.xx/ # 下载文件到当前目录 并仅通过IPv4连接 只获取比本地新的文件，限速 200KB/Swget --limit-rate=200k -N -4 https://softs.wtf/100MB.bin # 下载文件到当前目录 并重试次数为 1，超时时间为 2秒wget -t1 -T2 https://softs.wtf/100MB.bin # 通过 wget来获取服务器的外网IP（-qO- 代表运行完会输出下载的信息，并不会保存到本地文件）wget -qO- ipinfo.io/ip # 更多的命令可以用 wget --help 来查看。 curl 下载工具curl是Linux系统一个利用URL规则在命令行下工作的文件传输工具，是一款很强大的HTTP命令行工具。它支持文件的上传和下载，是综合传输工具，但习惯称curl为下载工具。 1234567891011121314151617# 只介绍最常用的参数# 如果提示命令不存在，那么使用 yum install curl -y / apt-get install curl -y 来安装（有一些非常精简的系统可能会没装） -s ：安静模式（不会输出任何信息）-C ：断点续传下载文件-o ：输出写入到文件中-O ：输出写入到文件，文件名为 远程文件的名称-k ：不验证服务器SSL证书-T ：上传文件-4 ：仅连接至 IPv4地址-6 ：仅连接至 IPv6地址-m ：设置传输总时间（单位：秒）--retry ：设置重试次数--data ：通过POST方式发送数据--limit-rate xxxK ：限制下载速度（K代表KB/S） # 更多的命令可以用 curl --help 来查看。 e.g.1234567891011121314151617181920212223242526272829# 获取当前服务器的外网IPcurl ipinfo.io/ip # 获取一个文件保存到当前目录中wget -O https://softs.wtf/Bash/ssr.sh # 获取一个文件保存到 /root/123456.plus 并修改文件名为 test.shcurl -o &quot;/root/123456.plus/test.sh&quot; https://softs.wtf/Bash/ssr.sh # 下载文件完成之前 curl进程结束了，那么可以使用断点续传重新下载中断的文件（前提是下载服务器支持断点续传）curl -C -O https://softs.wtf/100MB.bin # 有时候一些Linux系统中的SSL证书不完整，会导致访问/下载一些 HTTPS网站/文件的时候会验证SSL证书失败，可以这样做# 不验证服务器SSL证书，下载文件到当前目录并重命名为 test.shcurl -k -o &quot;test.sh&quot; https://softs.wtf/Bash/ssr.sh # 使用curl发送GET请求数据curl https://xxx.xx/?user=123456.plus # 使用curl发送POST请求数据curl --data &quot;user=123456.plus&amp;passwd=123465&quot; https://xxx.xx/ # 下载文件到当前目录 并仅通过IPv4连接，限速 200KB/Scurl --limit-rate 200K -4 https://softs.wtf/100MB.bin # 下载文件到当前目录 并重试次数为 1，超时时间为 2秒curl --retry 1 -m 10 https://softs.wtf/100MB.bin # 更多的命令可以用 curl --help 来查看。 netstat 查看链接和端口监听等信息12345678910111213141516-n ：不显示别名（主机名/域名以 数字或IP显示）-e ：显示其他/更多信息-p ：显示进程PID/进程名-c ：持续输出（设置后会每隔 1秒输出一次，Ctrl+C 终止）-l ：显示正在监听的套接字-a ：显示全部信息 # 下面这些就不很常用了。-r ：显示路由表-i ：显示网络接口（网卡）-g ：显示多播组信息-s ：显示网络统计-M ：显示伪装连接-v ：显示正在进行的工作 # 更多的命令可以用 netstat --help 来查看。 e.g.1234567891011121314# 显示当前服务器的所有连接信息netstat -a # 显示当前服务器的所有 TCP连接信息netstat -at # 显示当前服务器的所有 UDP连接信息netstat -au # 显示当前服务器的所有 端口监听信息netstat -lnp # 显示当前服务器的所有 TDP端口监听信息netstat -lntp 一般来说经常使用这个命令： 1234567891011121314151617181920212223242526# 显示当前服务器的所有正在监听 TCP端口的信息，并且 显示进程PID和进程名，但不显示别名（域名以IP显示），这个命令算是最常用的了。netstat -lntp # 输出示例Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 14233/nginx.conftcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1555/sshd tcp 0 0 0.0.0.0:443 0.0.0.0:* LISTEN 14233/nginx.conftcp6 0 0 :::22 :::* LISTEN 1555/sshd—————————————————————————————————————# 显示监听 80端口的进程PID和进程名，grep是匹配并显示 符合关键词的行。netstat -lntp|grep &quot;:80&quot; # 输出示例Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 14233/nginx.conf—————————————————————————————————————# 显示 ssh的监听情况，grep是匹配并显示 符合关键词的行。netstat -lntp|grep &quot;ssh&quot; # 输出示例Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1555/sshd 表头解释： 1234567Proto ：连接协议（tcp/udp是IPv4，tcp6/udp6是IPv6）Recv-Q ： 接收队列（基本都是0，如果不是代表堆积）Send-Q ：发送队列（基本都是0，如果不是代表堆积）Local Address ：本地地址和端口Foreign Address ：对外地址和端口State ：连接状态PID/Program name ：进程PID/进程名 12345678910111213141516171819# 每隔 1秒显示一次当前服务器的所有连接信息netstat -c # 每隔 1秒显示一次当前服务器的所有 TCP连接信息netstat -ct # 每隔 1秒显示一次当前服务器的所有 UDP连接信息netstat -cu # 显示当前服务器的路由表netstat -r # 显示当前服务器的网络接口信息（网卡）netstat -i # 显示当前服务器的网络统计信息netstat -s # 更多的命令可以用 netstat --help 来查看。 在使用 netstat命令中，会显示一些连接状态，下面是各状态的意思： 1234567891011121314151617181920212223242526272829303132LISTEN# 监听来自远程连接的 TCP端口连接请求 SYN-SENT# 在发送连接请求后，等待匹配的连接请求 SYN-RECEIVED# 在收到和发送一个连接请求后，等待对方对连接请求的确认 ESTABLISHED# 代表一个打开的连接 FIN-WAIT-1# 等待远程 TCP连接中断请求，或先前的连接中断请求的确认 FIN-WAIT-2# 从远程 TCP等待连接中断请求 CLOSE-WAIT# 等待从本地用户发来的连接中断请求 CLOSING# 等待远程TCP对连接中断的确认 LAST-ACK# 等待原来的发向远程TCP的连接中断请求的确认 TIME-WAIT# 等待足够的时间，以确保远程TCP接收到连接中断请求的确认 CLOSED# 没有任何连接状态（或者关闭了连接） 系统命令ps 查看进程信息1#可以用 man ps 来查看。 e.g.12345678# 显示当前进程信息ps -ef # 显示 ssh 进程（ grep -v grep 表示排除关键词grep，因为使用 grep匹配ssh，也会把grep自己的进程匹配进去的）ps -ef|grep -v grep|grep 'ssh'# 输出示例UID PID PPID C STIME TTY TIME CMD #注意使用上面命令的话是不会显示表头这一行的，我只是为了更好理解加上的root 1738 1 0 01/27 ? 00:08:56 /usr/sbin/sshd 表头解释： 12345678UID ：启动进程的用户PID ：进程标识符（进程 1代表init 是整个系统的父进程）PPID ：父进程标识符（进程 1代表init 是整个系统的父进程）C ：CPU占用率 %STIME ：启动进程的日期TTY ：终端号TIME ：进程运行时间（非休眠状态）CMD ：启动进程的命令（或进程名/进程程序所在目录） kill 结束进程1234567891011121314151617# 当我们想要结束一个进程的时候，我们可以用 kill 命令# PID是每个进程的一个唯一标识符，可以使用上面的 ps 命令来查看你要结束进程的PID。 # 假设我们要结束 Nginx的进程，那么这样做（ grep -v grep 表示排除关键词grep，因为使用 grep匹配ssh，也会把grep自己的进程匹配进去的）：ps -ef|grep -v grep|grep &quot;nginx&quot; # 输出示例UID PID PPID C STIME TTY TIME CMD #注意使用上面命令的话是不会显示表头这一行的，我只是为了更好理解加上的root 2356 1 0 04/03 ? 00:03:12 nginx # 然后我们可以看到第二列的 PID 进程标识符，然后我们 kill 即可。kill -9 2356 # 中断进程 -2 相当于 程序运行在前台，然后输入 Ctrl+C 的效果，但是进程有权利忽略，所以不一定能结束进程kill -2 PID# 强制结束进程 -9 ，注意：强制结束某个进程后，可能会造成进程数据丢失等问题！kill -9 PID free 查看内存使用信息123456789101112-b ：以 字节(bytes/B) 为单位显示-k ：以 KB 为单位显示-m ：以 MB 为单位显示-g ：以 GB 为单位显示--tera ：以 TB 为单位显示-h ：以 人类易读的方式输出--si ：以 1000为单位转换，而不是 1024（1MB=1*1024KB改成 1MB=1*1000KB）-t ：显示 内存总数 行-s 时间 ：每隔 X秒输出一次（重复输出监视内存，使用 Ctrl+C 终止）-c 次数 ：每隔 1秒输出 X次 # 更多的命令可以用 free --help 来查看。 e.g.12345678910111213141516171819202122232425262728293031323334# 显示当前系统内存（默认 free = free -k，单位为 KB）free # 输出示例 total used free shared buffers cachedMem: 250872 237752 13120 0 34620 70520-/+ buffers/cache: 132612 118260Swap: 643064 1744 641320—————————————————————————————————————# 以单位 B/KB/MB/GB/TG 显示当前系统内存free -b / free -k / free -m / free -g / free --tera—————————————————————————————————————# 以人类易读的方式 显示当前系统内存free -h # 输出示例 total used free shared buffers cachedMem: 244M 232M 12M 0B 33M 68M-/+ buffers/cache: 129M 115MSwap: 627M 1.7M 626M—————————————————————————————————————# 以 1000为单位转换并使用 MB为单位 显示当前系统内存（1MB=1*1024KB改成 1MB=1*1000KB）free -m --si # 每隔 3秒并使用 MB为单位 显示一次当前系统内存free -ms 3 # 每隔 1秒并使用 MB为单位 显示 5次当前系统内存free -mc 5 # 每隔 2秒并使用 MB为单位 总共显示 6次当前系统内存free -m -c 6 -s 2 # 更多的命令可以用 free --help 来查看。 表头解释： 12345# 说明示例 total used free shared buffers cachedMem: 244M 232M 12M 0B 33M 69M-/+ buffers/cache: 129M 115MSwap: 627M 1.7M 626M 1234567891011121314151617181920# Mem 行，表示物理内存统计total :系统 总物理内存used :系统 已分配物理内存（但非全部都在使用，包含buffers好cached）free :系统 未分配物理内存shared :系统 共享内存，一般都是 0buffers :系统 分配但未使用的 buffers数量cached :系统 分配但未使用的 cached数量 # -/+ buffers/cache 行，表示物理内存的缓存统计used :系统 实际使用的内存# user= Mem行 used-buffers-cached（232-33-69=130，因单位转换问题 所以会有一点差距）free :系统 实际可用的内存# free= Mem行 free+buffers+cached（12+33+69=114，因单位转换问题 所以会有一点差距） # 所以我们看系统的真实 使用/剩余内存 只需要看这一行即可！ # Swap 行，表示硬盘的交换分区（虚拟内存）统计total :系统 总虚拟内存used :系统 已分配虚拟内存free :系统 未分配虚拟内存 date 查看/设置 系统时间12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 -d ：以指定的时间格式 显示时间 -f ：显示 DATE FILE文件中的每行时间（我也不懂） -r ：显示 文件/文件夹 最后修改时间 -s ：设置 系统时间 -u ：显示 UTC时间 # 时间格式 %% - 显示字符%%a - 星期几的缩写(Sun..Sat)%A - 星期几的完整名称（Sunday...Saturday）%b - 月份的缩写(Jan..Dec)%B - 月份的完整名称(January..December)%c - 日期与时间。只输入date指令也会显示同样的结果%C - 世纪(年份除100后去整) [00-99]%d - 日期(以01-31来表示)。%D - 日期(含年月日)。%e - 一个月的第几天 ( 1..31)%F - 日期，同%Y-%m-%d%g - 年份(yy)%G - 年份(yyyy)%h - 同%b%H - 小时(00..23)%I - 小时(01..12)%j - 一年的第几天(001..366)%k - 小时( 0..23)%l - 小时( 1..12)%m - 月份(01..12)%M - 分钟(00..59)%n - 换行%N - 纳秒(000000000..999999999)%p - AM or PM%P - am or pm%r - 12小时制时间(hh:mm:ss [AP]M)%R - 24小时制时间(hh:mm)%s - 从00:00:00 1970-01-01 UTC开始的秒数%S - 秒(00..60)%t - 制表符%T - 24小时制时间(hh:mm:ss)%u - 一周的第几天(1..7); 1 表示星期一%U - 一年的第几周，周日为每周的第一天(00..53)%V - 一年的第几周，周一为每周的第一天 (01..53)%w - 一周的第几天 (0..6); 0 代表周日%W - 一年的第几周，周一为每周的第一天(00..53)%x - 日期(mm/dd/yy)%X - 时间(%H:%M:%S)%y - 年份(00..99)%Y - 年份 (1970…)%z - RFC-2822 风格数字格式时区(-0500)%Z - 时区(e.g., EDT), 无法确定时区则为空 # 更多的命令可以用 date --help 来查看。 e.g.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 显示 当前系统时间date# 输出：Wed Apr 5 12:38:44 CST 2017 # 显示当前系统的 UTC时间date -u# 输出：Wed Apr 5 04:30:06 UTC 2017 # 显示 log.txt 文件的最后修改时间date -r log.txt # 显示 当前日期的年份date +%Y# 输出：2017 # 显示 当前日期的月份date +%m# 输出：4 # 显示 各种格式类型的日期date +%D# 输出：04/05/17 date +%Y-%m-%d# 输出：2017-04-05 date +%m/%d/%y# 输出：04/05/17 date +%m/%d/%Y# 输出：04/05/2017 # 显示 Unix时间戳date +%s# 输出：1491367399 # 显示一个完整的时间（年、月、日、小时、分钟、秒钟、周几 时区）date &quot;+%Y-%m-%d %H:%M:%S %u %Z&quot;# 输出：2017-04-05 12:12:15 3 CST # 设置 系统时间（年、月、日）date -s &quot;2017-04-05&quot; # 设置 系统时间（小时、分钟、秒钟）date -s &quot;10:29:05&quot; # 设置 系统时间（年、月、日、小时、分钟、秒钟）date -s &quot;2017-04-05 10:29:05&quot; # 更多的命令可以用 date --help 来查看。 修改时区为上海（北京）时区的方法： 1cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 然后再用date查看时间，就会发现时区变为 CST 了。 chmod 修改 文件/文件夹 权限1234567891011121314151617181920212223242526272829303132333435-c :只输出被改变权限的文件信息-f :当chmod不能改变文件模式时，不通知文件的用户-R :可递归遍历子目录，把修改应到目录下所有文件和子目录-v :无论修改是否成功，输出每个文件的信息 # 操作符号： + :添加某个权限。- :取消某个权限。= :赋予给定权限并取消其他所有权限（如果有的话）。 # 权限设置字母： r :可读w :可写x :可执行X :只有目标文件对某些用户是可执行的或该目标文件是目录时才追加x 属性s :在文件执行时把进程的属主或组ID置为该文件的文件属主。方式“u＋s”设置文件的用户ID位，“g＋s”设置组ID位t :保存程序的文本到交换设备上u :当前用户的权限g :当前用户同组的权限o :其他用户的权限 # 权限设定数字： # 数字表示的属性含义：0 ：表示没有权限1 ：表示可执行权限2 ：表示可写权限4 ：表示可读权限 # 然后将其相加，所以数字属性的格式应为3个从0到7的八进制数，其顺序是（u）（g）（o）。# 如果想让某个文件的属主有“读/写”二种权限，需要把4（可读）+2（可写）＝6（读/写）。 # 更多的命令可以用 chmod --help 来查看。 e.g.123456789101112131415# 当需要运行 可执行的脚本或者程序（比如 Go语言编写的软件）的时候，需要赋予执行权限chmod +x ssr.sh # 赋予 log.txt 文件可读权限chmod 444 log.txt # 赋予 /ver/log 文件夹 可读、可写权限chmod 666 log.txt # 赋予 /home/www 文件夹 可读、可写、可执行权限chmod 777 log.txt # 赋予 /home/www 文件夹极其所有子目录和文件 可读、可写、可执行权限chmod -R 777 log.txt# 更多的命令可以用 chmod --help 来查看。 uname 获取操作系统信息1234567891011-a：显示 全部信息-m：显示 系统位数-n：显示 主机名称-r：显示 操作系统的发行编号-s：显示 操作系统的名称-v：显示 操作系统的版本-p：输出 处理器类型 或&quot;unknown&quot;-i：输出 硬件平台 或&quot;unknown&quot;-o：输出 操作系统名称 # 更多的命令可以用 uname --help 来查看。 e.g.1234567891011121314151617181920root@liu:~# uname #在使用 uname 的时候，相当于是使用 uname -sLinuxroot@liu:~# uname -aLinux liu 2.6.32-042stab120.6 #1 SMP Thu Oct 27 16:59:03 MSK 2016 i686 GNU/Linuxroot@liu:~# uname -m #输出一般是64位: x86_64 / 32位: i386 或分支 i686 i686root@liu:~# uname -nliuroot@liu:~# uname -r2.6.32-042stab120.6root@liu:~# uname -sLinuxroot@liu:~# uname -v#1 SMP Thu Oct 27 16:59:03 MSK 2016root@liu:~# uname -punknownroot@liu:~# uname -iunknownroot@liu:~# uname -oGNU/Linux 参考链接: linux命令大全 Linux常用命令大全 Linux常用命令学习 『持续更新』Linux 常用命令简单介绍 —— 基础篇","link":"/2018/11/07/Linux%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%8F%8A%E4%B8%BE%E4%BE%8B(20181107%E6%9B%B4%E6%96%B0)/"}],"tags":[{"name":"javascript","slug":"javascript","link":"/tags/javascript/"},{"name":"爬虫","slug":"爬虫","link":"/tags/%E7%88%AC%E8%99%AB/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"Chrome","slug":"Chrome","link":"/tags/Chrome/"},{"name":"TypeScript","slug":"TypeScript","link":"/tags/TypeScript/"},{"name":"React","slug":"React","link":"/tags/React/"},{"name":"customize-cra","slug":"customize-cra","link":"/tags/customize-cra/"},{"name":"SpaceX","slug":"SpaceX","link":"/tags/SpaceX/"},{"name":"MacOS","slug":"MacOS","link":"/tags/MacOS/"},{"name":"任何来源","slug":"任何来源","link":"/tags/%E4%BB%BB%E4%BD%95%E6%9D%A5%E6%BA%90/"},{"name":"javaScript","slug":"javaScript","link":"/tags/javaScript/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"老照片上色","slug":"老照片上色","link":"/tags/%E8%80%81%E7%85%A7%E7%89%87%E4%B8%8A%E8%89%B2/"},{"name":"图片无损放大","slug":"图片无损放大","link":"/tags/%E5%9B%BE%E7%89%87%E6%97%A0%E6%8D%9F%E6%94%BE%E5%A4%A7/"},{"name":"javascript排序","slug":"javascript排序","link":"/tags/javascript%E6%8E%92%E5%BA%8F/"},{"name":"Rocket.Chat","slug":"Rocket-Chat","link":"/tags/Rocket-Chat/"},{"name":"私人聊天服务","slug":"私人聊天服务","link":"/tags/%E7%A7%81%E4%BA%BA%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1/"},{"name":"团队聊天服务","slug":"团队聊天服务","link":"/tags/%E5%9B%A2%E9%98%9F%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"马赛克修复","slug":"马赛克修复","link":"/tags/%E9%A9%AC%E8%B5%9B%E5%85%8B%E4%BF%AE%E5%A4%8D/"},{"name":"图片转3D","slug":"图片转3D","link":"/tags/%E5%9B%BE%E7%89%87%E8%BD%AC3D/"},{"name":"人工智能","slug":"人工智能","link":"/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"DAIN","slug":"DAIN","link":"/tags/DAIN/"},{"name":"补帧","slug":"补帧","link":"/tags/%E8%A1%A5%E5%B8%A7/"},{"name":"FFmpeg","slug":"FFmpeg","link":"/tags/FFmpeg/"},{"name":"vps","slug":"vps","link":"/tags/vps/"},{"name":"百度网盘","slug":"百度网盘","link":"/tags/%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98/"},{"name":"tensorflow.js","slug":"tensorflow-js","link":"/tags/tensorflow-js/"},{"name":"新冠肺炎","slug":"新冠肺炎","link":"/tags/%E6%96%B0%E5%86%A0%E8%82%BA%E7%82%8E/"},{"name":"树莓派","slug":"树莓派","link":"/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"COVID-19","slug":"COVID-19","link":"/tags/COVID-19/"},{"name":"rrweb","slug":"rrweb","link":"/tags/rrweb/"},{"name":"typescript","slug":"typescript","link":"/tags/typescript/"},{"name":"Deno","slug":"Deno","link":"/tags/Deno/"},{"name":"周杰伦","slug":"周杰伦","link":"/tags/%E5%91%A8%E6%9D%B0%E4%BC%A6/"},{"name":"frp","slug":"frp","link":"/tags/frp/"},{"name":"nps","slug":"nps","link":"/tags/nps/"},{"name":"内网穿透","slug":"内网穿透","link":"/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"远程遥控","slug":"远程遥控","link":"/tags/%E8%BF%9C%E7%A8%8B%E9%81%A5%E6%8E%A7/"},{"name":"安卓","slug":"安卓","link":"/tags/%E5%AE%89%E5%8D%93/"},{"name":"钉钉","slug":"钉钉","link":"/tags/%E9%92%89%E9%92%89/"},{"name":"远程打卡","slug":"远程打卡","link":"/tags/%E8%BF%9C%E7%A8%8B%E6%89%93%E5%8D%A1/"},{"name":"Bitwarden","slug":"Bitwarden","link":"/tags/Bitwarden/"},{"name":"密码保护","slug":"密码保护","link":"/tags/%E5%AF%86%E7%A0%81%E4%BF%9D%E6%8A%A4/"},{"name":"WebGL","slug":"WebGL","link":"/tags/WebGL/"},{"name":"性能优化","slug":"性能优化","link":"/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"Node.js","slug":"Node-js","link":"/tags/Node-js/"},{"name":"NASA","slug":"NASA","link":"/tags/NASA/"},{"name":"哈勃望远镜","slug":"哈勃望远镜","link":"/tags/%E5%93%88%E5%8B%83%E6%9C%9B%E8%BF%9C%E9%95%9C/"},{"name":"Powershell","slug":"Powershell","link":"/tags/Powershell/"},{"name":"windows-terminal","slug":"windows-terminal","link":"/tags/windows-terminal/"},{"name":"homeassistant","slug":"homeassistant","link":"/tags/homeassistant/"},{"name":"智能家居","slug":"智能家居","link":"/tags/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/"},{"name":"libreELEC","slug":"libreELEC","link":"/tags/libreELEC/"},{"name":"http","slug":"http","link":"/tags/http/"},{"name":"GET,POST","slug":"GET-POST","link":"/tags/GET-POST/"},{"name":"AJAX","slug":"AJAX","link":"/tags/AJAX/"},{"name":"双11","slug":"双11","link":"/tags/%E5%8F%8C11/"},{"name":"双十一","slug":"双十一","link":"/tags/%E5%8F%8C%E5%8D%81%E4%B8%80/"},{"name":"android","slug":"android","link":"/tags/android/"},{"name":"iOS","slug":"iOS","link":"/tags/iOS/"},{"name":"苹果","slug":"苹果","link":"/tags/%E8%8B%B9%E6%9E%9C/"},{"name":"移动端视频，h5视频自动播放","slug":"移动端视频，h5视频自动播放","link":"/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E8%A7%86%E9%A2%91%EF%BC%8Ch5%E8%A7%86%E9%A2%91%E8%87%AA%E5%8A%A8%E6%92%AD%E6%94%BE/"},{"name":"threejs","slug":"threejs","link":"/tags/threejs/"},{"name":"tweenjs","slug":"tweenjs","link":"/tags/tweenjs/"},{"name":"腾讯up互动娱乐","slug":"腾讯up互动娱乐","link":"/tags/%E8%85%BE%E8%AE%AFup%E4%BA%92%E5%8A%A8%E5%A8%B1%E4%B9%90/"},{"name":"3D","slug":"3D","link":"/tags/3D/"},{"name":"apple","slug":"apple","link":"/tags/apple/"},{"name":"自带日历","slug":"自带日历","link":"/tags/%E8%87%AA%E5%B8%A6%E6%97%A5%E5%8E%86/"},{"name":"中国，国内节假日","slug":"中国，国内节假日","link":"/tags/%E4%B8%AD%E5%9B%BD%EF%BC%8C%E5%9B%BD%E5%86%85%E8%8A%82%E5%81%87%E6%97%A5/"},{"name":"跨域","slug":"跨域","link":"/tags/%E8%B7%A8%E5%9F%9F/"},{"name":"CORS","slug":"CORS","link":"/tags/CORS/"},{"name":"JSONP","slug":"JSONP","link":"/tags/JSONP/"},{"name":"鸿蒙OS","slug":"鸿蒙OS","link":"/tags/%E9%B8%BF%E8%92%99OS/"},{"name":"uni","slug":"uni","link":"/tags/uni/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"shell","slug":"shell","link":"/tags/shell/"}],"categories":[{"name":"javascript","slug":"javascript","link":"/categories/javascript/"},{"name":"Mac","slug":"Mac","link":"/categories/Mac/"},{"name":"TypeScript","slug":"TypeScript","link":"/categories/TypeScript/"},{"name":"MacOS","slug":"MacOS","link":"/categories/MacOS/"},{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"自建服务","slug":"自建服务","link":"/categories/%E8%87%AA%E5%BB%BA%E6%9C%8D%E5%8A%A1/"},{"name":"vps","slug":"vps","link":"/categories/vps/"},{"name":"新冠肺炎","slug":"新冠肺炎","link":"/categories/%E6%96%B0%E5%86%A0%E8%82%BA%E7%82%8E/"},{"name":"Deno","slug":"Deno","link":"/categories/Deno/"},{"name":"内网穿透","slug":"内网穿透","link":"/categories/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"bitwarden","slug":"bitwarden","link":"/categories/bitwarden/"},{"name":"WebGL","slug":"WebGL","link":"/categories/WebGL/"},{"name":"爬虫","slug":"爬虫","link":"/categories/%E7%88%AC%E8%99%AB/"},{"name":"homeassistant","slug":"homeassistant","link":"/categories/homeassistant/"},{"name":"树莓派","slug":"树莓派","link":"/categories/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"苹果自带日历软件显示中国节假日","slug":"苹果自带日历软件显示中国节假日","link":"/categories/%E8%8B%B9%E6%9E%9C%E8%87%AA%E5%B8%A6%E6%97%A5%E5%8E%86%E8%BD%AF%E4%BB%B6%E6%98%BE%E7%A4%BA%E4%B8%AD%E5%9B%BD%E8%8A%82%E5%81%87%E6%97%A5/"},{"name":"鸿蒙OS","slug":"鸿蒙OS","link":"/categories/%E9%B8%BF%E8%92%99OS/"},{"name":"linux","slug":"linux","link":"/categories/linux/"}]}